{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening and cleaning out openephys data\n",
    "\n",
    "Note: Use L1imag/formation environment.\n",
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantities as pq\n",
    "import numpy as np\n",
    "import neo\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import scipy\n",
    "from scipy import interpolate\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "%matplotlib widget\n",
    "\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer\n",
    "\n",
    "#%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "### Load timestamps from continuous recording\n",
    "\n",
    "Note here the synchronised timestamps are not loaded. Attempt is made next cell but there is a bug because the files are of different lengths. \n",
    "What needs to be done is to understand the exact content of these files to then load them properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder = Path('.').absolute()\n",
    "print(folder)\n",
    "path_list_ERS = []\n",
    "Ephys_rec_stamps = {}\n",
    "\n",
    "for file in folder.glob('**/*continuous/Rhythm_FPGA-112.0/timestamps.npy'):\n",
    "    path_list_ERS.append(file)\n",
    "\n",
    "for file_path in folder.glob('**/*continuous/Rhythm_FPGA-112.0/timestamps.npy'):\n",
    "    recording = file_path.parents[2].stem\n",
    "    arr = np.load(file_path)\n",
    "    Ephys_rec_stamps[recording] = arr\n",
    "\n",
    "## Here the timestamps are stored in a dict which is not necessarily what I want, maybe will need to amend that\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not working yet as synchronised timestamps and timestamps for recording 2 are of different size.\n",
    "\n",
    "TTL_stamp2 = []\n",
    "for file_path in folder.glob('**/*.npy'):\n",
    "    subfolder = file_path.parents[1].stem\n",
    "    if subfolder == 'continuous':\n",
    "        recording = file_path.parents[2].stem.replace('recording','')\n",
    "        print(recording)\n",
    "        file = file_path.stem\n",
    "        print(recording, file)\n",
    "        np_arr = np.load(file_path)\n",
    "        datalen = len(np_arr)\n",
    "        print(file, datalen)\n",
    "        if recording == 1: #not in TTL_stamp2:\n",
    "            TTL_stamp2.append(recording)\n",
    "            coords = {\n",
    "                'channels' : np.array(['synchronized_timestamps', 'timestamps']),\n",
    "                'duration_rec' : np.arange(datalen)\n",
    "            }\n",
    "            globals()[f\"StampsCont_{recording}\"] = xr.DataArray(coords=coords, dims=['channels', 'duration_rec'])\n",
    "        globals()[f\"StampsCont_{recording}\"].loc[file,:] = np_arr   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load timestamps for miniscope frames and laser (TTL in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TTL_stamps = []\n",
    "list_recordings = []\n",
    "for file_path in folder.glob('**/*.npy'):\n",
    "    subfolder = file_path.parents[0].stem\n",
    "    if subfolder == 'TTL_1':\n",
    "        recording = file_path.parents[3].stem.replace('recording','')\n",
    "        file = file_path.stem\n",
    "        np_arr = np.load(file_path)\n",
    "        datalen = len(np_arr)\n",
    "        if recording not in TTL_stamps:\n",
    "            TTL_stamps.append(recording)\n",
    "            list_recordings.append(file_path.parents[3].stem)\n",
    "            coords = {\n",
    "                'channels' : np.array(['full_words', 'timestamps', 'channel_states', 'channels']),\n",
    "                'duration_rec' : np.arange(datalen)\n",
    "            }\n",
    "            globals()[f\"Allstamps_{recording}\"] = xr.DataArray(coords=coords, dims=['channels', 'duration_rec'])\n",
    "        globals()[f\"Allstamps_{recording}\"].loc[file,:] = np_arr   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder = Path('.').absolute()\n",
    "list_raw = []\n",
    "for file_path in folder.glob('**/*.dat'):\n",
    "    subfolder = file_path.parents[1].stem\n",
    "    if subfolder == 'continuous':\n",
    "        recording = file_path.parents[2].stem.replace('recording','')\n",
    "        file = file_path.stem\n",
    "        print(recording)\n",
    "        globals()[f\"DataRec_{recording}\"] = np.fromfile(file_path, dtype=\"int16\")\n",
    "        globals()[f\"DataRaw_{recording}\"] = globals()[f\"DataRec_{recording}\"].reshape(-1,32)\n",
    "        list_raw.append(f\"DataRaw_{recording}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribute channels.\n",
    "\n",
    "EMG = 11, deep PFC = 17, superficial PFC = 18, deep S1 = 24, superficial S1 = 23, deep CA1 = 21, superficial CA1 = 20\n",
    "\n",
    "WARNING: this has to be adjusted for every mouse. In the future, add a cell at the beginning to enter these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rawchan = []\n",
    "\n",
    "for ele, file in enumerate(list_raw):\n",
    "    ele2 = ele + 1\n",
    "    # Distribute\n",
    "    EMG = globals()[f\"DataRaw_{ele2}\"][:,10]\n",
    "    PFC = globals()[f\"DataRaw_{ele2}\"][:,17] #- globals()[f\"DataRaw_{ele2}\"][:,17]\n",
    "    S1 = globals()[f\"DataRaw_{ele2}\"][:,22] - globals()[f\"DataRaw_{ele2}\"][:,23] \n",
    "    CA1 = globals()[f\"DataRaw_{ele2}\"][:,20]- globals()[f\"DataRaw_{ele2}\"][:,19]\n",
    "    # Stack back\n",
    "    globals()[f\"Good_channels_{ele2}\"] = np.stack((EMG, PFC, S1, CA1), axis = 1)#.reshape(-1, 4)\n",
    "    nmberchann = globals()[f\"Good_channels_{ele2}\"].shape\n",
    "    datalen = globals()[f\"Good_channels_{ele2}\"].size / nmberchann[1]\n",
    "    print(datalen)\n",
    "    coords = {\n",
    "        'brain_areas' : np.array(['EMG', 'PFC', \"S1\", \"CA1\"]),\n",
    "        'duration_rec' : np.arange(0, datalen/25000, 1/25000)\n",
    "    }\n",
    "    # Put in xarray\n",
    "    globals()[f\"xrGoodChannels_{ele2}\"] = xr.DataArray(coords=coords, dims=['duration_rec', 'brain_areas'])\n",
    "    globals()[f\"xrGoodChannels_{ele2}\"].loc[:,:]  = globals()[f\"Good_channels_{ele2}\"]\n",
    "    Good_channels = globals()[f\"xrGoodChannels_{ele2}\"]\n",
    "    # Save datas\n",
    "    np.save(f'RawDataChannelExtracted_{ele2}.npy', Good_channels)\n",
    "    list_rawchan.append(Good_channels)\n",
    "    # Empty array to free memory \n",
    "    globals()[f\"DataRaw_{ele2}\"] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Downsample all signals to 1 kz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#list_rawchan = [xrGoodChannels_1, xrGoodChannels_2]\n",
    "list_rawchan_filt = []\n",
    "for ele, file in enumerate(list_rawchan):\n",
    "    ele2 = ele + 1\n",
    "    print(ele2)\n",
    "    sampling_rate = 25000 # Hz\n",
    "    new_sampling_rate = 1000 # Hz\n",
    "    nmberchann = file.shape\n",
    "    datalen = file.size/ nmberchann[1]\n",
    "    Nmber_points = int(datalen * new_sampling_rate / sampling_rate)\n",
    "    print(datalen, Nmber_points)\n",
    "    globals()[f\"DS_GoodChannels_{ele2}\"] = signal.resample(file, Nmber_points, axis = 0)\n",
    "    Good_channels_filtered = globals()[f\"DS_GoodChannels_{ele2}\"]\n",
    "    list_rawchan_filt.append(Good_channels_filtered)\n",
    "    np.save(f'RawDataChannelExtractedDS_{ele2}.npy', Good_channels_filtered)\n",
    "    globals()[f\"xrGoodChannels_{ele2}\"] = None\n",
    "\n",
    "list_rawchan = None\n",
    "\n",
    "# if done and no intention to display for assessment\n",
    "#%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook. \n",
    "Data is cleaned up and saved. Data processing for different cortical areas on specific notebooks. Next step is WakeRemoving notebook.\n",
    "\n",
    "Below is for quick filtering, plotting and visualisation to assess data quality. Filtering for data processing is done again in specific notebooks.\n",
    "\n",
    "Data quality is assessed on a Sample, whose value has to be attributed on the initial cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering \n",
    "\n",
    "SWR: 120 - 200 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample = filtered_GoodChannels_1\n",
    "\n",
    "f_CA1 = Sample[:, 3].copy()\n",
    "\n",
    "# Paramètres de notre filtre :\n",
    "f_lowcut = 120.\n",
    "f_hicut = 200.\n",
    "fs = new_sampling_rate\n",
    "nyq = 0.5 * fs\n",
    "N = 6                 # Ordre du filtre\n",
    "Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "print(Wn)\n",
    "\n",
    "# Création du filtre :\n",
    "b, a = scipy.signal.butter(N, Wn, 'band')\n",
    "filt_SWR_CA1 = scipy.signal.filtfilt(b, a, f_CA1)\n",
    "\n",
    "times = np.arange(0, f_CA1.size/new_sampling_rate, 1./new_sampling_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spindles: 8 - 16 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_PFC = Sample[:, 1].copy()\n",
    "f_S1 = Sample[:, 2].copy()\n",
    "\n",
    "# Paramètres de notre filtre :\n",
    "f_lowcut = 10.\n",
    "f_hicut = 16.\n",
    "Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "N = 4\n",
    "# Création du filtre :\n",
    "b, a = scipy.signal.butter(N, Wn, 'band')\n",
    "filt_Spind_PFC = scipy.signal.filtfilt(b, a, f_PFC)\n",
    "filt_Spind_S1 = scipy.signal.filtfilt(b, a, f_S1)\n",
    "\n",
    "# # Calcul de la reponse en fréquence du filtre\n",
    "# w, h = signal.freqz(b, a)\n",
    "\n",
    "# # Tracé de la réponse en fréquence du filtre\n",
    "# fig, ax = plt.subplots(figsize=(8,5)) \n",
    "\n",
    "# ax.plot(0.5*fs*w/np.pi, np.abs(h), 'b')\n",
    "\n",
    "# ax.set_xlabel('frequency [Hz]')\n",
    "# ax.set_ylabel('Amplitude [dB]')\n",
    "# ax.grid(which='both', axis='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFT display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du spectre\n",
    "f, Pxx_den = signal.welch(f_CA1, fs, nperseg=1024)\n",
    "\n",
    "# Tracé\n",
    "fig, ax = plt.subplots(figsize=(10,5)) \n",
    "ax.semilogy(f, Pxx_den)   #  plot with log scaling on the y axis\n",
    "ax.set_xlabel('frequency [Hz]')\n",
    "ax.set_ylabel('PSD [V**2/Hz]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display. \n",
    "\n",
    "Can massively be improved: with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_sliced = times[000:200000]\n",
    "filt_to_display = filt_SWR_CA1[000:200000]-1000\n",
    "f_CA1_sliced = f_CA1[0000:200000]/2\n",
    "combined = np.stack((f_CA1_sliced, filt_to_display), axis = 1)\n",
    "# Tracé du signal filtré\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,5), layout='constrained') \n",
    "ax.plot(times_sliced, combined, 'r')\n",
    "ax.set_xlabel('Temps [sec]')\n",
    "ax.set_ylabel('Amplitude')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ephyviewer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare numpy array for ephyviewer\n",
    "\n",
    "filt_SWR_CA1_sliced= filt_SWR_CA1[000:200000, np.newaxis]\n",
    "filt_Spind_PFC_sliced= filt_Spind_PFC[000:200000, np.newaxis]\n",
    "filt_Spind_S1_sliced= filt_Spind_S1[000:200000, np.newaxis]\n",
    "filt_sliced = Sample[0000:200000,:]\n",
    "combined2 = filt_sliced[:,0:2].copy()\n",
    "intf_sliced = filt_sliced[:,2]\n",
    "intf_sliced = intf_sliced[:, np.newaxis]\n",
    "combined2 = np.append(combined2, filt_Spind_PFC_sliced, axis=1)\n",
    "combined2 = np.append(combined2, intf_sliced, axis=1)\n",
    "combined2 = np.append(combined2, filt_Spind_S1_sliced, axis=1)\n",
    "intf_sliced = filt_sliced[:,3]\n",
    "intf_sliced = intf_sliced[:, np.newaxis]\n",
    "combined2 = np.append(combined2, intf_sliced, axis=1)\n",
    "combined2 = np.append(combined2, filt_SWR_CA1_sliced, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = mkQApp()\n",
    "\n",
    "\n",
    "sample_rate = 1000.\n",
    "t_start = 0.\n",
    "\n",
    "#Create the main window that can contain several viewers\n",
    "win = MainViewer()\n",
    "view1 = TraceViewer.from_numpy(combined2, sample_rate, t_start, 'Signals')\n",
    "win.add_view(view1)\n",
    "\n",
    "#Parameters can be set in script\n",
    "#view1.params['scale_mode'] = 'same_for_all'\n",
    "view1.params['display_labels'] = True\n",
    "#And also parameters for each channel\n",
    "view1.by_channel_params['ch0', 'color'] = '#aa0000'\n",
    "view1.by_channel_params['ch1', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch2', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch5', 'color'] = '#ff5500'\n",
    "view1.by_channel_params['ch6', 'color'] = '#ff5500'\n",
    "\n",
    "view1.by_channel_params['ch0', 'gain'] = 0.00002\n",
    "view1.by_channel_params['ch1', 'gain'] = 0.00002\n",
    "view1.by_channel_params['ch2', 'gain'] = 0.00004\n",
    "view1.by_channel_params['ch3', 'gain'] = 0.0001\n",
    "view1.by_channel_params['ch4', 'gain'] = 0.0001\n",
    "view1.by_channel_params['ch5', 'gain'] = 0.00002\n",
    "view1.by_channel_params['ch6', 'gain'] = 0.00005\n",
    "\n",
    "view1.by_channel_params['ch0', 'offset'] = 0.3\n",
    "view1.by_channel_params['ch1', 'offset'] = 0.2\n",
    "view1.by_channel_params['ch2', 'offset'] = 0.1\n",
    "view1.by_channel_params['ch3', 'offset'] = 0.\n",
    "view1.by_channel_params['ch4', 'offset'] = -0.1\n",
    "view1.by_channel_params['ch5', 'offset'] = -0.2\n",
    "view1.by_channel_params['ch6', 'offset'] = -0.3\n",
    "\n",
    "#Run\n",
    "win.show()\n",
    "app.exec_()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('formation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:27:05) \n[Clang 12.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "984d3fbee8ffa490637705ae3d7233e001ab0304f3daaca07b5aa8569b88ca53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
