{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spdl oscillations analysis...\n",
      "... for All neurons...\n",
      "... in the PFC\n",
      "Spindles_PFC_ABdetection_CalciumAvgResultsAB_Purple.xlsx\n",
      "Spindles_PFC_ABdetection_CalciumAvgResultsAB_ThreeBlueCrossesOK.xlsx\n",
      "Spindles_PFC_ABdetection_CalciumAvgResultsAB_ThreeColDotsOK.xlsx\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, filename)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Read the Excel file into a dataframe and append it to the list\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(filename)\n",
      "File \u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:517\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 517\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1629\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m   1589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[0;32m   1590\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1591\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1609\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1610\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1612\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1613\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;124;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:793\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    790\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n\u001b[0;32m    792\u001b[0m file_rows_needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_rows(header, index_col, skiprows, nrows)\n\u001b[1;32m--> 793\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sheet_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_rows_needed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[0;32m    796\u001b[0m     sheet\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:616\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_data\u001b[1;34m(self, sheet, file_rows_needed)\u001b[0m\n\u001b[0;32m    614\u001b[0m data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    615\u001b[0m last_row_with_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 616\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msheet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_cell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconverted_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# trim trailing empty elements\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:81\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._cells_by_row\u001b[1;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[0;32m     77\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_source()\n\u001b[0;32m     78\u001b[0m parser \u001b[38;5;241m=\u001b[39m WorkSheetParser(src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shared_strings,\n\u001b[0;32m     79\u001b[0m                          data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mdata_only, epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mepoch,\n\u001b[0;32m     80\u001b[0m                          date_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_date_formats)\n\u001b[1;32m---> 81\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_row\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001b[0m, in \u001b[0;36mWorkSheetParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m properties \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    138\u001b[0m     PRINT_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprint_options\u001b[39m\u001b[38;5;124m'\u001b[39m, PrintOptions),\n\u001b[0;32m    139\u001b[0m     MARGINS_TAG: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_margins\u001b[39m\u001b[38;5;124m'\u001b[39m, PageMargins),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m \n\u001b[0;32m    152\u001b[0m }\n\u001b[0;32m    154\u001b[0m it \u001b[38;5;241m=\u001b[39m iterparse(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource) \u001b[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtag_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdispatcher\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\xml\\etree\\ElementTree.py:1251\u001b[0m, in \u001b[0;36miterparse.<locals>.iterator\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m pullparser\u001b[38;5;241m.\u001b[39mread_events()\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;66;03m# load event buffer\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\zipfile.py:955\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 955\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m    957\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\Manip2\\.conda\\envs\\minian311new2\\Lib\\zipfile.py:1031\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_type \u001b[38;5;241m==\u001b[39m ZIP_DEFLATED:\n\u001b[0;32m   1030\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[1;32m-> 1031\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39meof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m                  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Stats on Ca2+ imaging with miniscope and Osc\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import pickle\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import zscore\n",
    "from scipy.stats import sem\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def column_with_max_single_per_row(row):\n",
    "    max_val = row.max()  # Find the max value in the row\n",
    "    max_columns = row == max_val  # Boolean Series of columns with max value\n",
    "    \n",
    "    if max_columns.sum() > 1:\n",
    "        return 'NoPref'  # More than one column has the max value\n",
    "    else:\n",
    "        return max_columns.idxmax()  # Return the name of the column with max value\n",
    "\n",
    "########################################################################\n",
    "        # SCRIPT 27AB_GrandAverages&Stats_for_Osc\n",
    "########################################################################\n",
    "\n",
    "# Specify the directory containing the Excel files\n",
    "directory = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis/OscillationsAnalysis_PerMouse_2024_06_13_16_33_03_913022/\"\n",
    "\n",
    "# Get the current date and time\n",
    "FolderNameSave=str(datetime.now())\n",
    "FolderNameSave = FolderNameSave.replace(\" \", \"_\").replace(\".\", \"_\").replace(\":\", \"_\")\n",
    "destination_folder= f\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording_ABmodified/AB_Analysis/GlobalOscillationsAnalysis_{FolderNameSave}/\"\n",
    "os.makedirs(destination_folder)\n",
    "folder_to_save=Path(destination_folder)\n",
    "\n",
    "# Copy the script file to the destination folder\n",
    "source_script = \"C:/Users/Manip2/SCRIPTS/Code python audrey/code python aurelie/HayLabAnalysis/python/25_28AB_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.ipynb\"\n",
    "destination_file_path = f\"{destination_folder}/25_28AB_GrandAverage&Stats_for_DownStatesSpdl&SWR_FullAuto.txt\"\n",
    "shutil.copy(source_script, destination_file_path)\n",
    "\n",
    "NrSubtypeList=['All', 'L1']\n",
    "CortexList=['PFC', 'S1']\n",
    "\n",
    "OscList=['Spdl', 'SWR', 'DS']\n",
    "OscillationList=['Spindles', 'SWR', 'DS']\n",
    "\n",
    "for o, Osc in enumerate(OscList): \n",
    "    \n",
    "    print(Osc, 'oscillations analysis...')\n",
    "\n",
    "    for NrSubtype in NrSubtypeList: \n",
    "        \n",
    "        print('... for', NrSubtype, 'neurons...')\n",
    "\n",
    "        for Cortex in CortexList:\n",
    "            \n",
    "            print('... in the', Cortex)\n",
    "\n",
    "            # Initialize an empty list to store the dataframes\n",
    "            dfs = []\n",
    "            df=[]\n",
    "            dfs2 = []\n",
    "            df2=[]\n",
    "            dfs2_per_sheet = {}\n",
    "            dfs3 = []\n",
    "            df3=[]\n",
    "            dfs3_per_sheet = {}\n",
    "            dfs4 = []\n",
    "            df4=[]\n",
    "            dfs4_per_sheet = {}\n",
    "            combined_df=[]\n",
    "\n",
    "            if NrSubtype=='L1':\n",
    "                MiceList=['BlackLinesOK', 'BlueLinesOK', 'GreenDotsOK', 'GreenLinesOK', 'RedLinesOK']\n",
    "            else:\n",
    "                MiceList=['Purple', 'ThreeColDotsOK', 'ThreeBlueCrossesOK']\n",
    "\n",
    "            nametofind=f'{OscillationList[o]}_{Cortex}_ABdetection_GlobalResultsAB'\n",
    "            nametofind2=f'{OscillationList[o]}_{Cortex}_ABdetection_CalciumAvgResultsAB'\n",
    "            nametofind3=f'{OscillationList[o]}_{Cortex}_ABdetection_SpikeAvgResultsAB'\n",
    "            nametofind4=f'{OscillationList[o]}_{Cortex}_ABdetection_SpikeSumResultsAB'\n",
    "\n",
    "            # Recursively traverse the directory structure\n",
    "            for root, _, files in os.walk(directory):\n",
    "                for filename in files:\n",
    "                    # Check if the file is an Excel file and contains the specified name\n",
    "                    if filename.endswith('.xlsx') and nametofind in filename:\n",
    "                        if any(name in filename for name in MiceList):  \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            # Read the Excel file into a dataframe and append it to the list\n",
    "                            df = pd.read_excel(filepath, index_col=0)\n",
    "                            dfs.append(df)\n",
    "                            print(filename)\n",
    "                    if filename.endswith('.xlsx') and nametofind2 in filename: \n",
    "                        if any(name in filename for name in MiceList): \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            # Read the Excel file into a dataframe and append it to the list\n",
    "                            excel_data = pd.read_excel(filepath, sheet_name=None, index_col=0, header=None)           \n",
    "                            for sheet_name, df2 in excel_data.items():\n",
    "                                if len(df2)>0:\n",
    "                                    if sheet_name in dfs2_per_sheet:                                       \n",
    "                                        updated_matrix = pd.concat([dfs2_per_sheet[sheet_name], df2], ignore_index=False, axis=0)                    \n",
    "                                        dfs2_per_sheet[sheet_name] = updated_matrix    \n",
    "                                    else:\n",
    "                                        dfs2_per_sheet[sheet_name] = df2  #one average trace per unique unit, len(df2)==nb unit recorded for that mouse\n",
    "                            print(filename)\n",
    "                    if filename.endswith('.xlsx') and nametofind3 in filename: \n",
    "                        if any(name in filename for name in MiceList): \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            # Read the Excel file into a dataframe and append it to the list\n",
    "                            excel_data = pd.read_excel(filepath, sheet_name=None, index_col=0, header=None)           \n",
    "                            for sheet_name, df3 in excel_data.items():\n",
    "                                if sheet_name in dfs3_per_sheet:   \n",
    "                                    updated_matrix = pd.concat((dfs3_per_sheet[sheet_name],df3), ignore_index=False, axis=0)                \n",
    "                                    dfs3_per_sheet[sheet_name] = updated_matrix                    \n",
    "                                else:                    \n",
    "                                    dfs3_per_sheet[sheet_name] = df3 #one average trace per unique unit, len(df3)==nb unit recorded for that mouse\n",
    "                            print(filename)\n",
    "                    if filename.endswith('.xlsx') and nametofind4 in filename: \n",
    "                        if any(name in filename for name in MiceList): \n",
    "                            # Construct the full path to the file\n",
    "                            filepath = os.path.join(root, filename)\n",
    "                            # Read the Excel file into a dataframe and append it to the list\n",
    "                            excel_data = pd.read_excel(filepath, sheet_name=None, index_col=0, header=None)           \n",
    "                            for sheet_name, df4 in excel_data.items():\n",
    "                                if sheet_name in dfs4_per_sheet:   \n",
    "                                    updated_matrix = pd.concat((dfs4_per_sheet[sheet_name],df4), ignore_index=False, axis=0)                \n",
    "                                    dfs4_per_sheet[sheet_name] = updated_matrix                    \n",
    "                                else:                    \n",
    "                                    dfs4_per_sheet[sheet_name] = df4 #one average trace per unique unit, len(df4)==nb unit recorded for that mouse\n",
    "                            print(filename)\n",
    "\n",
    "\n",
    "            ###########################################################################\n",
    "                                        ##### GLOBAL #####\n",
    "            ###########################################################################\n",
    "\n",
    "            # Concatenate all dataframes into a single dataframe\n",
    "            combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "            combined_df['Unique_Unit'] = combined_df['Unique_Unit'].astype(str)\n",
    "            combined_df['UnitNumber'] = combined_df['UnitNumber'].astype(str)\n",
    "            combined_df['UnitValue'] = combined_df['UnitValue'].astype(str)\n",
    "            combined_df[f'{Osc}Statut'] = combined_df[f'{Osc}Statut'].astype(str)\n",
    "\n",
    "            combined_df['Unit_ID'] = combined_df['Mice'] + combined_df['Unique_Unit']\n",
    "\n",
    "            unique_count = combined_df['Unit_ID'].nunique()\n",
    "            print(unique_count, f'{NrSubtype} neurons recorded') \n",
    "\n",
    "            # Remove non defined Unique Units \n",
    "            combined_df = combined_df[combined_df['Unique_Unit'] != '[]']\n",
    "            unique_count = combined_df['Unit_ID'].nunique()\n",
    "            print(unique_count, f'{NrSubtype} neurons in the cross-registration') \n",
    "            \n",
    "            combined_df[f'{Osc}_ID'] = combined_df['Mice'] + combined_df['Session'] + combined_df[f'{Osc}Number'].astype(str)\n",
    "            \n",
    "            unique_count = combined_df[f'{Osc}_ID'].nunique()\n",
    "            print(unique_count, f'{Osc} recorded in total in the {Cortex}')\n",
    "\n",
    "            filenameOut = f'{folder_to_save}/{NrSubtype}_{Osc}_{Cortex}_ABdetection_GrandGlobalAB.xlsx'\n",
    "            writer = pd.ExcelWriter(filenameOut)\n",
    "            combined_df.to_excel(writer)\n",
    "            writer.close()\n",
    "\n",
    "            ###########################################################################\n",
    "                                        ##### Before/During/After #####\n",
    "            ###########################################################################\n",
    "\n",
    "            filenameOut = f'{folder_to_save}/{NrSubtype}_{Osc}_{Cortex}_SpikeAct_BeforeDuringAfter.xlsx'          \n",
    "            excel_writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "            SpikeActivityBefore_perUnit = combined_df.groupby('Unit_ID')['SpikeActivityBefore'].sum()\n",
    "            SpikeActivityDuring_perUnit = combined_df.groupby('Unit_ID')['SpikeActivityDuring'].sum()\n",
    "            SpikeActivityAfter_perUnit = combined_df.groupby('Unit_ID')['SpikeActivityAfter'].sum()\n",
    "            \n",
    "            allSPresult = pd.concat([SpikeActivityBefore_perUnit,SpikeActivityDuring_perUnit,SpikeActivityAfter_perUnit], axis=1).rename(columns={'SpikeActivityBefore': 'Before', 'SpikeActivityDuring': 'During', 'SpikeActivityAfter': 'After'})\n",
    "            allSPresult_ActiveOnly = allSPresult.loc[~(allSPresult == 0).all(axis=1)]\n",
    "            allSPresult_ActiveOnly = allSPresult_ActiveOnly.copy()\n",
    "            allSPresult_ActiveOnly['Pref']  = allSPresult_ActiveOnly.apply(column_with_max_single_per_row, axis=1)\n",
    "            allSPresult = allSPresult.copy()\n",
    "            allSPresult['Pref']  = allSPresult.apply(column_with_max_single_per_row, axis=1)\n",
    "            CountPref=allSPresult['Pref'].value_counts()\n",
    "            CountPref_ActiveOnly=allSPresult_ActiveOnly['Pref'].value_counts()            \n",
    "            allSPresult.to_excel(excel_writer, sheet_name='Sum', index=True, header=True)\n",
    "            allSPresult_ActiveOnly.to_excel(excel_writer, sheet_name='Sum_ActiveOnly', index=True, header=True)\n",
    "\n",
    "            SpikeActivityBefore_perUnit = combined_df.groupby('Unit_ID')['SpikeActivityBefore'].mean()\n",
    "            SpikeActivityDuring_perUnit = combined_df.groupby('Unit_ID')['SpikeActivityDuring'].mean()\n",
    "            SpikeActivityAfter_perUnit = combined_df.groupby('Unit_ID')['SpikeActivityAfter'].mean()\n",
    "            \n",
    "            allSPresult = pd.concat([SpikeActivityBefore_perUnit,SpikeActivityDuring_perUnit,SpikeActivityAfter_perUnit], axis=1, keys=['Before','During', 'After'])\n",
    "            allSPresult_ActiveOnly = allSPresult.loc[~(allSPresult == 0).all(axis=1)]\n",
    "            allSPresult_ActiveOnly = allSPresult_ActiveOnly.copy()\n",
    "            allSPresult_ActiveOnly['Pref']  = allSPresult_ActiveOnly.apply(column_with_max_single_per_row, axis=1)\n",
    "            allSPresult = allSPresult.copy()\n",
    "            allSPresult['Pref']  = allSPresult.apply(column_with_max_single_per_row, axis=1)\n",
    "            CountPref2=allSPresult['Pref'].value_counts()\n",
    "            CountPref_ActiveOnly2=allSPresult_ActiveOnly['Pref'].value_counts()     \n",
    "            allSPresult.to_excel(excel_writer, sheet_name='Mean', index=True, header=True)\n",
    "            allSPresult_ActiveOnly.to_excel(excel_writer, sheet_name='Mean_ActiveOnly', index=True, header=True)\n",
    "\n",
    "            CountP=pd.concat([CountPref, CountPref_ActiveOnly,CountPref2, CountPref_ActiveOnly2], axis=1, keys=['Sum', 'Sum_ActiveOnly', 'Mean', 'Mean_ActiveOnly'])\n",
    "            CountP.to_excel(excel_writer, sheet_name='Preference', index=True, header=True)\n",
    "\n",
    "            excel_writer.close()\n",
    "\n",
    "            ###########################################################################\n",
    "                                        ##### PSTH #####\n",
    "            ###########################################################################\n",
    "\n",
    "            filenameOutAVG = f'{folder_to_save}/{NrSubtype}_{Osc}_{Cortex}_Average&SEM.xlsx'\n",
    "            excel_writerAVG = pd.ExcelWriter(filenameOutAVG)\n",
    "\n",
    "            FileNames= ['CalciumGrandAverage', 'SpikeGrandSum', 'SpikeGrandAverage',]\n",
    "            FileNamesNormalized= ['Normalized_CalciumGrandAverage', 'Normalized_SpikeGrandSum', 'Normalized_SpikeGrandAverage',]\n",
    "            dfs_per_sheet=[dfs2_per_sheet, dfs4_per_sheet, dfs3_per_sheet]\n",
    "\n",
    "            for d, df_per_sheet in enumerate(dfs_per_sheet):\n",
    "\n",
    "                FileName=FileNames[d]\n",
    "                FileNameNormalized=FileNamesNormalized[d]\n",
    "                \n",
    "                filenameOut = f'{folder_to_save}/{NrSubtype}_{Osc}_{Cortex}_ABdetection_{FileName}.xlsx'\n",
    "                excel_writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "                Array=[]\n",
    "                ArrayUn=[]\n",
    "                ArrayPre=[]\n",
    "                ArrayPost=[]\n",
    "                \n",
    "                Array=pd.DataFrame(df_per_sheet[f'All_{OscillationList[o]}'])\n",
    "                ArrayUn=pd.DataFrame(df_per_sheet[f'Uncoupled_{OscillationList[o]}'])\n",
    "                ArrayPre=pd.DataFrame(df_per_sheet[f'Precoupled_{OscillationList[o]}'])\n",
    "                ArrayPost=pd.DataFrame(df_per_sheet[f'Postcoupled_{OscillationList[o]}'])\n",
    "                \n",
    "                Array.to_excel(excel_writer, sheet_name=f'All_{OscillationList[o]}', index=True, header=False)\n",
    "                ArrayUn.to_excel(excel_writer, sheet_name=f'Uncoupled_{OscillationList[o]}', index=True, header=False)\n",
    "                ArrayPre.to_excel(excel_writer, sheet_name=f'Precoupled_{OscillationList[o]}', index=True, header=False)\n",
    "                ArrayPost.to_excel(excel_writer, sheet_name=f'Postcoupled_{OscillationList[o]}', index=True, header=False)\n",
    "\n",
    "                mArray=Array.mean(axis=0)\n",
    "                semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                mArrayUn=ArrayUn.mean(axis=0)\n",
    "                semArrayUn = stats.sem(ArrayUn, axis=0, ddof=1, nan_policy='omit')\n",
    "                icArrayUn = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayUn, axis=0) / np.sqrt(ArrayUn.shape[0]))\n",
    "                mArrayPre=ArrayPre.mean(axis=0)\n",
    "                semArrayPre = stats.sem(ArrayPre, axis=0, ddof=1, nan_policy='omit')\n",
    "                icArrayPre = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayPre, axis=0) / np.sqrt(ArrayPre.shape[0]))\n",
    "                mArrayPost=ArrayPost.mean(axis=0)\n",
    "                semArrayPost = stats.sem(ArrayPost, axis=0, ddof=1, nan_policy='omit')\n",
    "                icArrayPost = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayPost, axis=0) / np.sqrt(ArrayPost.shape[0]))\n",
    "                BigArray=[mArray,semArray,icArray , mArrayUn, semArrayUn, icArrayUn, mArrayPre, semArrayPre, icArrayPre, mArrayPost, semArrayPost, icArrayPost]\n",
    "                BigArray=pd.DataFrame(np.transpose(BigArray), columns=[f'All {Osc} Mean', f'All {Osc} SEM', f'All {Osc} IC', f'Uncoupled {Osc} Mean', f'Uncoupled {Osc} SEM',f'Uncoupled {Osc} IC', f'Postcoupled {Osc} Mean', f'Postcoupled {Osc} SEM',f'Postcoupled {Osc} IC', f'Precoupled {Osc} Mean', f'Precoupled {Osc} SEM',  f'Precoupled {Osc} IC'])\n",
    "\n",
    "                if Osc=='Spdl':\n",
    "                    \n",
    "                    ArrayGlobal=[]\n",
    "                    ArrayLocal=[]\n",
    "                    ArrayGlobal=pd.DataFrame(df_per_sheet[f'Global_Spindles'])\n",
    "                    ArrayLocal=pd.DataFrame(df_per_sheet[f'Local_Spindles'])\n",
    "\n",
    "                    ArrayGlobal.to_excel(excel_writer, sheet_name=f'Global_Spindles', index=True, header=False)\n",
    "                    ArrayLocal.to_excel(excel_writer, sheet_name=f'Local_Spindles', index=True, header=False)\n",
    "\n",
    "                    mArrayLocal=ArrayLocal.mean(axis=0)\n",
    "                    semArrayLocal = stats.sem(ArrayLocal, axis=0, ddof=1, nan_policy='omit')\n",
    "                    icArrayLocal = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayLocal, axis=0) / np.sqrt(ArrayLocal.shape[0]))\n",
    "                    mArrayGlobal=ArrayGlobal.mean(axis=0)\n",
    "                    semArrayGlobal = stats.sem(ArrayGlobal, axis=0, ddof=1, nan_policy='omit')\n",
    "                    icArrayGlobal = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayGlobal, axis=0) / np.sqrt(ArrayGlobal.shape[0]))\n",
    "                    BigArray=[mArray,semArray,icArray , mArrayUn, semArrayUn, icArrayUn, mArrayPre, semArrayPre, icArrayPre, mArrayPost, semArrayPost, icArrayPost,mArrayLocal, semArrayLocal, icArrayLocal , mArrayGlobal, semArrayGlobal, icArrayGlobal]\n",
    "                    BigArray=pd.DataFrame(np.transpose(BigArray), columns=[f'All {Osc} Mean', f'All {Osc} SEM', f'All {Osc} IC', f'Uncoupled {Osc} Mean', f'Uncoupled {Osc} SEM',f'Uncoupled {Osc} IC', f'Postcoupled {Osc} Mean', f'Postcoupled {Osc} SEM',f'Postcoupled {Osc} IC', f'Precoupled {Osc} Mean', f'Precoupled {Osc} SEM',  f'Precoupled {Osc} IC', f'Local {Osc} Mean', f'Local {Osc} SEM',f'Local {Osc} IC',f'Global {Osc} Mean', f'Global {Osc} SEM', f'Global {Osc} IC'])\n",
    "\n",
    "                BigArray.to_excel(excel_writerAVG, sheet_name=FileName, index=True, header=True)\n",
    "                excel_writer.close()\n",
    "\n",
    "                # CALCIUM traces Normalization dfs2_per_sheet\n",
    "\n",
    "                filenameOut = f'{folder_to_save}/{NrSubtype}_{Osc}_{Cortex}_ABdetection_{FileNameNormalized}.xlsx'\n",
    "                excel_writer = pd.ExcelWriter(filenameOut)\n",
    "                \n",
    "                row_sums = Array.sum(axis=1)\n",
    "                Array = Array.div(row_sums, axis=0)\n",
    "                row_sums = ArrayUn.sum(axis=1)\n",
    "                ArrayUn = ArrayUn.div(row_sums, axis=0)\n",
    "                row_sums = ArrayPre.sum(axis=1)\n",
    "                ArrayPre = ArrayPre.div(row_sums, axis=0)\n",
    "                row_sums = ArrayPost.sum(axis=1)\n",
    "                ArrayPost = ArrayPost.div(row_sums, axis=0)\n",
    "\n",
    "                Array.to_excel(excel_writer, sheet_name=f'All_{OscillationList[o]}', index=True, header=False)\n",
    "                ArrayUn.to_excel(excel_writer, sheet_name=f'Uncoupled_{OscillationList[o]}', index=True, header=False)\n",
    "                ArrayPre.to_excel(excel_writer, sheet_name=f'Precoupled_{OscillationList[o]}', index=True, header=False)\n",
    "                ArrayPost.to_excel(excel_writer, sheet_name=f'Postcoupled_{OscillationList[o]}', index=True, header=False)\n",
    "\n",
    "                mArray=Array.mean(axis=0)\n",
    "                semArray = stats.sem(Array, axis=0, ddof=1, nan_policy='omit')\n",
    "                icArray = norm.ppf((1 +  0.95) / 2) * (np.std(Array, axis=0) / np.sqrt(Array.shape[0]))\n",
    "                mArrayUn=ArrayUn.mean(axis=0)\n",
    "                semArrayUn = stats.sem(ArrayUn, axis=0, ddof=1, nan_policy='omit')\n",
    "                icArrayUn = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayUn, axis=0) / np.sqrt(ArrayUn.shape[0]))\n",
    "                mArrayPre=ArrayPre.mean(axis=0)\n",
    "                semArrayPre = stats.sem(ArrayPre, axis=0, ddof=1, nan_policy='omit')\n",
    "                icArrayPre = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayPre, axis=0) / np.sqrt(ArrayPre.shape[0]))\n",
    "                mArrayPost=ArrayPost.mean(axis=0)\n",
    "                semArrayPost = stats.sem(ArrayPost, axis=0, ddof=1, nan_policy='omit')\n",
    "                icArrayPost = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayPost, axis=0) / np.sqrt(ArrayPost.shape[0]))\n",
    "                BigArray=[mArray,semArray,icArray , mArrayUn, semArrayUn, icArrayUn, mArrayPre, semArrayPre, icArrayPre, mArrayPost, semArrayPost, icArrayPost]\n",
    "                BigArray=pd.DataFrame(np.transpose(BigArray), columns=[f'All {Osc} Mean', f'All {Osc} SEM', f'All {Osc} IC', f'Uncoupled {Osc} Mean', f'Uncoupled {Osc} SEM',f'Uncoupled {Osc} IC', f'Postcoupled {Osc} Mean', f'Postcoupled {Osc} SEM',f'Postcoupled {Osc} IC', f'Precoupled {Osc} Mean', f'Precoupled {Osc} SEM',  f'Precoupled {Osc} IC'])\n",
    "\n",
    "                if Osc=='Spdl':\n",
    "                    \n",
    "                    ArrayGlobal=[]\n",
    "                    ArrayLocal=[]\n",
    "                    ArrayGlobal=pd.DataFrame(df_per_sheet[f'Global_Spindles'])\n",
    "                    ArrayLocal=pd.DataFrame(df_per_sheet[f'Local_Spindles'])\n",
    "                    row_sums = ArrayGlobal.sum(axis=1)\n",
    "                    ArrayGlobal = ArrayGlobal.div(row_sums, axis=0)\n",
    "                    row_sums = ArrayLocal.sum(axis=1)\n",
    "                    ArrayLocal = ArrayLocal.div(row_sums, axis=0)\n",
    "\n",
    "                    ArrayGlobal.to_excel(excel_writer, sheet_name=f'Global_Spindles', index=True, header=False)\n",
    "                    ArrayLocal.to_excel(excel_writer, sheet_name=f'Local_Spindles', index=True, header=False)\n",
    "\n",
    "                    mArrayLocal=ArrayLocal.mean(axis=0)\n",
    "                    semArrayLocal = stats.sem(ArrayLocal, axis=0, ddof=1, nan_policy='omit')\n",
    "                    icArrayLocal = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayLocal, axis=0) / np.sqrt(ArrayLocal.shape[0]))\n",
    "                    mArrayGlobal=ArrayGlobal.mean(axis=0)\n",
    "                    semArrayGlobal = stats.sem(ArrayGlobal, axis=0, ddof=1, nan_policy='omit')\n",
    "                    icArrayGlobal = norm.ppf((1 +  0.95) / 2) * (np.std(ArrayGlobal, axis=0) / np.sqrt(ArrayGlobal.shape[0]))\n",
    "                    BigArray=[mArray,semArray,icArray , mArrayUn, semArrayUn, icArrayUn, mArrayPre, semArrayPre, icArrayPre, mArrayPost, semArrayPost, icArrayPost,mArrayLocal, semArrayLocal, icArrayLocal , mArrayGlobal, semArrayGlobal, icArrayGlobal]\n",
    "                    BigArray=pd.DataFrame(np.transpose(BigArray), columns=[f'All {Osc} Mean', f'All {Osc} SEM', f'All {Osc} IC', f'Uncoupled {Osc} Mean', f'Uncoupled {Osc} SEM',f'Uncoupled {Osc} IC', f'Postcoupled {Osc} Mean', f'Postcoupled {Osc} SEM',f'Postcoupled {Osc} IC', f'Precoupled {Osc} Mean', f'Precoupled {Osc} SEM',  f'Precoupled {Osc} IC', f'Local {Osc} Mean', f'Local {Osc} SEM',f'Local {Osc} IC',f'Global {Osc} Mean', f'Global {Osc} SEM', f'Global {Osc} IC'])\n",
    "\n",
    "                excel_writer.close() \n",
    "                BigArray.to_excel(excel_writerAVG, sheet_name=FileNameNormalized, index=True, header=True)\n",
    "\n",
    "            excel_writerAVG.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minian311new2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
