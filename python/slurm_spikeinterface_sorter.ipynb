{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7dda0d",
   "metadata": {},
   "source": [
    "# Spike sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fb4cdd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reAnalyse = False\n",
    "engine = \"dask\"\n",
    "GPU_available = True\n",
    "sorterFolder='kilosort4_output'\n",
    "training_folder = 'sorting_analyzer_training'\n",
    "fullAnalyzer_folder = 'sorting_analyzer_full'\n",
    "baseName = '/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd66156",
   "metadata": {},
   "source": [
    "## Set up everything\n",
    "You shouldn't have to change anything from here so you can keep that part folded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b006d50",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4c2661-565d-4949-aa45-d44200c20f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import submitit\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import asyncio\n",
    "import gc\n",
    "\n",
    "from mbTools import mbTools\n",
    "from ipyfilechooser import FileChooser\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython import get_ipython\n",
    "import IPython\n",
    "import pickleshare\n",
    "\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from distributed import Client\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e190a",
   "metadata": {},
   "source": [
    "### Define a few variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c0cf29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_extract = 2 #min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac2f4e",
   "metadata": {},
   "source": [
    "#### Structural (important for the process but no need to change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e310982",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_job=None\n",
    "sorter='kilosort4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ed711",
   "metadata": {},
   "source": [
    "### Define a few functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bbf1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_my_expe_choice(chooser):\n",
    "    currentFile = str(chooser.selected)\n",
    "    mbTools.magicstore('currentFile', currentFile)\n",
    "\n",
    "def selectData(currentFile):\n",
    "    if currentFile is not None:\n",
    "        pathName, fileName = os.path.split(currentFile)\n",
    "    else:\n",
    "        pathName = '/crnldata/waking/audrey_hay/'\n",
    "        fileName = ''\n",
    "    fc = FileChooser(path=pathName, filename=fileName, filter_pattern='NP_spikes_*.raw', select_default=True, show_only_dirs = False, title = \"<b>Select file</b>\")\n",
    "    display(fc)\n",
    "\n",
    "    # Register callback function\n",
    "    fc.register_callback(update_my_expe_choice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a4a6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magicretrieve(stored_var):\n",
    "   # myvar will contain the variable previously stored with \"%store test\"\n",
    "   myvar_filename = get_ipython().ipython_dir + '/profile_default/db/autorestore/' + stored_var\n",
    "   with open(myvar_filename, 'rb') as f:\n",
    "      return pickle.load(f)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "39b539b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateDict(rec, probe, folder, **sorter_params):\n",
    "    rec = rec.set_probe(probe)\n",
    "    si.set_global_job_kwargs(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    sorting = si.run_sorter(sorter, rec, verbose=True, folder=folder, remove_existing_folder=True, **sorter_params)\n",
    "    return sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "484a0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_analyzer(sorting,rec,probe,folder,append=False):\n",
    "    rec = rec.set_probe(probe)\n",
    "    si.set_global_job_kwargs(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    \n",
    "    if append:\n",
    "        sorting_analyzer = si.load_sorting_analyzer(folder)\n",
    "    else:\n",
    "        sorting_analyzer = si.create_sorting_analyzer(sorting, rec, sparse=True, folder=folder,overwrite=True)\n",
    "\n",
    "    sorting_analyzer.compute(\"random_spikes\", method=\"uniform\", max_spikes_per_unit=500)\n",
    "    sorting_analyzer.compute(\"waveforms\")\n",
    "    sorting_analyzer.compute(\"templates\")\n",
    "    sorting_analyzer.compute(\"noise_levels\")\n",
    "    sorting_analyzer.compute(\"unit_locations\", method=\"monopolar_triangulation\")\n",
    "    sorting_analyzer.compute(\"isi_histograms\")\n",
    "    sorting_analyzer.compute(\"correlograms\") #, window_ms=100, bin_ms=5.\n",
    "    sorting_analyzer.compute(\"principal_components\", n_components=3, mode='by_channel_global', whiten=True)\n",
    "    sorting_analyzer.compute(\"quality_metrics\", metric_names=[\"snr\", \"firing_rate\"])\n",
    "    sorting_analyzer.compute(\"template_similarity\")\n",
    "    sorting_analyzer.compute(\"spike_amplitudes\")\n",
    "\n",
    "\n",
    "    #sorting_analyzer.save_as(folder=folder, format='binary_folder')\n",
    "\n",
    "    #return sorting_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "017793bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_traces(rec):\n",
    "    # filter traces\n",
    "    rec = rec.astype('float32')\n",
    "    rec_filt = si.bandpass_filter(rec)\n",
    "    display(rec_filt)\n",
    "\n",
    "    # Remove bad channels\n",
    "    try:\n",
    "        bad_channel_ids, channel_labels = si.detect_bad_channels(rec_filt)\n",
    "        print('bad_channel_ids', bad_channel_ids)\n",
    "        rec_filt = rec_filt.remove_channels(bad_channel_ids)\n",
    "    except Exception as error:\n",
    "        print(\"could not remove bad channels because there was an error:\")\n",
    "        print(error)\n",
    "\n",
    "    # Account for the slight delays in recordings due to the fact the 384 channels are only digitilized with 32 ADCs\n",
    "    #rec_filt_shifted = si.phase_shift(rec_filt)\n",
    "\n",
    "    # Remove the common noisy events (artefacts)\n",
    "    rec_filt_ref = si.common_reference(rec_filt)\n",
    "    display(rec_filt_ref)\n",
    "\n",
    "    recording_layers = dict(\n",
    "        raw = rec,\n",
    "        filter = rec_filt,\n",
    "        #realigned = rec_filt_shifted,\n",
    "        cmr = rec_filt_ref,\n",
    "    )\n",
    "    #si.plot_traces(recording_layers, backend='ipywidgets') #, mode='line'\n",
    "\n",
    "    return recording_layers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a63688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_drift(rec, probe):\n",
    "    rec = rec.set_probe(probe)\n",
    "\n",
    "    job_kwargs = dict(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "    recording_corrected, motion, motion_info = si.correct_motion(\n",
    "            rec, preset=\"dredge\", folder=None, output_motion=True, output_motion_info=True, **job_kwargs\n",
    "        )\n",
    "    return recording_corrected, motion, motion_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "339081a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRessources():\n",
    "    # check node and CPU information\n",
    "    print(\"### Node counts: \\nA: currently in use \\B available\")\n",
    "    !sinfo -o%A\n",
    "    print(\"### CPU counts: \\nA: core currently in use \\nI: available \\nO: unavailable (maintenance, down, etc) \\nT: total\")\n",
    "    !sinfo -o%C\n",
    "    !sinfo\n",
    "\n",
    "    # check some stats of our last job\n",
    "    if last_job is not None:\n",
    "        print('### CPU time and MaxRSS of our last job (about 1000Mb should be added to your MaxRSS (Mb) in order to cover safely the memory needs of the python runtime)###')\n",
    "        os.system(f'sacct -j {last_job.job_id} --format=\"CPUTime,MaxRSS\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a24596",
   "metadata": {},
   "source": [
    "## Choose data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6dc444",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#currentFile = '/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16/NP_spikes_2024-07-22T17_55_16.raw'\n",
    "currentFile = magicretrieve('currentFile')\n",
    "selectData(currentFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8669ae",
   "metadata": {},
   "source": [
    "### Move data to /mnt/ if appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check location of file\n",
    "currentFile = magicretrieve('currentFile')\n",
    "if not currentFile.startswith('/mnt/'):\n",
    "    src = currentFile\n",
    "    raw_path = src\n",
    "    dst = os.path.join('/mnt/data/ahay',os.path.split(currentFile)[1])\n",
    "    print(f'the selected file {currentFile} is not on /mnt/')\n",
    "\n",
    "    # check if the file already exists on /mnt/\n",
    "    if os.path.isfile(dst):\n",
    "        print(f\"but {dst} already exists so making it the currentFile to use\")\n",
    "        currentFile = dst\n",
    "        mbTools.magicstore('currentFile', currentFile)\n",
    "    else:\n",
    "        print(\"and there is no version on /mnt/\")\n",
    "        shouldCopy = False # it took a while (20 min for a file of about 150Gb)\n",
    "        if shouldCopy:\n",
    "            print(f'it will be copied to {dst}')\n",
    "            startTime = time.time()\n",
    "            shutil.copyfile(src, dst)\n",
    "            print(f'the transfer is complete, it took {time.time()-startTime} seconds')\n",
    "            currentFile = dst\n",
    "            mbTools.magicstore('currentFile', currentFile)\n",
    "        else:\n",
    "            print('it can be transfered from here by changing the shouldCopy parameter but probably best not to because it takes a while and uses massive ressources')\n",
    "else:\n",
    "    print(f'the file {currentFile} is already on /mnt/ so all is well')\n",
    "    raw_path = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532274e",
   "metadata": {},
   "source": [
    "### Lazy load data and probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFile = magicretrieve('currentFile')\n",
    "\n",
    "raw_rec = si.read_binary(currentFile, dtype='uint16', num_channels=384, sampling_frequency=30_000.)\n",
    "if raw_path is not None:\n",
    "    raw_rec.annotate(raw_path = raw_path)\n",
    "display(raw_rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/crnldata/waking/audrey_hay/NPX/NPXprobe.pkl', 'rb') as outp: \n",
    "    probe = pickle.load(outp)\n",
    "probe.set_device_channel_indices(np.arange(384))\n",
    "\n",
    "raw_rec = raw_rec.set_probe(probe)\n",
    "display(si.plot_probe_map(raw_rec, with_channel_ids=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a43680",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c250e0",
   "metadata": {},
   "source": [
    "### Filter and apply common ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f39f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if engine==\"dask\":\n",
    "    # takes about 15s\n",
    "    cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"3GB\",\n",
    "                        walltime=\"00:02:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(preprocess_traces, raw_rec)\n",
    "    recording_layers = future.result() \n",
    "\n",
    "\n",
    "    #recording_layers = preprocess_traces(raw_rec)\n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    si.plot_traces(recording_layers, backend='ipywidgets') #, mode='line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b49c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if engine==\"submitit\":\n",
    "    # takes less than 10s\n",
    "    start_time = time.time()\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "    executor.update_parameters(mem_gb=3, timeout_min=2, slurm_partition=\"CPU\", cpus_per_task=4)\n",
    "    job = executor.submit(preprocess_traces, raw_rec)\n",
    "\n",
    "    # print the ID of your job\n",
    "    print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "    # await a single result\n",
    "    await job.awaitable().results()\n",
    "    print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")\n",
    "\n",
    "    last_job = job\n",
    "    recording_layers = job.result()\n",
    "\n",
    "    si.plot_traces(recording_layers, backend='ipywidgets') #, mode='line'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_filt_ref = recording_layers[\"cmr\"]\n",
    "display(rec_filt_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637e35e",
   "metadata": {},
   "source": [
    "### Correct for motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b06737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if engine==\"dask\":\n",
    "    if GPU_available: # takes about 8 minutes\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"30GB\",\n",
    "                        job_cpu=55, #should concider 1\n",
    "                        walltime=\"01:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\n",
    "                            \"dashboard_address\": \":8780\",\n",
    "                                           } #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 10 minutes\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"30GB\",\n",
    "                        job_cpu=55,\n",
    "                        walltime=\"01:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(check_drift, rec_filt_ref, probe) \n",
    "\n",
    "    recording_corrected, motion, motion_info = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(motion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab171b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if engine==\"submitit\":\n",
    "    # takes about 10 min without slurm more like 16 min with submitit\n",
    "    GPU_available = False\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "    if GPU_available:\n",
    "        executor.update_parameters(slurm_array_parallelism=40, mem_gb=16, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=2)\n",
    "        #executor.update_parameters(mem_gb=16, timeout_min=20, slurm_partition=\"GPU\", slurm_gres='gpu:1')\n",
    "        #\n",
    "    else:\n",
    "        executor.update_parameters(slurm_array_parallelism=4, mem_gb=60, timeout_min=20, slurm_partition=\"CPU\", cpus_per_task=40)\n",
    "    job = executor.submit(check_drift, rec_filt_ref, probe)\n",
    "\n",
    "    # print the ID of your job\n",
    "    print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "    # await a single result\n",
    "    await job.awaitable().results()\n",
    "    print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")\n",
    "\n",
    "    last_job = job\n",
    "    recording_corrected, motion, motion_info = job.result()\n",
    "\n",
    "    display(motion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (72) 16 min (slurm_array_parallelism=4, mem_gb=60, timeout_min=20, slurm_partition=\"CPU\", cpus_per_task=40)\n",
    "print(\"\"\"rq: you should avoid submitting multiple small tasks with submitit, which would create many independent jobs\n",
    "      and possibly overload the cluster, while you can do it without any problem through dask.distributed.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7225843",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_motion_info(motion_info, recording_corrected,\n",
    "                   color_amplitude=True,\n",
    "        amplitude_cmap=\"inferno\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9470dc2",
   "metadata": {},
   "source": [
    "## Identify spike clusters for the first few minutes of recording"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df08855",
   "metadata": {},
   "source": [
    "It is good practice to have a look at available ressources and current use of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkRessources()\n",
    "\n",
    "!sinfo --nodes=node15 -o \"%50N  %10c  %20m  %30G \"\n",
    "!squeue --partition=\"GPU\"\n",
    "\n",
    "#torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 712.00 MiB. GPU 0 has a total capacity of 79.26 GiB of which 187.19 MiB is free. Process 1619368 has 77.78 GiB memory in use. Including non-PyTorch memory, this process has 1.28 GiB memory in use. Of the allocated memory 529.55 MiB is allocated by PyTorch, and 276.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c09f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for iformation, display a list of all parameters that can be modified for the sorter\n",
    "params = si.get_default_sorter_params(sorter_name_or_class=sorter)\n",
    "print(f\"For information, parameters that are available for the sorter {sorter} are:\\n\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine==\"dask\":\n",
    "    gc.collect()\n",
    "\n",
    "    start_time = time.time()\n",
    "    rec_training = recording_corrected.frame_slice(0, 30_000 * 60 * duration_extract)\n",
    "    sorter_params=dict(\n",
    "        do_correction = False,\n",
    "        skip_kilosort_preprocessing = True # we already did it\n",
    "    )\n",
    "\n",
    "    \n",
    "    if GPU_available: # takes about 10 minutes with dask\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"4GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:10:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        #worker_extra_args=[\"--resources GPU=2\"],\n",
    "                        job_extra_directives=['--gpus=2'],\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 10 minutes\n",
    "       cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"6GB\",\n",
    "                        job_cpu=55,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(GenerateDict, rec_training, probe, sortedFolder, **sorter_params)\n",
    "    sorting = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine==\"submitit\":\n",
    "    #it takes about 90s with GPU (if available) ; 40 min otherwise\n",
    "    gc.collect()\n",
    "\n",
    "    GPU_available = True\n",
    "\n",
    "    start_time = time.time()\n",
    "    rec_training = recording_corrected.frame_slice(0, 30_000 * 60 * duration_extract)\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "    if GPU_available:\n",
    "        executor.update_parameters(mem_gb=5, timeout_min=10, slurm_partition=\"GPU\", cpus_per_task=2)\n",
    "        #executor.update_parameters(mem_gb=5, timeout_min=5, slurm_partition=\"GPU\", slurm_gres='gpu:1')\n",
    "    else:\n",
    "        executor.update_parameters(mem_gb=5, timeout_min=120, slurm_partition=\"CPU\", cpus_per_task=60)\n",
    "\n",
    "\n",
    "    # actually submit the job\n",
    "    job = executor.submit(GenerateDict, rec_training, probe)\n",
    "\n",
    "    # print the ID of your job\n",
    "    print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "    # await a single result\n",
    "    await job.awaitable().results()\n",
    "    print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")\n",
    "\n",
    "    last_job = job\n",
    "    sorting = job.result()\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d277d8c6-e2e1-46e1-8dee-4424d98675d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kilosort4 run time 2212.34s for 8Gb 10cpus num1 (15.74, 15.42, 1.49, 2.11)\n",
    "#100%|██████████| 60/60 [39:44<00:00, 39.74s/it] 8/10 python\n",
    "\n",
    "#32%|███▏      | 19/60 [09:26<19:40, 28.78s/it] 8/30 submitit\n",
    "#32%|███▏      | 19/60 [09:13<19:55, 29.16s/it] 16/30 submitit\n",
    "#60%|██████    | 36/60 [12:10<07:36, 19.02s/it] 5/30 submitit\n",
    "#23%|██▎       | 14/60 [10:14<32:55, 42.95s/it] 5/10 submitit\n",
    "#42%|████▏     | 25/60 [06:35<07:23, 12.66s/it] 5/50 submitit\n",
    "#33%|███▎      | 20/60 [05:32<10:29, 15.75s/it] 5/50 submitit data in mnt\n",
    "\n",
    "\n",
    "#GPU\n",
    "#job completed: 33972 returned in 110.73936009407043 seconds 5/50\n",
    "#job completed: 33973 returned in 94.93399000167847 seconds 5/10\n",
    "#job completed: 33975 returned in 93.79518842697144 seconds 5/2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee34b754",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "file_path=\"kilosort4_output/spikeinterface_recording.pickle\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    d = pickle.load(f)\n",
    "\n",
    "for key in d[\"kwargs\"]:\n",
    "#for key in d:\n",
    "    print(key)\n",
    "\n",
    "print(d[\"kwargs\"][\"parent_recording\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cf455d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the previous folder kilosort4_output was found, importing the data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>KiloSortSortingExtractor: 255 units - 1 segments - 30.0kHz</strong></div><details style='margin-left: 10px;'>  <summary><strong>Unit IDs</strong></summary><ul>[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
       "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
       "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
       "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
       "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
       "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
       " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
       " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
       " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
       " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
       " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
       " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
       " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
       " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
       " 252 253 254] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> phy_folder </strong>: /home/audrey.hay/HayLabAnalysis/python/kilosort4_output/sorter_output</li><li> <strong> __sorting_info__ </strong>: {'recording': None, 'params': {'sorter_name': 'kilosort4', 'sorter_params': {'batch_size': 60000, 'nblocks': 1, 'Th_universal': 9, 'Th_learned': 8, 'do_CAR': True, 'invert_sign': False, 'nt': 61, 'shift': None, 'scale': None, 'artifact_threshold': None, 'nskip': 25, 'whitening_range': 32, 'highpass_cutoff': 300, 'binning_depth': 5, 'sig_interp': 20, 'drift_smoothing': [0.5, 0.5, 0.5], 'nt0min': None, 'dmin': None, 'dminx': 32, 'min_template_size': 10, 'template_sizes': 5, 'nearest_chans': 10, 'nearest_templates': 100, 'max_channel_distance': None, 'templates_from_data': True, 'n_templates': 6, 'n_pcs': 6, 'Th_single_ch': 6, 'acg_threshold': 0.2, 'ccg_threshold': 0.25, 'cluster_downsampling': 20, 'cluster_pcs': 64, 'x_centers': None, 'duplicate_spike_ms': 0.25, 'scaleproc': None, 'save_preprocessed_copy': False, 'torch_device': 'auto', 'bad_channels': None, 'clear_cache': False, 'save_extra_vars': False, 'do_correction': False, 'keep_good_only': False, 'skip_kilosort_preprocessing': True, 'use_binary_file': None, 'delete_recording_dat': True}}, 'log': {'sorter_name': 'kilosort4', 'sorter_version': '4.0.17', 'datetime': '2024-09-19T11:07:59.925383', 'runtime_trace': [], 'error': False, 'run_time': 357.914842184633}}</li></details><details style='margin-left: 10px;'><summary><strong>Unit Properties</strong></summary><ul><details><summary><strong>original_cluster_id</strong></summary>[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
       "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
       "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
       "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
       "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
       "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
       " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
       " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
       " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
       " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
       " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
       " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
       " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
       " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
       " 252 253 254]</details><details><summary><strong>KSLabel</strong></summary>['mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'good' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'good' 'good'\n",
       " 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'good' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'good' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua'\n",
       " 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua']</details><details><summary><strong>Amplitude</strong></summary>[ 107.5  109.1  851.2  154.6  126.4  117.6  229.7  242.8  132.4  122.9\n",
       "  124.6  118.4  255.9  125.4 1010.6  744.5  633.5  799.2  126.1  128.5\n",
       "  125.1  137.5  130.6  129.7  372.3  285.8  390.9  491.6  184.6  114.3\n",
       "  132.1  109.6  439.2  104.   113.2  455.6  118.4  123.7  118.6  190.\n",
       "  124.6  104.   125.8  168.1  127.7  130.9  137.   111.7  116.2   97.1\n",
       "   99.6  118.6  829.7  242.1  102.4  319.3  251.8   99.3  283.8  868.4\n",
       "  385.6  100.5  251.9  319.7  120.5  235.   140.1  275.5  278.   191.5\n",
       "  125.7  233.6  405.6   93.3   99.5  183.   463.8  215.7  103.7  100.7\n",
       "  104.1  105.4  109.   112.6  112.1  112.2  116.7  267.6  273.6  102.5\n",
       "  404.8   97.3  405.4  480.6  110.2  108.3  107.9  117.5  117.   500.9\n",
       "  112.6  224.2  108.6  567.7  543.   169.8  133.   227.6  113.   120.5\n",
       "  159.5  119.5  324.5  108.4   99.7  122.3  109.1   84.6   91.9   84.3\n",
       "   70.6   69.5   73.2   72.8   72.3   84.    84.6   81.5   77.1   99.6\n",
       "   83.5   99.2   92.   105.    96.8   98.2  313.6   92.7   84.3   83.4\n",
       "   96.5   77.5   81.1  156.3   87.4   84.5   77.7  167.3   79.6   95.3\n",
       "   74.7   79.1   77.2   71.7   73.6   74.8   68.5   70.7   72.7   70.9\n",
       "   70.6   77.9   75.8   73.5   72.8   78.2   74.3   74.3   72.6   76.\n",
       "   75.3  101.    79.6   79.9   91.7   77.2   79.8   90.7   79.3  107.4\n",
       "   95.7  397.7  267.6  305.7  281.7  100.7  120.3  102.5   92.3   96.6\n",
       "  154.5   99.2  111.7   97.5  202.1  166.6  305.5   99.4  498.1   93.\n",
       "   98.9  200.5   81.2   93.7   71.    75.7   65.3   66.    63.2   65.4\n",
       "   64.1   62.9   62.9   62.5   62.    62.    61.9   62.6   62.8   62.5\n",
       "   62.6   63.7   62.4    3.9    6.8    4.6    4.     5.3   64.    65.\n",
       "   22.9    6.2    7.5   63.7   46.6   63.7   47.9   46.7   70.4   63.2\n",
       "    6.2   11.8   88.    21.7   11.5   79.9   76.5   83.3   86.4   86.5\n",
       "   84.9   70.4   91.6    4.7  122.8]</details><details><summary><strong>ContamPct</strong></summary>[101.3 109.3  28.6  83.   98.6 115.3   0.   94.4 107.5 100.1 112.2 108.1\n",
       "   0.  110.6   0.    0.   10.7   8.6 126.3 115.  124.2  99.8 108.8 106.5\n",
       "  55.2  81.6   0.    0.   86.8 102.8 103.7 113.8   0.  106.2 104.7  23.\n",
       " 107.2  85.1 105.9  79.3 106.2 105.  106.   94.7 106.1 111.8  77.7 102.8\n",
       " 107.6  95.5 104.5  87.8   0.    0.   97.5   0.    0.  101.8   0.    0.\n",
       "  46.   90.1   0.    0.   95.8   0.   76.    0.    0.    0.   57.8   0.\n",
       "   0.  103.8  69.2   0.    0.    0.   89.6 101.7  94.7 103.  104.6 103.5\n",
       " 100.9  84.1  81.7  80.9   0.   92.4   0.   95.3   0.   28.2 103.2 101.3\n",
       " 102.1  85.4  94.4  54.4 101.9  81.4 102.7   7.7   0.   94.7 101.1 102.6\n",
       " 104.9 104.9  91.8 101.9  18.  104.   96.4  71.7  82.3 107.   96.5  49.8\n",
       "  75.1 115.1  53.1 107.2  96.5  75.8 118.9 133.8 131.  110.  139.4 117.\n",
       "  89.8  78.1  86.5 122.1   0.  105.  108.8 171.   88.9  44.5 123.9   3.9\n",
       "  24.7 105.9  79.1   3.  110.6  88.6 108.4  90.9  86.6  88.9  58.8  48.9\n",
       "  54.7  84.4  77.8  92.8  75.5  57.1  37.5  84.1  41.9  91.6  67.   92.2\n",
       "  83.6  86.5  82.9   3.1  50.3 115.9  56.6  79.4 119.  107.3 133.4 121.4\n",
       "  88.2  34.3 101.7  45.4  91.4 131.9 168.8 148.1  56.7  33.2 138.7  43.5\n",
       "  46.5  35.9   0.  106.4  62.8 134.6   3.2 121.7 141.4   0.  169.1 115.6\n",
       " 121.3 120.6  91.4  80.    0.   77.1  60.2 121.2  85.8  93.5  29.9 128.3\n",
       "  53.7 120.9 114.3  54.5  91.9  80.  117.4   0.    0.  105.3  84.6  98.9\n",
       " 101.3  76.8   0.  131.1   0.  162.2   0.    0.   98.   82.1 155.6  67.\n",
       "  65.1 126.4   0.   81.5  66.7   0.  108.6  88.4  29.6 148.1  87.8   0.\n",
       "  65.   83.6   0. ]</details><details><summary><strong>KSLabel_repeat</strong></summary>['mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'good' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'good' 'good'\n",
       " 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'good' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'good' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua'\n",
       " 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua']</details></ul></details>"
      ],
      "text/plain": [
       "KiloSortSortingExtractor: 255 units - 1 segments - 30.0kHz"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not reAnalyse:\n",
    "    if os.path.isdir(sorterFolder):\n",
    "        # directory exists\n",
    "        print(f\"the previous folder {sorterFolder} was found, importing the data\")\n",
    "        sorting = si.read_sorter_folder(sorterFolder)\n",
    "        display(sorting)\n",
    "    else:\n",
    "        print(f\"the folder {sorterFolder} does not exist ; make sure of the path or reAnalyse the data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ff5c7",
   "metadata": {},
   "source": [
    "## Cure the clusters\n",
    "Here you should ensure that you are happy with the clusters that were found. For that, you should first compute analyzis for the training clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037ccfe",
   "metadata": {},
   "source": [
    "### Fast initial curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cebbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sorting)\n",
    "sorting = si.remove_duplicated_spikes(sorting=sorting)\n",
    "sorting = si.remove_excess_spikes(sorting=sorting, recording=recording_corrected)\n",
    "display(sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfff988",
   "metadata": {},
   "source": [
    "### Construct analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c139bb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -e si_dask_logs/dask-worker-%J.err\n",
      "#SBATCH -o si_dask_logs/dask-worker-%J.out\n",
      "#SBATCH -p CPU\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=40\n",
      "#SBATCH --mem=56G\n",
      "#SBATCH -t 02:00:00\n",
      "\n",
      "/home/audrey.hay/HayLabAnalysis/.si-env/bin/python -m distributed.cli.dask_worker tcp://10.69.168.93:37113 --name dummy-name --nthreads 1 --memory-limit 55.88GiB --no-nanny --death-timeout 60\n",
      "\n",
      "job done in 27.189473628997803 s\n"
     ]
    }
   ],
   "source": [
    "reAnalyse=True\n",
    "GPU_available=False\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    gc.collect()\n",
    "    \n",
    "    if GPU_available: # takes about 10 minutes with dask\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"70GB\",\n",
    "                        job_cpu=70,\n",
    "                        walltime=\"00:20:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        #worker_extra_args=[\"--resources GPU=2\"],\n",
    "                        job_extra_directives=['--gpus=2'],\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 10 minutes\n",
    "       cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"60GB\",\n",
    "                        job_cpu=40,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(compute_analyzer, sorting, rec_training, probe, training_folder) #, append=True) # uncomment to redo only a few analysis\n",
    "    future.result()\n",
    "    #sorting_analyzer_training = future.results() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    #display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4112693",
   "metadata": {},
   "source": [
    "Now, you have 2 options:\n",
    "- Either go back to local computer for full benefice of spikeinterface_gui\n",
    "1. First, copy the sorting_analyzer_training folder to crnldata ([see next cell](#download))\n",
    "1. Then, go on a local (not over ssh) script at [the most interactive viewing part](#local) at the end of this notebook, reload the sorting_analyzer older, and visualize everything on a gui.\n",
    "1. Finally, when you are happy with the spike clusters, you can upload it back to the crnl cluster to proceed with [full sorting](#sort-full-recording)\n",
    "- Or use [the following embedded plotting widgets](#widgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efe0c4",
   "metadata": {},
   "source": [
    "### Option1: go back to local PC\n",
    "<a id='download'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ec648099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job done in 4.955073356628418 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='border:1px solid #ddd; padding:10px;'><strong>KiloSortSortingExtractor: 255 units - 1 segments - 30.0kHz</strong></div><details style='margin-left: 10px;'>  <summary><strong>Unit IDs</strong></summary><ul>[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
       "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
       "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
       "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
       "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
       "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
       " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
       " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
       " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
       " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
       " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
       " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
       " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
       " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
       " 252 253 254] </details><details style='margin-left: 10px;'>  <summary><strong>Annotations</strong></summary><ul><li> <strong> phy_folder </strong>: /home/audrey.hay/HayLabAnalysis/python/kilosort4_output/sorter_output</li><li> <strong> __sorting_info__ </strong>: {'recording': None, 'params': {'sorter_name': 'kilosort4', 'sorter_params': {'batch_size': 60000, 'nblocks': 1, 'Th_universal': 9, 'Th_learned': 8, 'do_CAR': True, 'invert_sign': False, 'nt': 61, 'shift': None, 'scale': None, 'artifact_threshold': None, 'nskip': 25, 'whitening_range': 32, 'highpass_cutoff': 300, 'binning_depth': 5, 'sig_interp': 20, 'drift_smoothing': [0.5, 0.5, 0.5], 'nt0min': None, 'dmin': None, 'dminx': 32, 'min_template_size': 10, 'template_sizes': 5, 'nearest_chans': 10, 'nearest_templates': 100, 'max_channel_distance': None, 'templates_from_data': True, 'n_templates': 6, 'n_pcs': 6, 'Th_single_ch': 6, 'acg_threshold': 0.2, 'ccg_threshold': 0.25, 'cluster_downsampling': 20, 'cluster_pcs': 64, 'x_centers': None, 'duplicate_spike_ms': 0.25, 'scaleproc': None, 'save_preprocessed_copy': False, 'torch_device': 'auto', 'bad_channels': None, 'clear_cache': False, 'save_extra_vars': False, 'do_correction': False, 'keep_good_only': False, 'skip_kilosort_preprocessing': True, 'use_binary_file': None, 'delete_recording_dat': True}}, 'log': {'sorter_name': 'kilosort4', 'sorter_version': '4.0.17', 'datetime': '2024-09-19T11:07:59.925383', 'runtime_trace': [], 'error': False, 'run_time': 357.914842184633}}</li></details><details style='margin-left: 10px;'><summary><strong>Unit Properties</strong></summary><ul><details><summary><strong>original_cluster_id</strong></summary>[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
       "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
       "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
       "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
       "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
       "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
       " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
       " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
       " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
       " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
       " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
       " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
       " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
       " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
       " 252 253 254]</details><details><summary><strong>KSLabel</strong></summary>['mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'good' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'good' 'good'\n",
       " 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'good' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'good' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua'\n",
       " 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua']</details><details><summary><strong>Amplitude</strong></summary>[ 107.5  109.1  851.2  154.6  126.4  117.6  229.7  242.8  132.4  122.9\n",
       "  124.6  118.4  255.9  125.4 1010.6  744.5  633.5  799.2  126.1  128.5\n",
       "  125.1  137.5  130.6  129.7  372.3  285.8  390.9  491.6  184.6  114.3\n",
       "  132.1  109.6  439.2  104.   113.2  455.6  118.4  123.7  118.6  190.\n",
       "  124.6  104.   125.8  168.1  127.7  130.9  137.   111.7  116.2   97.1\n",
       "   99.6  118.6  829.7  242.1  102.4  319.3  251.8   99.3  283.8  868.4\n",
       "  385.6  100.5  251.9  319.7  120.5  235.   140.1  275.5  278.   191.5\n",
       "  125.7  233.6  405.6   93.3   99.5  183.   463.8  215.7  103.7  100.7\n",
       "  104.1  105.4  109.   112.6  112.1  112.2  116.7  267.6  273.6  102.5\n",
       "  404.8   97.3  405.4  480.6  110.2  108.3  107.9  117.5  117.   500.9\n",
       "  112.6  224.2  108.6  567.7  543.   169.8  133.   227.6  113.   120.5\n",
       "  159.5  119.5  324.5  108.4   99.7  122.3  109.1   84.6   91.9   84.3\n",
       "   70.6   69.5   73.2   72.8   72.3   84.    84.6   81.5   77.1   99.6\n",
       "   83.5   99.2   92.   105.    96.8   98.2  313.6   92.7   84.3   83.4\n",
       "   96.5   77.5   81.1  156.3   87.4   84.5   77.7  167.3   79.6   95.3\n",
       "   74.7   79.1   77.2   71.7   73.6   74.8   68.5   70.7   72.7   70.9\n",
       "   70.6   77.9   75.8   73.5   72.8   78.2   74.3   74.3   72.6   76.\n",
       "   75.3  101.    79.6   79.9   91.7   77.2   79.8   90.7   79.3  107.4\n",
       "   95.7  397.7  267.6  305.7  281.7  100.7  120.3  102.5   92.3   96.6\n",
       "  154.5   99.2  111.7   97.5  202.1  166.6  305.5   99.4  498.1   93.\n",
       "   98.9  200.5   81.2   93.7   71.    75.7   65.3   66.    63.2   65.4\n",
       "   64.1   62.9   62.9   62.5   62.    62.    61.9   62.6   62.8   62.5\n",
       "   62.6   63.7   62.4    3.9    6.8    4.6    4.     5.3   64.    65.\n",
       "   22.9    6.2    7.5   63.7   46.6   63.7   47.9   46.7   70.4   63.2\n",
       "    6.2   11.8   88.    21.7   11.5   79.9   76.5   83.3   86.4   86.5\n",
       "   84.9   70.4   91.6    4.7  122.8]</details><details><summary><strong>ContamPct</strong></summary>[101.3 109.3  28.6  83.   98.6 115.3   0.   94.4 107.5 100.1 112.2 108.1\n",
       "   0.  110.6   0.    0.   10.7   8.6 126.3 115.  124.2  99.8 108.8 106.5\n",
       "  55.2  81.6   0.    0.   86.8 102.8 103.7 113.8   0.  106.2 104.7  23.\n",
       " 107.2  85.1 105.9  79.3 106.2 105.  106.   94.7 106.1 111.8  77.7 102.8\n",
       " 107.6  95.5 104.5  87.8   0.    0.   97.5   0.    0.  101.8   0.    0.\n",
       "  46.   90.1   0.    0.   95.8   0.   76.    0.    0.    0.   57.8   0.\n",
       "   0.  103.8  69.2   0.    0.    0.   89.6 101.7  94.7 103.  104.6 103.5\n",
       " 100.9  84.1  81.7  80.9   0.   92.4   0.   95.3   0.   28.2 103.2 101.3\n",
       " 102.1  85.4  94.4  54.4 101.9  81.4 102.7   7.7   0.   94.7 101.1 102.6\n",
       " 104.9 104.9  91.8 101.9  18.  104.   96.4  71.7  82.3 107.   96.5  49.8\n",
       "  75.1 115.1  53.1 107.2  96.5  75.8 118.9 133.8 131.  110.  139.4 117.\n",
       "  89.8  78.1  86.5 122.1   0.  105.  108.8 171.   88.9  44.5 123.9   3.9\n",
       "  24.7 105.9  79.1   3.  110.6  88.6 108.4  90.9  86.6  88.9  58.8  48.9\n",
       "  54.7  84.4  77.8  92.8  75.5  57.1  37.5  84.1  41.9  91.6  67.   92.2\n",
       "  83.6  86.5  82.9   3.1  50.3 115.9  56.6  79.4 119.  107.3 133.4 121.4\n",
       "  88.2  34.3 101.7  45.4  91.4 131.9 168.8 148.1  56.7  33.2 138.7  43.5\n",
       "  46.5  35.9   0.  106.4  62.8 134.6   3.2 121.7 141.4   0.  169.1 115.6\n",
       " 121.3 120.6  91.4  80.    0.   77.1  60.2 121.2  85.8  93.5  29.9 128.3\n",
       "  53.7 120.9 114.3  54.5  91.9  80.  117.4   0.    0.  105.3  84.6  98.9\n",
       " 101.3  76.8   0.  131.1   0.  162.2   0.    0.   98.   82.1 155.6  67.\n",
       "  65.1 126.4   0.   81.5  66.7   0.  108.6  88.4  29.6 148.1  87.8   0.\n",
       "  65.   83.6   0. ]</details><details><summary><strong>KSLabel_repeat</strong></summary>['mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'good' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'good' 'good'\n",
       " 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'good' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'good' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua'\n",
       " 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua'\n",
       " 'mua' 'mua' 'good' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua'\n",
       " 'good' 'mua' 'mua' 'good' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good'\n",
       " 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'mua' 'good' 'mua' 'mua' 'mua']</details></ul></details>"
      ],
      "text/plain": [
       "KiloSortSortingExtractor: 255 units - 1 segments - 30.0kHz"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# copy initial sorting to crnldata for viewing\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    #it takes about 10s\n",
    "\n",
    "    # takes about 10 minutes with dask\n",
    "    cluster = SLURMCluster(cores=1,\n",
    "                        memory=\"1GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:05:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    src=training_folder\n",
    "    dst=os.path.join(baseName,src)\n",
    "    start_time = time.time()\n",
    "    future = client.submit(shutil.copytree, src, dst) \n",
    "    _ = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a0cdd",
   "metadata": {},
   "source": [
    "**Here is when you should work locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ce41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import back sorting_analyzer\n",
    "# reAnalyse = True\n",
    "if reAnalyse and engine==\"dask\":\n",
    "    #it takes about 10s\n",
    "\n",
    "    # takes about 10 minutes with dask\n",
    "    cluster = SLURMCluster(cores=1,\n",
    "                        memory=\"1GB\",\n",
    "                        job_cpu=1,\n",
    "                        walltime=\"00:05:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    dst=training_folder\n",
    "    src=os.path.join(baseName,dst)\n",
    "    start_time = time.time()\n",
    "    future = client.submit(shutil.copytree, src, dst) \n",
    "    _ = future.result() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    display(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7a2477c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae12783",
   "metadata": {},
   "source": [
    "### Option2: inline visualisation\n",
    "<a id='widgets'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3241794",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_analyzer_training = si.load_sorting_analyzer(\"sorting_analyzer_training\")\n",
    "display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cbe8fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few ids\n",
    "#unit_ids=[1, 2, 5]\n",
    "unit_ids=sorting_analyzer_training.unit_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_unit_templates(sorting_analyzer_training, unit_ids=unit_ids, backend=\"ipywidgets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "97227a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few ids\n",
    "unit_ids=[1, 2, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14860987",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_rasters(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    si.plot_isi_distribution(sorting_analyzer_training,unit_ids=unit_ids)\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628e747",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_autocorrelograms(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389668da",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_crosscorrelograms(sorting_analyzer_training, unit_ids=unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c822e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.plot_unit_presence(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ca0a6",
   "metadata": {},
   "source": [
    "## Sort full recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d403bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine==\"dask\":\n",
    "    gc.collect()\n",
    "    \n",
    "    if GPU_available: # takes about 10 minutes with dask\n",
    "        cluster = SLURMCluster(\n",
    "                        queue='GPU',\n",
    "                        cores=1,\n",
    "                        memory=\"70GB\",\n",
    "                        job_cpu=70,\n",
    "                        walltime=\"00:20:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=40, # seems to divide ressources\n",
    "                        #worker_extra_args=[\"--resources GPU=2\"],\n",
    "                        job_extra_directives=['--gpus=2'],\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "    else: # takes about 10 minutes\n",
    "       cluster = SLURMCluster(\n",
    "                        queue='CPU',\n",
    "                        cores=1,\n",
    "                        memory=\"6GB\",\n",
    "                        job_cpu=55,\n",
    "                        walltime=\"02:00:00\",\n",
    "                        log_directory=\"si_dask_logs\",\n",
    "                        nanny=False,\n",
    "                        n_workers=1, # seems to divide ressources\n",
    "                        scheduler_options={\"dashboard_address\": \":8780\"} #port 8787 already used by jupyter\n",
    "                        )\n",
    "       \n",
    "    cluster.scale(1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "    print(cluster.job_script()) \n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    future = client.submit(compute_analyzer, sorting, recording_corrected, probe, fullAnalyzer_folder)\n",
    "    future.result()\n",
    "    #sorting_analyzer_training = future.results() \n",
    "    print(f\"job done in {time.time()- start_time} s\")\n",
    "\n",
    "    # Close cluster\n",
    "    client.close()\n",
    "    cluster.close()\n",
    "\n",
    "    #display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adef6f8-a103-40aa-a640-8ad538b056ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reAnalyse and engine=='submitit':\n",
    "    start_time = time.time()\n",
    "\n",
    "    executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "    #executor.update_parameters(slurm_array_parallelism=2, mem_gb=30, timeout_min=10, slurm_partition=\"CPU\", cpus_per_task=50)\n",
    "    executor.update_parameters(mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70) #cpus_per_task\n",
    "\n",
    "    # actually submit the job\n",
    "    job = executor.submit(compute_analyzer, sorting, recording_corrected, probe, fullAnalyzer_folder)\n",
    "\n",
    "    # print the ID of your job\n",
    "    print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "    # await a single result\n",
    "    await job.awaitable().results()\n",
    "    print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a42b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#job 34074 completed in 408.1813361644745 second (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=50)\n",
    "#job 34078 completed in 437.409494638443 seconds (slurm_array_parallelism=3, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=50)\n",
    "#job 34081 completed in 423.37460565567017 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", slurm_gres=\"gpu:2\", cpus_per_task=50)\n",
    "#job 34085 completed in 367.0000305175781 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70)\n",
    "#job 34089 completed in 370.1982145309448 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=80)\n",
    "#job 34093 completed in 355.1876621246338 seconds (mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70)\n",
    "\n",
    "last_job = job\n",
    "checkRessources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not reAnalyse:\n",
    "    print(\"not running analysis but loading previous one\")\n",
    "    sorting_analyzer = si.load_sorting_analyzer(fullAnalyzer_folder)\n",
    "    display(sorting_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.export_report(sorting_analyzer=sorting_analyzer,output_folder='report')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2da484",
   "metadata": {},
   "source": [
    "# Most interactive viewing on local\n",
    "<a id='local'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes 13s\n",
    "sorting_analyzer_training = si.load_sorting_analyzer(os.path.join('//10.69.168.1',baseName,training_folder))\n",
    "display(sorting_analyzer_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061be488",
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui qt\n",
    "si.plot_sorting_summary(sorting_analyzer_training, backend=\"spikeinterface_gui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0ee0a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
