{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e4c2661-565d-4949-aa45-d44200c20f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spikeinterface.full as si\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import submitit\n",
    "from memory_profiler import memory_usage\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import asyncio\n",
    "import gc\n",
    "\n",
    "\n",
    "last_job=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cf29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_extract = 2 #min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e6843e-de88-4d73-998b-65d5d46296c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stabilisation\n",
    "file = \"/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-29-40/NP_spikes_2024-07-22T17_29_40.raw\"\n",
    "\n",
    "\n",
    "# vrai enregisstrement\n",
    "file = \"/crnldata/waking/audrey_hay/NPX/NPX1/VB/Expe_2024-07-22_17-55-16/NP_spikes_2024-07-22T17_55_16.raw\"\n",
    "\n",
    "file = \"/mnt/data/ahay/NP_spikes_2024-07-22T17_55_16.raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b539b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateDict(file, duration_extract):\n",
    "    dirpath = os.path.join(os.getcwd(), 'kilosort4_output')\n",
    "    if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "        shutil.rmtree(dirpath)\n",
    "        print(f'{dirpath} existed so it was deleted')\n",
    "    \n",
    "    with open('/crnldata/waking/audrey_hay/NPX/NPXprobe.pkl', 'rb') as outp: \n",
    "        probe = pickle.load(outp)\n",
    "    probe.set_device_channel_indices(np.arange(384))\n",
    "\n",
    "    raw_rec = si.read_binary(file, dtype='uint16', num_channels=384, sampling_frequency=30_000.)\n",
    "    raw_rec = raw_rec.set_probe(probe)\n",
    "    raw_rec = raw_rec.frame_slice(0, 30_000 * 60 * duration_extract)\n",
    "\n",
    "    sorting = si.run_sorter('kilosort4', raw_rec, verbose=False)\n",
    "    return sorting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0705378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runFullSpikeSorting(file, sorting):\n",
    "    dirpath = os.path.join(os.getcwd(), 'sorting_analyzer_demo_K')\n",
    "    if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "        shutil.rmtree(dirpath)\n",
    "        print(f'{dirpath} existed so it was deleted')\n",
    "\n",
    "    with open('/crnldata/waking/audrey_hay/NPX/NPXprobe.pkl', 'rb') as outp: \n",
    "        probe = pickle.load(outp)\n",
    "    probe.set_device_channel_indices(np.arange(384))\n",
    "\n",
    "    raw_rec = si.read_binary(file, dtype='uint16', num_channels=384, sampling_frequency=30_000.)\n",
    "    raw_rec = raw_rec.set_probe(probe)\n",
    "\n",
    "    rec = raw_rec.astype('float32')\n",
    "    rec = si.bandpass_filter(rec)\n",
    "    rec = si.common_reference(rec)\n",
    "    rec.get_dtype()\n",
    "\n",
    "    si.set_global_job_kwargs(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "\n",
    "    sorting_analyzer = si.create_sorting_analyzer(sorting, rec, sparse=True)\n",
    "\n",
    "    job_kwargs = dict(n_jobs=40, progress_bar=True, chunk_duration=\"1s\")\n",
    "\n",
    "    sorting_analyzer.compute(\"random_spikes\", method=\"uniform\", max_spikes_per_unit=500)\n",
    "    sorting_analyzer.compute(\"waveforms\", **job_kwargs)\n",
    "    sorting_analyzer.compute(\"templates\", **job_kwargs)\n",
    "    sorting_analyzer.compute(\"noise_levels\")\n",
    "    sorting_analyzer.compute(\"unit_locations\", method=\"monopolar_triangulation\")\n",
    "    sorting_analyzer.compute(\"isi_histograms\")\n",
    "    sorting_analyzer.compute(\"correlograms\", window_ms=100, bin_ms=5.)\n",
    "    sorting_analyzer.compute(\"principal_components\", n_components=3, mode='by_channel_global', whiten=True, **job_kwargs)\n",
    "    sorting_analyzer.compute(\"quality_metrics\", metric_names=[\"snr\", \"firing_rate\"])\n",
    "    sorting_analyzer.compute(\"template_similarity\")\n",
    "    sorting_analyzer.compute(\"spike_amplitudes\", **job_kwargs)\n",
    "\n",
    "\n",
    "    sorting_analyzer.save_as(folder='./sorting_analyzer_demo_K', format='binary_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "339081a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRessources():\n",
    "    # check node and CPU information\n",
    "    print(\"### Node counts: \\nA: currently in use \\B available\")\n",
    "    !sinfo -o%A\n",
    "    print(\"### CPU counts: \\nA: core currently in use \\nI: available \\nO: unavailable (maintenance, down, etc) \\nT: total\")\n",
    "    !sinfo -o%C\n",
    "    !sinfo\n",
    "\n",
    "    # check some stats of our last job\n",
    "    if last_job is not None:\n",
    "        print('### CPU time and MaxRSS of our last job (about 1000Mb should be added to your MaxRSS (Mb) in order to cover safely the memory needs of the python runtime)###')\n",
    "        os.system(f'sacct -j {last_job.job_id} --format=\"CPUTime,MaxRSS\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9470dc2",
   "metadata": {},
   "source": [
    "## Sort spikes for the first few minutes of recording"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df08855",
   "metadata": {},
   "source": [
    "It is good practice to have a look at available ressources and current use of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkRessources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a70c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it takes about 90s\n",
    "gc.collect()\n",
    "start_time = time.time()\n",
    "\n",
    "executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "#executor.update_parameters(mem_gb=5, timeout_min=5, slurm_partition=\"CPU\", cpus_per_task=50)\n",
    "executor.update_parameters(mem_gb=5, timeout_min=5, slurm_partition=\"GPU\", cpus_per_task=2)\n",
    "\n",
    "# actually submit the job\n",
    "job = executor.submit(GenerateDict, file, duration_extract)\n",
    "\n",
    "# print the ID of your job\n",
    "print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "# await a single result\n",
    "await job.awaitable().results()\n",
    "print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")\n",
    "\n",
    "last_job = job\n",
    "sorting = job.result()\n",
    "print(sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277d8c6-e2e1-46e1-8dee-4424d98675d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kilosort4 run time 2212.34s for 8Gb 10cpus num1 (15.74, 15.42, 1.49, 2.11)\n",
    "#100%|██████████| 60/60 [39:44<00:00, 39.74s/it] 8/10 python\n",
    "\n",
    "#32%|███▏      | 19/60 [09:26<19:40, 28.78s/it] 8/30 submitit\n",
    "#32%|███▏      | 19/60 [09:13<19:55, 29.16s/it] 16/30 submitit\n",
    "#60%|██████    | 36/60 [12:10<07:36, 19.02s/it] 5/30 submitit\n",
    "#23%|██▎       | 14/60 [10:14<32:55, 42.95s/it] 5/10 submitit\n",
    "#42%|████▏     | 25/60 [06:35<07:23, 12.66s/it] 5/50 submitit\n",
    "#33%|███▎      | 20/60 [05:32<10:29, 15.75s/it] 5/50 submitit data in mnt\n",
    "\n",
    "\n",
    "#GPU\n",
    "#job completed: 33972 returned in 110.73936009407043 seconds 5/50\n",
    "#job completed: 33973 returned in 94.93399000167847 seconds 5/10\n",
    "#job completed: 33975 returned in 93.79518842697144 seconds 5/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ff5c7",
   "metadata": {},
   "source": [
    "## Cure the clusters\n",
    "Here you should ensure that yopu are happy with the clusters that were found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ca0a6",
   "metadata": {},
   "source": [
    "## Sort full recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d9b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorting)\n",
    "\n",
    "start_time = time.time()\n",
    "mem_usage=memory_usage((runFullSpikeSorting,(file,sorting)))\n",
    "end_time = time.time()\n",
    "print('Maximum memory usage (in MB): %s' % max(mem_usage))\n",
    "print('Maximum memory usage (in GB): %s' % (max(mem_usage)/1000))\n",
    "print('Time taken (in s): %s' % (end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adef6f8-a103-40aa-a640-8ad538b056ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "executor = submitit.AutoExecutor(folder=os.getcwd()+'/si_logs/')\n",
    "#executor.update_parameters(slurm_array_parallelism=2, mem_gb=30, timeout_min=10, slurm_partition=\"CPU\", cpus_per_task=50)\n",
    "executor.update_parameters(mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70) #cpus_per_task\n",
    "\n",
    "# actually submit the job\n",
    "job = executor.submit(runFullSpikeSorting, file, sorting)\n",
    "\n",
    "# print the ID of your job\n",
    "print(\"submit job\" + str(job.job_id))  \n",
    "\n",
    "# await a single result\n",
    "await job.awaitable().results()\n",
    "print(f\"job {job.job_id} completed in \" + str(time.time()-start_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a42b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#job 34074 completed in 408.1813361644745 second (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=50)\n",
    "#job 34078 completed in 437.409494638443 seconds (slurm_array_parallelism=3, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=50)\n",
    "#job 34081 completed in 423.37460565567017 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", slurm_gres=\"gpu:2\", cpus_per_task=50)\n",
    "#job 34085 completed in 367.0000305175781 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70)\n",
    "#job 34089 completed in 370.1982145309448 seconds (slurm_array_parallelism=2, mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=80)\n",
    "#job 34093 completed in 355.1876621246338 seconds (mem_gb=60, timeout_min=20, slurm_partition=\"GPU\", cpus_per_task=70)\n",
    "\n",
    "last_job = job\n",
    "checkRessources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0e099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
