{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.signal import chirp, find_peaks, peak_widths\n",
    "import ephyviewer\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer\n",
    "from ephyviewer import AnalogSignalSourceWithScatter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract relevant variables from recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-11-14_15-45-09', 1, 2]\n",
      "['2023-11-15_14-00-12', nan, 1]\n",
      "['2023-11-16_13-47-23', 1, 2]\n",
      "['2024-01-23_11-42-06', 2, nan]\n"
     ]
    }
   ],
   "source": [
    "#Variables that might change from mouse to mouse\n",
    "\n",
    "# format: recordings = [date_time, TTL of midline, TTL of VB]       #put float(\"nan\") if no stim of this type in recording!!\n",
    "recordings = [[\"2023-11-14_15-45-09\", 1, 2], [\"2023-11-15_14-00-12\", float(\"nan\"), 1], [\"2023-11-16_13-47-23\", 1, 2], [\"2024-01-23_11-42-06\", 2, float(\"nan\")]]\n",
    "# format: CA1_Eles = [CA1 ipsi, CA1 contra]\n",
    "CA1_Eles = [7, 14]\n",
    "stim_regions = [\"mid\", \"vb\"]    #make sure to have that in same order as TTLs in recordings info\n",
    "Letter = \"I:\"\n",
    "nb_E = 15\n",
    "mouse = os.path.basename(os.getcwd())   #script contained in folder named after mouse\n",
    "\n",
    "#Plenty of empty lists that will be filled with variables\n",
    "EMGboolean = []\n",
    "EMGs = []\n",
    "CA1_i = []\n",
    "CA1_c = []\n",
    "CA1_i_cwt = []\n",
    "CA1_c_cwt = []\n",
    "CA1_i_means_sd = []\n",
    "CA1_c_means_sd = []\n",
    "CA1_i_stim0 = []\n",
    "CA1_c_stim0 = []\n",
    "CA1_i_onlystim = []\n",
    "CA1_c_onlystim = []\n",
    "\n",
    "\n",
    "for rec_nb, rec_infos in enumerate(recordings):\n",
    "    print(rec_infos)\n",
    "    date_time = rec_infos[0]\n",
    "    if date_time == \"2024-01-23_11-42-06\":\n",
    "        recordnode = 101\n",
    "        acquiboard = 100\n",
    "    else:\n",
    "        recordnode = 105\n",
    "        acquiboard = 104\n",
    "\n",
    "\n",
    "    ### STIM TIMES ###\n",
    "    #Load stim info from hard drive with original recording\n",
    "    sample_numbers = np.load(f\"{Letter}/{date_time}/Record Node {recordnode}/experiment1/recording1/events/Acquisition_Board-{acquiboard}.Rhythm Data/TTL/sample_numbers.npy\")\n",
    "    channel_states = np.load(f\"{Letter}/{date_time}/Record Node {recordnode}/experiment1/recording1/events/Acquisition_Board-{acquiboard}.Rhythm Data/TTL/states.npy\")\n",
    "    cont = np.load(f\"{Letter}/{date_time}/Record Node {recordnode}/experiment1/recording1/continuous/Acquisition_Board-{acquiboard}.Rhythm Data/sample_numbers.npy\")\n",
    "\n",
    "    for pos, stim_region in enumerate(stim_regions):\n",
    "        TTL = rec_infos[pos+1]  #because loops through mid then vb, and info about TTL is in position 1 and 2 of sub-list in \"recordings\" (line 4)\n",
    "        \n",
    "        if TTL == float(\"nan\"):\n",
    "            globals()[f\"stim_times_{stim_region}_rec{rec_nb}\"] = float(\"nan\")\n",
    "\n",
    "        else:\n",
    "            # find the indices of the start and end times\n",
    "            start_indices = np.where(channel_states == TTL)[0]\n",
    "            end_indices = np.where(channel_states == -TTL)[0]\n",
    "\n",
    "            # create a new array with the start and end times\n",
    "            stim_times = np.zeros((len(start_indices), 2))\n",
    "            for i in range(len(start_indices)):\n",
    "                stim_times[i, 0] = sample_numbers[start_indices[i]]\n",
    "                stim_times[i, 1] = sample_numbers[end_indices[i]]\n",
    "\n",
    "            #Adjust stim timestamps - start time and sampling frequency\n",
    "            start_time = cont[0]  # in 0.5 milliseconds   #First value of timestamps memmap from 'continuous' folder\n",
    "            stim_times -= start_time\n",
    "            stim_times = stim_times.astype('float64')\n",
    "            stim_times /= 2.0\n",
    "            stim_times = stim_times.astype('int64')\n",
    "\n",
    "            #Identify stim_times by name of stimulated region, keep only that\n",
    "            globals()[f\"stim_times_{stim_region}_rec{rec_nb}\"] = stim_times; stim_times = None\n",
    "\n",
    "\n",
    "\n",
    "    ### LFP RECORDINGS ###\n",
    "    # Load DS and ordered recordings, and sleep scoring frame, from subfolder\n",
    "    EMGboolean.append(pd.read_pickle(f'{date_time}/EMGframeBoolean_1.pkl'))\n",
    "    All = np.load(f'{date_time}/RawDataChannelExtractedDS_1.npy', mmap_mode= 'r')\n",
    "\n",
    "    #Get LFPs by calculating differences between electrode pairs\n",
    "    EMG = All[:,0]\n",
    "    y = 1\n",
    "    for x in range(nb_E):\n",
    "        exec(f\"Ea = All[:,{y}]\")\n",
    "        y += 1\n",
    "        exec(f\"Eb = All[:,{y}]\")\n",
    "        y += 1\n",
    "        exec(f\"E{x} = Ea - Eb\")\n",
    "\n",
    "    #Keep only CA1 channels, erase the rest\n",
    "    exec(f\"CA1_i.append(E{CA1_Eles[0]})\")\n",
    "    exec(f\"CA1_c.append(E{CA1_Eles[1]})\")\n",
    "\n",
    "    # Filter EMG for nicer visualisation later on\n",
    "    f_lowcut = 200.; f_hicut = 400.; N = 4; fs = 1000; nyq = 0.5 * fs\n",
    "    Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "    b, a = signal.butter(N, Wn, 'band')\n",
    "    filt_EMG = signal.filtfilt(b, a, EMG)\n",
    "    EMGs.append(filt_EMG)\n",
    "    \n",
    "    All = None; Ea = None; Eb = None\n",
    "    for x in range(nb_E):\n",
    "        exec(f\"E{x} = None\")\n",
    "#Gathered all info from recordings, now end loop\n",
    "    \n",
    "\n",
    "### ANALYSE CA1 LFPs ###\n",
    "# Contiuous wavelet transform (parameters and computation)\n",
    "w = 10.\n",
    "fs = 1000\n",
    "freq = np.linspace(120, 200, 80)\n",
    "widths = w*fs / (2*freq*np.pi)\n",
    "\n",
    "for rec_nb in range(len(recordings)):\n",
    "    CA1_i_cwt.append(np.mean(np.absolute(signal.cwt(CA1_i[rec_nb], signal.morlet2, widths, w=w)), axis=0))\n",
    "    CA1_c_cwt.append(np.mean(np.absolute(signal.cwt(CA1_c[rec_nb], signal.morlet2, widths, w=w)), axis=0))\n",
    "\n",
    "# From the whole recording, keep only times where there is a stimulation (with some time before and after) that entirely happens during sleep\n",
    "for hemi in [\"i\", \"c\"]:\n",
    "    for rec_nb in range(len(recordings)):\n",
    "        CWT_wakeremoved = np.array(globals()[f\"CA1_{hemi}_cwt\"][rec_nb].copy())\n",
    "        CWT_wakeremoved = CWT_wakeremoved[EMGboolean[rec_nb]['BooleanLiberal']]  #Keep only SWS\n",
    "        CA1_mean = np.mean(CWT_wakeremoved)\n",
    "        CA1_sd = np.std(CWT_wakeremoved)\n",
    "        globals()[f\"CA1_{hemi}_means_sd\"].append([CA1_mean, CA1_sd])\n",
    "        CWT_stim0 = np.array(globals()[f\"CA1_{hemi}_cwt\"][rec_nb].copy())\n",
    "        CWT_stim0[~EMGboolean[rec_nb]['BooleanLiberal']] = 0  #Put everything else than SWS to 0\n",
    "\n",
    "        stimtimes_vector = np.zeros(len(CWT_stim0))\n",
    "        for stim_region in stim_regions:\n",
    "            stim_times = globals()[f\"stim_times_{stim_region}_rec{rec_nb}\"]\n",
    "            for stim_nb in range(0, len(stim_times), 10):   #every 10th stim because blocks of 10\n",
    "                stim_start = stim_times[stim_nb, 0]\n",
    "                stim_end = stim_times[stim_nb+9, 1]\n",
    "                stim_duration = stim_end-stim_start\n",
    "\n",
    "                # Marquer la période de stimulation dans le vecteur\n",
    "                stim_window = slice(stim_start - stim_duration, stim_end + stim_duration + 10000)\n",
    "                stimtimes_vector[stim_window] = 1\n",
    "\n",
    "                # Vérifier si au moins une valeur dans la fenêtre de stimulation n'est pas contenue dans EMGboolean-sommeil\n",
    "                if np.any(~EMGboolean[rec_nb]['BooleanLiberal'][stim_window]):\n",
    "                    stimtimes_vector[stim_window] = 0\n",
    "\n",
    "            # # Exclure les périodes marquées par EMGboolean\n",
    "            stimtimes_vector[~EMGboolean[rec_nb]['BooleanLiberal']] = 0\n",
    "            tests.append(stimtimes_vector)\n",
    "\n",
    "        # Créer un vecteur booléen pour les périodes de stimulation\n",
    "        bool_stimtimes = (stimtimes_vector == 1)\n",
    "        CWT_stim0[~bool_stimtimes] = 0   #now also put everything that is not before/during/after stim to 0\n",
    "        globals()[f\"CA1_{hemi}_stim0\"].append(CWT_stim0)\n",
    "        times = np.arange(len(CWT_stim0))[bool_stimtimes]\n",
    "        CWT_onlystim = np.concatenate((CWT_stim0[bool_stimtimes], times)).reshape(2,len(times)) #create variable where everything except valid stimtimes is removed, but add times row to preserve info about original times\n",
    "        globals()[f\"CA1_{hemi}_onlystim\"].append(CWT_onlystim)\n",
    "        globals()[f\"bool_stimtimes_rec{rec_nb}\"] = bool_stimtimes\n",
    "\n",
    "CWT_wakeremoved = None #free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect SWRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug True\n",
      "QT_MODE PySide6\n",
      "refresh duration for  0.0009975433349609375 s\n",
      "save_all_settings\n",
      "3107099\n",
      "1627 1910\n"
     ]
    }
   ],
   "source": [
    "### REC 0 ###\n",
    "\n",
    "### DETECT SWRs ON STIM ONLY DATA ###\n",
    "#Do both hemispheres (can view both at same time)\n",
    "for hemi in [\"i\", \"c\"]:\n",
    "    if hemi == \"i\":\n",
    "        threshold = 4   #number by which to multiply SD; 2 diff thresholds for 2 diff channels\n",
    "    else:\n",
    "        threshold = 4\n",
    "    \n",
    "    CA1_mean = globals()[f\"CA1_{hemi}_means_sd\"][0][0]\n",
    "    CA1_sd = globals()[f\"CA1_{hemi}_means_sd\"][0][1]\n",
    "    peaks, properties = find_peaks(globals()[f\"CA1_{hemi}_onlystim\"][0][0], prominence=1, width=20, height = CA1_mean+CA1_sd*threshold)\n",
    "\n",
    "    properties[\"prominences\"], properties[\"widths\"]\n",
    "    # SWR boundaries taken at 70% from peak of intensity. This means that the SWRs with small amplitude will be longer than the big ones.\n",
    "    results_width = peak_widths(globals()[f\"CA1_{hemi}_onlystim\"][0][0], peaks, rel_height=0.7)\n",
    "    peaks2 = peaks.reshape(len(peaks),1)\n",
    "    npresults_width = np.array(results_width).reshape(4,-1)\n",
    "    SWR_prop = np.append(peaks2, results_width).reshape(5,len(peaks2)).round()\n",
    "\n",
    "    #Filter signal because is nice for SWR visualisation\n",
    "    f_lowcut = 120.; f_hicut = 200.; fs = 1000; nyq = 0.5 * fs; N = 6\n",
    "    Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "    b, a = signal.butter(N, Wn, 'band')\n",
    "    globals()[f\"filt_CA1_{hemi}\"] = signal.filtfilt(b, a, globals()[f\"CA1_{hemi}\"][0])\n",
    "    globals()[f\"peaks_{hemi}_rec0\"] = peaks\n",
    "    globals()[f\"SWR_prop_{hemi}\"] = SWR_prop\n",
    "\n",
    "\n",
    "\n",
    "### LOOK AT THE RESULT AND JUDGE IT; UPDATE THRESHOLD AND REPEAT IF NECESSARY ###\n",
    "app = mkQApp()\n",
    "\n",
    "sample_rate = 1000.\n",
    "t_start = 0.\n",
    "\n",
    "combined = np.stack([CA1_i[0][bool_stimtimes_rec0], CA1_i_onlystim[0][0], filt_CA1_i[bool_stimtimes_rec0], CA1_c[0][bool_stimtimes_rec0], CA1_c_onlystim[0][0], filt_CA1_c[bool_stimtimes_rec0], EMGs[0][bool_stimtimes_rec0]], axis = 1)\n",
    "\n",
    "#create 2 family scatters from theses 2 indexes\n",
    "scatter_indexes = {0: peaks_i_rec0, 1: peaks_c_rec0}\n",
    "#and assign them to some channels each\n",
    "scatter_channels = {0: [0, 1], 1: [3, 4]}\n",
    "\n",
    "source = AnalogSignalSourceWithScatter(combined, sample_rate, t_start, scatter_indexes, scatter_channels)\n",
    "\n",
    "#Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "#create a viewer for signal with TraceViewer\n",
    "#connected to the signal source\n",
    "view1 = TraceViewer(source=source)\n",
    "\n",
    "#Parameters can be set in script\n",
    "#view1.params['scale_mode'] = 'same_for_all'\n",
    "view1.params['display_labels'] = True\n",
    "#And also parameters for each channel\n",
    "view1.by_channel_params['ch0', 'color'] = '#ffffff'\n",
    "view1.by_channel_params['ch1', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch2', 'color'] = '#ff5500'\n",
    "view1.by_channel_params['ch3', 'color'] = '#ffffff'\n",
    "view1.by_channel_params['ch4', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch5', 'color'] = '#ff5500'\n",
    "view1.by_channel_params['ch6', 'color'] = 'red'\n",
    "\n",
    "view1.by_channel_params['ch0', 'gain'] = 0.0005\n",
    "view1.by_channel_params['ch1', 'gain'] = 0.0015\n",
    "view1.by_channel_params['ch2', 'gain'] = 0.0015\n",
    "view1.by_channel_params['ch3', 'gain'] = 0.001\n",
    "view1.by_channel_params['ch4', 'gain'] = 0.0015\n",
    "view1.by_channel_params['ch5', 'gain'] = 0.0015\n",
    "view1.by_channel_params['ch6', 'gain'] = 0.001\n",
    "\n",
    "view1.by_channel_params['ch0', 'offset'] = 4\n",
    "view1.by_channel_params['ch1', 'offset'] = 1\n",
    "view1.by_channel_params['ch2', 'offset'] = 1\n",
    "view1.by_channel_params['ch3', 'offset'] = -3\n",
    "view1.by_channel_params['ch4', 'offset'] = -6\n",
    "view1.by_channel_params['ch5', 'offset'] = -6\n",
    "view1.by_channel_params['ch6', 'offset'] = 8\n",
    "\n",
    "#put this viewer in the main window\n",
    "win.add_view(view1)\n",
    "\n",
    "#Run\n",
    "win.show()\n",
    "app.exec()\n",
    "\n",
    "print(len(CA1_i_onlystim[0][0]))\n",
    "print(len(peaks_i_rec0), len(peaks_c_rec0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug True\n",
      "QT_MODE PySide6\n",
      "refresh duration for  0.0 s\n",
      "save_all_settings\n",
      "2571182\n",
      "1310 1496\n"
     ]
    }
   ],
   "source": [
    "### REC 1 ###\n",
    "\n",
    "### DETECT SWRs ON STIM ONLY DATA ###\n",
    "#Do both hemispheres (can view both at same time) but only one recording at a time\n",
    "for hemi in [\"i\", \"c\"]:\n",
    "    if hemi == \"i\":\n",
    "        threshold = 4   #number by which to multiply SD; 2 diff thresholds for 2 diff channels\n",
    "    else:\n",
    "        threshold = 4\n",
    "    \n",
    "    CA1_mean = globals()[f\"CA1_{hemi}_means_sd\"][1][0]\n",
    "    CA1_sd = globals()[f\"CA1_{hemi}_means_sd\"][1][1]\n",
    "    peaks, properties = find_peaks(globals()[f\"CA1_{hemi}_onlystim\"][1][0], prominence=1, width=20, height = CA1_mean+CA1_sd*threshold)\n",
    "\n",
    "    properties[\"prominences\"], properties[\"widths\"]\n",
    "    # SWR boundaries taken at 70% from peak of intensity. This means that the SWRs with small amplitude will be longer than the big ones.\n",
    "    results_width = peak_widths(globals()[f\"CA1_{hemi}_onlystim\"][1][0], peaks, rel_height=0.7)\n",
    "    peaks2 = peaks.reshape(len(peaks),1)\n",
    "    npresults_width = np.array(results_width).reshape(4,-1)\n",
    "    SWR_prop = np.append(peaks2, results_width).reshape(5,len(peaks2)).round()\n",
    "\n",
    "    #Filter signal because is nice for SWR visualisation\n",
    "    f_lowcut = 120.; f_hicut = 200.; fs = 1000; nyq = 0.5 * fs; N = 6\n",
    "    Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "    b, a = signal.butter(N, Wn, 'band')\n",
    "    globals()[f\"filt_CA1_{hemi}\"] = signal.filtfilt(b, a, globals()[f\"CA1_{hemi}\"][1])\n",
    "    globals()[f\"peaks_{hemi}_rec1\"] = peaks\n",
    "    globals()[f\"SWR_prop_{hemi}\"] = SWR_prop\n",
    "\n",
    "\n",
    "\n",
    "### LOOK AT THE RESULT AND JUDGE IT; REPEAT IF NECESSARY ###\n",
    "app = mkQApp()\n",
    "\n",
    "sample_rate = 1000.\n",
    "t_start = 0.\n",
    "\n",
    "combined = np.stack([CA1_i[1][bool_stimtimes_rec1], CA1_i_onlystim[1][0], filt_CA1_i[bool_stimtimes_rec1], CA1_c[1][bool_stimtimes_rec1], CA1_c_onlystim[1][0], filt_CA1_c[bool_stimtimes_rec1], EMGs[1][bool_stimtimes_rec1]], axis = 1)\n",
    "\n",
    "#create 2 family scatters from theses 2 indexes\n",
    "scatter_indexes = {0: peaks_i_rec1, 1: peaks_c_rec1}\n",
    "#and assign them to some channels each\n",
    "scatter_channels = {0: [0, 1], 1: [3, 4]}\n",
    "\n",
    "source = AnalogSignalSourceWithScatter(combined, sample_rate, t_start, scatter_indexes, scatter_channels)\n",
    "\n",
    "#Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "#create a viewer for signal with TraceViewer\n",
    "#connected to the signal source\n",
    "view1 = TraceViewer(source=source)\n",
    "\n",
    "#Parameters can be set in script\n",
    "#view1.params['scale_mode'] = 'same_for_all'\n",
    "view1.params['display_labels'] = True\n",
    "#And also parameters for each channel\n",
    "view1.by_channel_params['ch0', 'color'] = '#ffffff'\n",
    "view1.by_channel_params['ch1', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch2', 'color'] = '#ff5500'\n",
    "view1.by_channel_params['ch3', 'color'] = '#ffffff'\n",
    "view1.by_channel_params['ch4', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch5', 'color'] = '#ff5500'\n",
    "view1.by_channel_params['ch6', 'color'] = 'red'\n",
    "\n",
    "view1.by_channel_params['ch0', 'gain'] = 0.0005\n",
    "view1.by_channel_params['ch1', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch2', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch3', 'gain'] = 0.001\n",
    "view1.by_channel_params['ch4', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch5', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch6', 'gain'] = 0.001\n",
    "\n",
    "view1.by_channel_params['ch0', 'offset'] = 4\n",
    "view1.by_channel_params['ch1', 'offset'] = 1\n",
    "view1.by_channel_params['ch2', 'offset'] = 1\n",
    "view1.by_channel_params['ch3', 'offset'] = -3\n",
    "view1.by_channel_params['ch4', 'offset'] = -6\n",
    "view1.by_channel_params['ch5', 'offset'] = -6\n",
    "view1.by_channel_params['ch6', 'offset'] = 8\n",
    "\n",
    "#put this viewer in the main window\n",
    "win.add_view(view1)\n",
    "\n",
    "#Run\n",
    "win.show()\n",
    "app.exec()\n",
    "\n",
    "print(len(CA1_i_onlystim[1][0]))\n",
    "print(len(peaks_i_rec1), len(peaks_c_rec1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug True\n",
      "QT_MODE PySide6\n",
      "refresh duration for  0.0 s\n",
      "save_all_settings\n",
      "3680040\n",
      "1879 2179\n"
     ]
    }
   ],
   "source": [
    "### REC 2 ###\n",
    "\n",
    "### DETECT SWRs ON STIM ONLY DATA ###\n",
    "#Do both hemispheres (can view both at same time) but only one recording at a time\n",
    "for hemi in [\"i\", \"c\"]:\n",
    "    if hemi == \"i\":\n",
    "        threshold = 4   #number by which to multiply SD; 2 diff thresholds for 2 diff channels\n",
    "    else:\n",
    "        threshold = 4\n",
    "    \n",
    "    CA1_mean = globals()[f\"CA1_{hemi}_means_sd\"][2][0]\n",
    "    CA1_sd = globals()[f\"CA1_{hemi}_means_sd\"][2][1]\n",
    "    peaks, properties = find_peaks(globals()[f\"CA1_{hemi}_onlystim\"][2][0], prominence=1, width=20, height = CA1_mean+CA1_sd*threshold)\n",
    "\n",
    "    properties[\"prominences\"], properties[\"widths\"]\n",
    "    # SWR boundaries taken at 70% from peak of intensity. This means that the SWRs with small amplitude will be longer than the big ones.\n",
    "    results_width = peak_widths(globals()[f\"CA1_{hemi}_onlystim\"][2][0], peaks, rel_height=0.7)\n",
    "    peaks2 = peaks.reshape(len(peaks),1)\n",
    "    npresults_width = np.array(results_width).reshape(4,-1)\n",
    "    SWR_prop = np.append(peaks2, results_width).reshape(5,len(peaks2)).round()\n",
    "\n",
    "    #Filter signal because is nice for SWR visualisation\n",
    "    f_lowcut = 120.; f_hicut = 200.; fs = 1000; nyq = 0.5 * fs; N = 6\n",
    "    Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "    b, a = signal.butter(N, Wn, 'band')\n",
    "    globals()[f\"filt_CA1_{hemi}\"] = signal.filtfilt(b, a, globals()[f\"CA1_{hemi}\"][2])\n",
    "    globals()[f\"peaks_{hemi}_rec2\"] = peaks\n",
    "    globals()[f\"SWR_prop_{hemi}\"] = SWR_prop\n",
    "\n",
    "\n",
    "\n",
    "### LOOK AT THE RESULT AND JUDGE IT; REPEAT IF NECESSARY ###\n",
    "app = mkQApp()\n",
    "\n",
    "sample_rate = 1000.\n",
    "t_start = 0.\n",
    "\n",
    "combined = np.stack([CA1_i[2][bool_stimtimes_rec2], CA1_i_onlystim[2][0], filt_CA1_i[bool_stimtimes_rec2], CA1_c[2][bool_stimtimes_rec2], CA1_c_onlystim[2][0], filt_CA1_c[bool_stimtimes_rec2], EMGs[2][bool_stimtimes_rec2]], axis = 1)\n",
    "\n",
    "#create 2 family scatters from theses 2 indexes\n",
    "scatter_indexes = {0: peaks_i_rec2, 1: peaks_c_rec2}\n",
    "#and assign them to some channels each\n",
    "scatter_channels = {0: [0, 1], 1: [3, 4]}\n",
    "\n",
    "source = AnalogSignalSourceWithScatter(combined, sample_rate, t_start, scatter_indexes, scatter_channels)\n",
    "\n",
    "#Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "#create a viewer for signal with TraceViewer\n",
    "#connected to the signal source\n",
    "view1 = TraceViewer(source=source)\n",
    "\n",
    "#Parameters can be set in script\n",
    "#view1.params['scale_mode'] = 'same_for_all'\n",
    "view1.params['display_labels'] = True\n",
    "#And also parameters for each channel\n",
    "view1.by_channel_params['ch0', 'color'] = '#ffffff'\n",
    "view1.by_channel_params['ch1', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch2', 'color'] = '#ff5500'\n",
    "view1.by_channel_params['ch3', 'color'] = '#ffffff'\n",
    "view1.by_channel_params['ch4', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch5', 'color'] = '#ff5500'\n",
    "view1.by_channel_params['ch6', 'color'] = 'red'\n",
    "\n",
    "view1.by_channel_params['ch0', 'gain'] = 0.0005\n",
    "view1.by_channel_params['ch1', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch2', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch3', 'gain'] = 0.001\n",
    "view1.by_channel_params['ch4', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch5', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch6', 'gain'] = 0.001\n",
    "\n",
    "view1.by_channel_params['ch0', 'offset'] = 4\n",
    "view1.by_channel_params['ch1', 'offset'] = 1\n",
    "view1.by_channel_params['ch2', 'offset'] = 1\n",
    "view1.by_channel_params['ch3', 'offset'] = -3\n",
    "view1.by_channel_params['ch4', 'offset'] = -6\n",
    "view1.by_channel_params['ch5', 'offset'] = -6\n",
    "view1.by_channel_params['ch6', 'offset'] = 8\n",
    "\n",
    "#put this viewer in the main window\n",
    "win.add_view(view1)\n",
    "\n",
    "#Run\n",
    "win.show()\n",
    "app.exec()\n",
    "\n",
    "print(len(CA1_i_onlystim[2][0]))\n",
    "print(len(peaks_i_rec2), len(peaks_c_rec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug True\n",
      "QT_MODE PySide6\n",
      "refresh duration for  0.0 s\n",
      "save_all_settings\n",
      "1871881\n",
      "944 1820\n"
     ]
    }
   ],
   "source": [
    "### REC 3 ###\n",
    "\n",
    "### DETECT SWRs ON STIM ONLY DATA ###\n",
    "#Do both hemispheres (can view both at same time) but only one recording at a time\n",
    "for hemi in [\"i\", \"c\"]:\n",
    "    if hemi == \"i\":\n",
    "        threshold = 4   #number by which to multiply SD; 2 diff thresholds for 2 diff channels\n",
    "    else:\n",
    "        threshold = 4\n",
    "    \n",
    "    CA1_mean = globals()[f\"CA1_{hemi}_means_sd\"][2][0]\n",
    "    CA1_sd = globals()[f\"CA1_{hemi}_means_sd\"][2][1]\n",
    "    peaks, properties = find_peaks(globals()[f\"CA1_{hemi}_onlystim\"][3][0], prominence=1, width=20, height = CA1_mean+CA1_sd*threshold)\n",
    "\n",
    "    properties[\"prominences\"], properties[\"widths\"]\n",
    "    # SWR boundaries taken at 70% from peak of intensity. This means that the SWRs with small amplitude will be longer than the big ones.\n",
    "    results_width = peak_widths(globals()[f\"CA1_{hemi}_onlystim\"][3][0], peaks, rel_height=0.7)\n",
    "    peaks2 = peaks.reshape(len(peaks),1)\n",
    "    npresults_width = np.array(results_width).reshape(4,-1)\n",
    "    SWR_prop = np.append(peaks2, results_width).reshape(5,len(peaks2)).round()\n",
    "\n",
    "    #Filter signal because is nice for SWR visualisation\n",
    "    f_lowcut = 120.; f_hicut = 200.; fs = 1000; nyq = 0.5 * fs; N = 6\n",
    "    Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "    b, a = signal.butter(N, Wn, 'band')\n",
    "    globals()[f\"filt_CA1_{hemi}\"] = signal.filtfilt(b, a, globals()[f\"CA1_{hemi}\"][3])\n",
    "    globals()[f\"peaks_{hemi}_rec3\"] = peaks\n",
    "    globals()[f\"SWR_prop_{hemi}\"] = SWR_prop\n",
    "\n",
    "\n",
    "\n",
    "### LOOK AT THE RESULT AND JUDGE IT; REPEAT IF NECESSARY ###\n",
    "app = mkQApp()\n",
    "\n",
    "sample_rate = 1000.\n",
    "t_start = 0.\n",
    "\n",
    "combined = np.stack([CA1_i[3][bool_stimtimes_rec3], CA1_i_onlystim[3][0], filt_CA1_i[bool_stimtimes_rec3], CA1_c[3][bool_stimtimes_rec3], CA1_c_onlystim[3][0], filt_CA1_c[bool_stimtimes_rec3], EMGs[3][bool_stimtimes_rec3]], axis = 1)\n",
    "\n",
    "#create 2 family scatters from theses 2 indexes\n",
    "scatter_indexes = {0: peaks_i_rec3, 1: peaks_c_rec3}\n",
    "#and assign them to some channels each\n",
    "scatter_channels = {0: [0, 1], 1: [3, 4]}\n",
    "\n",
    "source = AnalogSignalSourceWithScatter(combined, sample_rate, t_start, scatter_indexes, scatter_channels)\n",
    "\n",
    "#Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "#create a viewer for signal with TraceViewer\n",
    "#connected to the signal source\n",
    "view1 = TraceViewer(source=source)\n",
    "\n",
    "#Parameters can be set in script\n",
    "#view1.params['scale_mode'] = 'same_for_all'\n",
    "view1.params['display_labels'] = True\n",
    "#And also parameters for each channel\n",
    "view1.by_channel_params['ch0', 'color'] = '#ffffff'\n",
    "view1.by_channel_params['ch1', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch2', 'color'] = '#ff5500'\n",
    "view1.by_channel_params['ch3', 'color'] = '#ffffff'\n",
    "view1.by_channel_params['ch4', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch5', 'color'] = '#ff5500'\n",
    "view1.by_channel_params['ch6', 'color'] = 'red'\n",
    "\n",
    "view1.by_channel_params['ch0', 'gain'] = 0.0005\n",
    "view1.by_channel_params['ch1', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch2', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch3', 'gain'] = 0.001\n",
    "view1.by_channel_params['ch4', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch5', 'gain'] = 0.002\n",
    "view1.by_channel_params['ch6', 'gain'] = 0.001\n",
    "\n",
    "view1.by_channel_params['ch0', 'offset'] = 4\n",
    "view1.by_channel_params['ch1', 'offset'] = 1\n",
    "view1.by_channel_params['ch2', 'offset'] = 1\n",
    "view1.by_channel_params['ch3', 'offset'] = -3\n",
    "view1.by_channel_params['ch4', 'offset'] = -6\n",
    "view1.by_channel_params['ch5', 'offset'] = -6\n",
    "view1.by_channel_params['ch6', 'offset'] = 8\n",
    "\n",
    "#put this viewer in the main window\n",
    "win.add_view(view1)\n",
    "\n",
    "#Run\n",
    "win.show()\n",
    "app.exec()\n",
    "\n",
    "print(len(CA1_i_onlystim[3][0]))\n",
    "print(len(peaks_i_rec3), len(peaks_c_rec3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove bad events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If go through recording with visualiser and see obviously wrong event, write the approximate timing of them here (can be done in parallel with open ephyviewer)\n",
    "# Once everything to exclude is written down for all recordings, run next cell (ONLY ONCE or run all thresholding-ephyviewer cells again)\n",
    "\n",
    "events_toremove_CA1_i_rec0 = []\n",
    "events_toremove_CA1_c_rec0 = []\n",
    "\n",
    "events_toremove_CA1_i_rec1 = []\n",
    "events_toremove_CA1_c_rec1 = []\n",
    "\n",
    "events_toremove_CA1_i_rec2 = []\n",
    "events_toremove_CA1_c_rec2 = []\n",
    "\n",
    "#etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to exclude flagged events\n",
    "# Will go through the list of flagged events and remove the event in the original list (peaks) that is closest in time to the noted timestamp\n",
    "\n",
    "def closest(list, Number):\n",
    "    aux = []\n",
    "    for valor in list:\n",
    "        aux.append(abs(Number*1000-valor))\n",
    "\n",
    "    return list[aux.index(min(aux))]\n",
    "\n",
    "for hemi in [\"i\", \"c\"]:\n",
    "    for rec_nb in range(len(recordings)):\n",
    "        events_toremove = globals()[f\"events_toremove_CA1_{hemi}_rec{rec_nb}\"]\n",
    "        peaks = globals()[f\"peaks_{hemi}_rec{rec_nb}\"]\n",
    "\n",
    "        print( hemi, rec_nb)\n",
    "        print(len(peaks))\n",
    "        print(len(peaks)-len(events_toremove))\n",
    "\n",
    "        for remove in events_toremove:\n",
    "            event = closest(peaks, remove)\n",
    "            mask = peaks != event\n",
    "            peaks = peaks[mask]\n",
    "\n",
    "        print(len(peaks))   #to check that right number of events was excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count events in right bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis will take all events from the peaks variables and place them in the correct bins: correct recording, hemisphere CA1, and stim freq\n",
    "\n",
    "#When working with CA1_onlystim (shortened version of recording), times of events don't fit anymore, so to get back real times: value in peaks tuple = index of onlystim array; and at that index (last row) can be found time = index of realtime CA1\n",
    "\n",
    "#Meaning of dimensions of event_count variables: (CA1 ipsi & contra; stim freqs 2-90 Hz; bins 5 before, 5 during, 5 after stim, & 10s after stim with 0.5s per bin)\n",
    "event_count_mid = np.zeros((2, 13, 35))\n",
    "event_count_vb = np.zeros((2, 13, 35))\n",
    "\n",
    "all_stim_freq = (2,4,6,8,10,12,14,16,18,20,40,60,90)\n",
    "total_count = 0\n",
    "\n",
    "\n",
    "for stim_region in stim_regions:\n",
    "    for rec_nb in range(len(recordings)):\n",
    "        stim_times = globals()[f\"stim_times_{stim_region}_rec{rec_nb}\"]\n",
    "        for f, stim_freq in enumerate(all_stim_freq):\n",
    "            for stim_nb in range(0, len(stim_times), 10):   #every 10th stim because blocks of 10. To be optimised.\n",
    "                stim_start = stim_times[stim_nb, 0]\n",
    "                stim_duration = stim_times[stim_nb+9, 1] - stim_start\n",
    "                bins = np.concatenate((np.arange(stim_start-stim_duration, stim_start+2*stim_duration, stim_duration/5), np.arange(stim_start+2*stim_duration, stim_start+2*stim_duration+10000, 500)))\n",
    "                for h, hemi in enumerate([\"i\", \"c\"]): \n",
    "                    times_wrong = globals()[f\"peaks_{hemi}_rec{rec_nb}\"]\n",
    "                    CA1_onlystim = globals()[f\"CA1_{hemi}_onlystim\"][rec_nb]\n",
    "                    times = []\n",
    "                    for t in times_wrong:\n",
    "                        times.append(CA1_onlystim[1][t])\n",
    "\n",
    "                    #Function created by ChatGPT\n",
    "                    def find_bin_indices(bins, times):\n",
    "                        times = np.array(times)\n",
    "                        indices = np.searchsorted(bins, times, side='right') - 1\n",
    "                        valid_indices = (indices >= 0) & (indices < len(bins) - 1)\n",
    "                        indices = indices[valid_indices]\n",
    "                        times = times[valid_indices]\n",
    "                        in_bin = (times >= bins[indices]) & (times < bins[indices + 1])\n",
    "                        result_indices = indices[in_bin]\n",
    "                        return result_indices\n",
    "\n",
    "                    bin_indices = find_bin_indices(bins, times)\n",
    "\n",
    "                    #Append count only if stim we're looking at fits with stim freq in duration (with less precision necessary if high freq)\n",
    "                    if stim_freq<30:\n",
    "                        if round(9000/(stim_duration-20)) == stim_freq:\n",
    "                            for b in bin_indices:\n",
    "                                globals()[f\"event_count_{stim_region}\"][h, f, b] += 1\n",
    "                            total_count += 1\n",
    "                    else:\n",
    "                        if round(9000/(stim_duration-20), -1) == stim_freq:\n",
    "                            for b in bin_indices:\n",
    "                                globals()[f\"event_count_{stim_region}\"][h, f, b] += 1\n",
    "                            total_count +=1\n",
    "                    #print(globals()[f\"event_count_{stim_region}\"][rec_nb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "ipsi very good, but contra excellent. will pick contra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_count_both = np.concatenate((event_count_mid, event_count_vb))\n",
    "np.save(f\"SWR count mouse{mouse} mid-vb.npy\", event_count_both)\n",
    "\n",
    "#format of numpy array:\n",
    "#Meaning of dimensions: (CA1 ipsi & contra; stim freqs 2-90 Hz; bins 5 before, 5 during, 5 after stim, & 10s after stim with 0.5s per bin) (see above)\n",
    "# and mid - CA1 ipsi contra; vb - CA1 ipsi contra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.0 27.0 37.0 27.0 36.0 37.0 32.0 32.0 31.0 42.0\n"
     ]
    }
   ],
   "source": [
    "#Quick-check result\n",
    "\n",
    "before = np.sum(event_count_mid[0, 5:9, :5])\n",
    "during = np.sum(event_count_mid[0, 5:9, 5:10])\n",
    "after = np.sum(event_count_mid[0, 5:9, 10:15])\n",
    "after2 = np.sum(event_count_mid[0, 5:9, 16:17])\n",
    "after3 = np.sum(event_count_mid[0, 5:9, 17:18])\n",
    "after4 = np.sum(event_count_mid[0, 5:9, 18:19])\n",
    "after5 = np.sum(event_count_mid[0, 5:9, 19:20])\n",
    "after6 = np.sum(event_count_mid[0, 5:9, 20:21])\n",
    "after7 = np.sum(event_count_mid[0, 5:9, 21:22])\n",
    "after8 = np.sum(event_count_mid[0, 5:9, 22:23])\n",
    "\n",
    "print(before, during, after, after2, after3, after4, after5, after6, after7, after8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e68ec53277ed191c360ed6d25b64b12c8ee91a2a55fa5a497523152662d636e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
