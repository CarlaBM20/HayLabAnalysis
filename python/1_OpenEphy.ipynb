{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening and cleaning out ephys data\n",
    "\n",
    "Note: Use L1imag/formation environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantities as pq\n",
    "import numpy as np\n",
    "import neo\n",
    "from pathlib import Path\n",
    "import fnmatch\n",
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "import scipy\n",
    "from scipy import interpolate\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "%matplotlib widget\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find files containing a specific string\n",
    "def find_files_with_string(folder_path, search_string):\n",
    "    matching_files = []\n",
    "    # Traverse the folder to find files\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if fnmatch.fnmatch(file, f\"*{search_string}*\"):\n",
    "                matching_files.append(os.path.join(root, file))\n",
    "    return matching_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording\"\n",
    "try:\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"data not in store\")\n",
    "    dpath =\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording\"\n",
    "\n",
    "# Set up Initial Basic Parameters#\n",
    "minian_path = \".\"\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>OpenEphys Folder</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "### Load timestamps from continuous recording\n",
    "\n",
    "Note here the synchronised timestamps are not loaded. Attempt is made next cell but there is a bug because the files are of different lengths. \n",
    "What needs to be done is to understand the exact content of these files to then load them properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder = Path('.').absolute()\n",
    "print(folder)\n",
    "path_list_ERS = []\n",
    "Ephys_rec_stamps = {}\n",
    "\n",
    "for file in folder.glob('**/*continuous/Rhythm_FPGA-112.0/timestamps.npy'):\n",
    "    path_list_ERS.append(file)\n",
    "\n",
    "for file_path in folder.glob('**/*continuous/Rhythm_FPGA-112.0/timestamps.npy'):\n",
    "    recording = file_path.parents[2].stem\n",
    "    arr = np.load(file_path)\n",
    "    Ephys_rec_stamps[recording] = arr\n",
    "\n",
    "## Here the timestamps are stored in a dict which is not necessarily what I want, maybe will need to amend that\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not working yet as synchronised timestamps and timestamps for recording 2 are of different size.\n",
    "\n",
    "TTL_stamp2 = []\n",
    "for file_path in folder.glob('**/*.npy'):\n",
    "    subfolder = file_path.parents[1].stem\n",
    "    if subfolder == 'continuous':\n",
    "        recording = file_path.parents[2].stem.replace('recording','')\n",
    "        print(recording)\n",
    "        file = file_path.stem\n",
    "        print(recording, file)\n",
    "        np_arr = np.load(file_path)\n",
    "        datalen = len(np_arr)\n",
    "        print(file, datalen)\n",
    "        if recording == 1: #not in TTL_stamp2:\n",
    "            TTL_stamp2.append(recording)\n",
    "            coords = {\n",
    "                'channels' : np.array(['synchronized_timestamps', 'timestamps']),\n",
    "                'duration_rec' : np.arange(datalen)\n",
    "            }\n",
    "            globals()[f\"StampsCont_{recording}\"] = xr.DataArray(coords=coords, dims=['channels', 'duration_rec'])\n",
    "        globals()[f\"StampsCont_{recording}\"].loc[file,:] = np_arr   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load timestamps for miniscope frames and laser (TTL in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TTL_stamps = []\n",
    "list_recordings = []\n",
    "for file_path in folder.glob('**/*.npy'):\n",
    "    subfolder = file_path.parents[0].stem\n",
    "    if subfolder == 'TTL_1':\n",
    "        recording = file_path.parents[3].stem.replace('recording','')\n",
    "        file = file_path.stem\n",
    "        np_arr = np.load(file_path)\n",
    "        datalen = len(np_arr)\n",
    "        if recording not in TTL_stamps:\n",
    "            TTL_stamps.append(recording)\n",
    "            list_recordings.append(file_path.parents[3].stem)\n",
    "            coords = {\n",
    "                'channels' : np.array(['full_words', 'timestamps', 'channel_states', 'channels']),\n",
    "                'duration_rec' : np.arange(datalen)\n",
    "            }\n",
    "            globals()[f\"Allstamps_{recording}\"] = xr.DataArray(coords=coords, dims=['channels', 'duration_rec'])\n",
    "        globals()[f\"Allstamps_{recording}\"].loc[file,:] = np_arr   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = Path(dpath)\n",
    "numchannels=32\n",
    "\n",
    "if find_files_with_string(folderpath,  \".bin\"): #Bonsai or IgorPro\n",
    "    recSyst = \"Bonsai\" #\"IgorPro\"\n",
    "    matching_files = find_files_with_string(folderpath, \".bin\")\n",
    "    fileType=\"OE32channels.bin\"\n",
    "\n",
    "elif find_files_with_string(folderpath,  \"continuous.dat\"): #OpenEphys\n",
    "    recSyst = \"OpenEphys\" #\"IgorPro\"\n",
    "    matching_files = find_files_with_string(folderpath, \"continuous.dat\")\n",
    "    fileType=\"OE32channels.bin\"\n",
    "\n",
    "match recSyst:\n",
    "    case \"Bonsai\":\n",
    "        dtype=np.uint16\n",
    "        offset=int(65535/2)\n",
    "    case _:\n",
    "        dtype=np.int16\n",
    "        offset=0\n",
    "\n",
    "All = np.zeros([0], dtype=dtype)\n",
    "for file in matching_files:\n",
    "    print(\"importing {}\".format(file))\n",
    "    file_data = np.fromfile(file, dtype=dtype)\n",
    "    All=np.append(All, file_data, axis=0)\n",
    "if offset != 0:\n",
    "    All = All - offset\n",
    "if All.dtype is not np.dtype(np.int16):\n",
    "    All = All.astype(np.int16)\n",
    "All = All.reshape(-1,numchannels)\n",
    "\n",
    "print('File loaded: {}, with {} channels and {} datapoint'.format(fileType, numchannels, All.shape[0] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribute channels.\n",
    "\n",
    "EMG = 11, deep PFC = 17, superficial PFC = 18, deep S1 = 24, superficial S1 = 23, deep CA1 = 21, superficial CA1 = 20\n",
    "\n",
    "WARNING: this has to be adjusted for every mouse. In the future, add a cell at the beginning to enter these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 25000 # Hz\n",
    "\n",
    "# Distribute\n",
    "EMG = All[:,10]\n",
    "PFC = All[:,17] #- All[:,17]\n",
    "S1 = All[:,22] - All[:,23] \n",
    "CA1 = All[:,20]- All[:,19]\n",
    "\n",
    "# Stack back\n",
    "combined = np.stack((EMG, PFC, S1, CA1), axis = 1)\n",
    "\n",
    "coords = {\n",
    "    'brain_areas' : np.array(['EMG', 'PFC', \"S1\", \"CA1\"]),\n",
    "    'duration_rec' : np.arange(0, combined.shape[0]/sampling_rate, 1/sampling_rate)\n",
    "}\n",
    "\n",
    "# Put in xarray\n",
    "xrCombined = xr.DataArray(coords=coords, dims=['duration_rec', 'brain_areas'])\n",
    "xrCombined.loc[:,:]  = combined\n",
    "\n",
    "# Save datas\n",
    "combinedFN = os.path.join(dpath,'RawDataChannelExtracted.npy')\n",
    "np.save(combinedFN, combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Downsample all signals to 1 kz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = All[:100000]\n",
    "new_sampling_rate = 1000 # Hz\n",
    "\n",
    "newLen = int(combined.shape[0] * new_sampling_rate / sampling_rate)\n",
    "print(combined.shape[0], newLen)\n",
    "combinedDS = signal.resample(combined, newLen, axis = 0)\n",
    "#combinedDS = signal.decimate(combined, 25, axis = 0)\n",
    "print('resampled', combinedDS.shape)\n",
    "combinedDSFN = os.path.join(dpath,'RawDataChannelExtractedDS.npy')\n",
    "np.save(combinedDSFN, combinedDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of notebook. \n",
    "Data is cleaned up and saved. Data processing for different cortical areas on specific notebooks. Next step is WakeRemoving notebook.\n",
    "\n",
    "Below is for quick filtering, plotting and visualisation to assess data quality. Filtering for data processing is done again in specific notebooks.\n",
    "\n",
    "Data quality is assessed on a Sample, whose value has to be attributed on the initial cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering \n",
    "\n",
    "SWR: 120 - 200 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample = filtered_GoodChannels_1\n",
    "\n",
    "f_CA1 = Sample[:, 3].copy()\n",
    "\n",
    "# Paramètres de notre filtre :\n",
    "f_lowcut = 120.\n",
    "f_hicut = 200.\n",
    "fs = new_sampling_rate\n",
    "nyq = 0.5 * fs\n",
    "N = 6                 # Ordre du filtre\n",
    "Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "print(Wn)\n",
    "\n",
    "# Création du filtre :\n",
    "b, a = scipy.signal.butter(N, Wn, 'band')\n",
    "filt_SWR_CA1 = scipy.signal.filtfilt(b, a, f_CA1)\n",
    "\n",
    "times = np.arange(0, f_CA1.size/new_sampling_rate, 1./new_sampling_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spindles: 8 - 16 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_PFC = Sample[:, 1].copy()\n",
    "f_S1 = Sample[:, 2].copy()\n",
    "\n",
    "# Paramètres de notre filtre :\n",
    "f_lowcut = 10.\n",
    "f_hicut = 16.\n",
    "Wn = [f_lowcut/nyq,f_hicut/nyq]  # Nyquist frequency fraction\n",
    "N = 4\n",
    "# Création du filtre :\n",
    "b, a = scipy.signal.butter(N, Wn, 'band')\n",
    "filt_Spind_PFC = scipy.signal.filtfilt(b, a, f_PFC)\n",
    "filt_Spind_S1 = scipy.signal.filtfilt(b, a, f_S1)\n",
    "\n",
    "# # Calcul de la reponse en fréquence du filtre\n",
    "# w, h = signal.freqz(b, a)\n",
    "\n",
    "# # Tracé de la réponse en fréquence du filtre\n",
    "# fig, ax = plt.subplots(figsize=(8,5)) \n",
    "\n",
    "# ax.plot(0.5*fs*w/np.pi, np.abs(h), 'b')\n",
    "\n",
    "# ax.set_xlabel('frequency [Hz]')\n",
    "# ax.set_ylabel('Amplitude [dB]')\n",
    "# ax.grid(which='both', axis='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFT display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du spectre\n",
    "f, Pxx_den = signal.welch(f_CA1, fs, nperseg=1024)\n",
    "\n",
    "# Tracé\n",
    "fig, ax = plt.subplots(figsize=(10,5)) \n",
    "ax.semilogy(f, Pxx_den)   #  plot with log scaling on the y axis\n",
    "ax.set_xlabel('frequency [Hz]')\n",
    "ax.set_ylabel('PSD [V**2/Hz]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display. \n",
    "\n",
    "Can massively be improved: with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_sliced = times[000:200000]\n",
    "filt_to_display = filt_SWR_CA1[000:200000]-1000\n",
    "f_CA1_sliced = f_CA1[0000:200000]/2\n",
    "combined = np.stack((f_CA1_sliced, filt_to_display), axis = 1)\n",
    "# Tracé du signal filtré\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,5), layout='constrained') \n",
    "ax.plot(times_sliced, combined, 'r')\n",
    "ax.set_xlabel('Temps [sec]')\n",
    "ax.set_ylabel('Amplitude')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ephyviewer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare numpy array for ephyviewer\n",
    "\n",
    "filt_SWR_CA1_sliced= filt_SWR_CA1[000:200000, np.newaxis]\n",
    "filt_Spind_PFC_sliced= filt_Spind_PFC[000:200000, np.newaxis]\n",
    "filt_Spind_S1_sliced= filt_Spind_S1[000:200000, np.newaxis]\n",
    "filt_sliced = Sample[0000:200000,:]\n",
    "combined2 = filt_sliced[:,0:2].copy()\n",
    "intf_sliced = filt_sliced[:,2]\n",
    "intf_sliced = intf_sliced[:, np.newaxis]\n",
    "combined2 = np.append(combined2, filt_Spind_PFC_sliced, axis=1)\n",
    "combined2 = np.append(combined2, intf_sliced, axis=1)\n",
    "combined2 = np.append(combined2, filt_Spind_S1_sliced, axis=1)\n",
    "intf_sliced = filt_sliced[:,3]\n",
    "intf_sliced = intf_sliced[:, np.newaxis]\n",
    "combined2 = np.append(combined2, intf_sliced, axis=1)\n",
    "combined2 = np.append(combined2, filt_SWR_CA1_sliced, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = mkQApp()\n",
    "\n",
    "\n",
    "sample_rate = 1000.\n",
    "t_start = 0.\n",
    "\n",
    "#Create the main window that can contain several viewers\n",
    "win = MainViewer()\n",
    "view1 = TraceViewer.from_numpy(combined2, sample_rate, t_start, 'Signals')\n",
    "win.add_view(view1)\n",
    "\n",
    "#Parameters can be set in script\n",
    "#view1.params['scale_mode'] = 'same_for_all'\n",
    "view1.params['display_labels'] = True\n",
    "#And also parameters for each channel\n",
    "view1.by_channel_params['ch0', 'color'] = '#aa0000'\n",
    "view1.by_channel_params['ch1', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch2', 'color'] = '#0055ff'\n",
    "view1.by_channel_params['ch5', 'color'] = '#ff5500'\n",
    "view1.by_channel_params['ch6', 'color'] = '#ff5500'\n",
    "\n",
    "view1.by_channel_params['ch0', 'gain'] = 0.00002\n",
    "view1.by_channel_params['ch1', 'gain'] = 0.00002\n",
    "view1.by_channel_params['ch2', 'gain'] = 0.00004\n",
    "view1.by_channel_params['ch3', 'gain'] = 0.0001\n",
    "view1.by_channel_params['ch4', 'gain'] = 0.0001\n",
    "view1.by_channel_params['ch5', 'gain'] = 0.00002\n",
    "view1.by_channel_params['ch6', 'gain'] = 0.00005\n",
    "\n",
    "view1.by_channel_params['ch0', 'offset'] = 0.3\n",
    "view1.by_channel_params['ch1', 'offset'] = 0.2\n",
    "view1.by_channel_params['ch2', 'offset'] = 0.1\n",
    "view1.by_channel_params['ch3', 'offset'] = 0.\n",
    "view1.by_channel_params['ch4', 'offset'] = -0.1\n",
    "view1.by_channel_params['ch5', 'offset'] = -0.2\n",
    "view1.by_channel_params['ch6', 'offset'] = -0.3\n",
    "\n",
    "#Run\n",
    "win.show()\n",
    "app.exec_()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('formation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "984d3fbee8ffa490637705ae3d7233e001ab0304f3daaca07b5aa8569b88ca53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
