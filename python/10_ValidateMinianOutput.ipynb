{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Minian outputs\n",
    "\n",
    "- Load\n",
    "    - spatial map (A) -> maybe to associate with a projection of neuron fluorescence\n",
    "    - temporal activity of detected neurons\n",
    "\n",
    "- Validate units\n",
    "- Extract and save relevant data for each selected unit\n",
    "    - spatial location (x, y); no need for shape\n",
    "    - Ca<sup>2+</sup> trace\n",
    "    - Ca<sup>2+</sup> peak time and amplitude\n",
    "    - Deconvolved spikes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the required packages (and many more that are not useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as itt\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import chirp, find_peaks, peak_widths\n",
    "\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import param\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from holoviews.operation.datashader import datashade, regrid\n",
    "from holoviews.util import Dynamic\n",
    "from holoviews import opts\n",
    "from holoviews import Store\n",
    "from holoviews.operation.datashader import shade\n",
    "hv.extension('bokeh', 'matplotlib')\n",
    "#from IPython.core.display import display\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "\n",
    "\n",
    "#%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048e4dc855744d36b2086c036d792654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='\\\\10.69.168.1\\crnldata\\waking\\audrey_hay\\L1imaging\\RAW\\Baseline_recording\\BlackLines\\Baselin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minian_path = os.path.join(os.path.abspath('..'),'minian')\n",
    "print(\"The folder used for minian procedures is : {}\".format(minian_path))\n",
    "\n",
    "sys.path.append(minian_path)\n",
    "from minian.utilities import (\n",
    "    open_minian,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the minian files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve dpath either from a previous run or from a previous notebook\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"the path was not defined in store\")\n",
    "    #dpath = \"/Users/mb/Documents/Syntuitio/AudreyHay/PlanB/ExampleRedLines/2022_08_06/13_30_01/My_V4_Miniscope/\"\n",
    "    dpath = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording\"\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>Folder with videos</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import spatial map, Ca<sup>2+</sup> traces, deconvolved spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # tries to retrieve minianversion either from a previous run or from a previous notebook\n",
    "    %store -r minianversion\n",
    "except:\n",
    "    print(\"the minian folder to use was not defined in store\")\n",
    "    minianversion = 'minian' # or 'minian_intermediate'\n",
    "    %store minianversion\n",
    "\n",
    "folderMouse = Path(os.path.join(dpath,minianversion))\n",
    "print(folderMouse)\n",
    "minian_ds = open_minian(folderMouse)\n",
    "\n",
    "A = minian_ds['A']\n",
    "C = minian_ds['C']\n",
    "S = minian_ds['S']\n",
    "\n",
    "B = A['unit_id']\n",
    "series = B.to_series()\n",
    "D = series.count()\n",
    "\n",
    "idloc = A.idxmax(\"unit_id\")\n",
    "Hmax = A.idxmax(\"height\")\n",
    "Hmax2 = Hmax.max(\"width\")\n",
    "\n",
    "Wmax = A.idxmax(\"width\")\n",
    "Wmax2 = Wmax.max(\"height\")\n",
    "coord1 = Wmax2.to_series()\n",
    "coord2 = Hmax2.to_series()\n",
    "\n",
    "a = pd.concat([coord1,coord2], axis=1)\n",
    "unit = len(a)\n",
    "print(\"{} units have been found\".format(unit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the actions triggered by drop/keep buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionSelect(param.Parameterized):\n",
    "    actionDrop = param.Action(default=lambda x: x.param.trigger('actionDrop'), label='Click here to drop!')\n",
    "    actionKeep = param.Action(default=lambda x: x.param.trigger('actionKeep'), label='Click here to keep!')\n",
    "\n",
    "    unit_to_keep=a.index.tolist()\n",
    "\n",
    "    unit = None\n",
    "\n",
    "    @param.depends('actionDrop')\n",
    "    def drop_unit(self):\n",
    "        if self.unit is not None:\n",
    "            number = self.unit.value\n",
    "            if number in self.unit_to_keep:\n",
    "                self.unit_to_keep.remove(number)\n",
    "                return \"The unit {} was dropped\".format(number)\n",
    "           \n",
    "    @param.depends('actionKeep')\n",
    "    def keep_unit(self):\n",
    "        if self.unit is not None:\n",
    "            number = self.unit.value\n",
    "            if number not in self.unit_to_keep:\n",
    "                self.unit_to_keep.append(number)\n",
    "                self.unit_to_keep.sort()\n",
    "                return \"The unit {} was restored\".format(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the spatial map for all cells + interactive Ca<sup>2+</sup> trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124b9e7a651648658ae3be55d81188e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'89c2967c-3e2d-48f9-877f-921bf14d970b': {'version…"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output_size = 80\n",
    "hv.output(size=int(output_size))\n",
    "\n",
    "image = hv.Image(\n",
    "    A.max(\"unit_id\").compute().astype(np.float32).rename(\"A\"),\n",
    "    kdims=[\"width\", \"height\"],\n",
    ")#.opts(**opts)\n",
    "\n",
    "#labels = hv.Labels([(a.iloc[i,0], a.iloc[i,1], a.index[i]) for i in range(5)]) #np.arange(50,100,1)\n",
    "labels = hv.Labels([(a.iloc[i,0], a.iloc[i,1], a.index[i]) for i in range(len(a))]).opts(text_color='orange',  text_font_size='9pt')\n",
    "\n",
    "plot_unit = hv.HoloMap({a.index[i]: hv.Curve((C[i,:]), group='keep') for i in range(len(a))}, kdims='Value').opts(ylim=(-0.5, 20)) #np.arange(50,100,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "selection = ActionSelect()\n",
    "\n",
    "layout = pn.Row(image * labels, plot_unit, pn.Column(\n",
    "        pn.panel(selection, show_name=False, margin=0, widgets={\"actionDrop\": {\"button_type\": \"primary\"}, }),\n",
    "    selection.drop_unit, selection.keep_unit,\n",
    "    )\n",
    "    )\n",
    "selection.unit = layout[1][1][0]\n",
    "display(layout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print list of kept and dropped units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The units kept are:\")\n",
    "print(selection.unit_to_keep)\n",
    "\n",
    "all_units=a.index.tolist()\n",
    "unit_to_drop = [e for e in all_units if e not in selection.unit_to_keep]\n",
    "print(\"\\n The units dropped are:\")\n",
    "print(unit_to_drop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove dropped units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "25\n",
      "35\n",
      "32\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "copyB = list(B.copy())\n",
    "for i in range(len(unit_to_drop)):\n",
    "    elem = unit_to_drop[i]\n",
    "    print(elem)\n",
    "    copyB.remove(elem) # IF CELL ID \n",
    "unit_to_keep = copyB\n",
    "\n",
    "A_upd = A.loc[unit_to_keep,:,:]\n",
    "C_upd = C.loc[unit_to_keep,:]\n",
    "S_upd = S.loc[unit_to_keep,:]\n",
    "\n",
    "TodropFile = os.path.join(folderMouse,'TodropFileAB.json')\n",
    "\n",
    "with open(TodropFile, 'w') as f:\n",
    "    json.dump(unit_to_drop, f, indent=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Ca<sup>2+</sup> peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For one neuron, need to be implemented for the whole set and concatenate the np into one xarray with \n",
    "\n",
    "Indiv_trace = C_upd[2,:].to_series()\n",
    "peaks, properties = find_peaks(Indiv_trace)\n",
    "# peak boundaries taken at 70% from peak of intensity. This means that the peaks with small amplitude will be longer than the big ones.\n",
    "results_width = peak_widths(Indiv_trace, peaks, rel_height=0.7)\n",
    "# Organise results in numpy array\n",
    "peaks2 = peaks.reshape(len(peaks),1)\n",
    "npresults_width = np.array(results_width).reshape(4,-1)\n",
    "peak_prop = np.append(peaks2, results_width).reshape(5,len(peaks2)).round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(unit_to_keep)):\n",
    "    Indiv_trace = C_upd[i,:].to_series()\n",
    "    peaks, properties = find_peaks(Indiv_trace)\n",
    "# peak boundaries taken at 70% from peak of intensity. This means that the peaks with small amplitude will be longer than the big ones.\n",
    "    results_width = peak_widths(Indiv_trace, peaks, rel_height=0.7)\n",
    "# Organise results in numpy array\n",
    "    peaks2 = peaks.reshape(len(peaks),1)\n",
    "    npresults_width = np.array(results_width).reshape(4,-1)\n",
    "    peak_prop = np.append(peaks2, results_width).reshape(5,len(peaks2)).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range((unit)):\n",
    "    file_path=folderMouse\n",
    "    subfolder = file_path.parents[1].stem\n",
    "    if subfolder == 'continuous':\n",
    "        recording = file_path.parents[2].stem.replace('recording','')\n",
    "        print(recording)\n",
    "        file = file_path.stem\n",
    "        print(recording, file)\n",
    "        np_arr = np.load(file_path)\n",
    "        datalen = len(np_arr)\n",
    "        print(file, datalen)\n",
    "        if recording == 1: #not in TTL_stamp2:\n",
    "            TTL_stamp2.append(recording)\n",
    "            coords = {\n",
    "                'channels' : np.array(['synchronized_timestamps', 'timestamps']),\n",
    "                'duration_rec' : np.arange(datalen)\n",
    "            }\n",
    "            globals()[f\"StampsCont_{recording}\"] = xr.DataArray(coords=coords, dims=['channels', 'duration_rec'])\n",
    "        globals()[f\"StampsCont_{recording}\"].loc[file,:] = np_arr   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MapSessionsPath = folderMouse.parents[2] / f'mappings.pkl'\n",
    "MapSessions = pd.read_pickle(MapSessionsPath)\n",
    "MapSessions\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('minian')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d28f0aa69d972f186b6eef62f149b885b857325c1e4e259a67006c9c0c737cc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
