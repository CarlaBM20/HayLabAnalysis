{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Associate Ca2+ signal with spindles for each session & subsessions using crossregistration\n",
    "\n",
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manip2\\SCRIPTS\\Code python audrey\\code python aurelie\\interfaceJupyter\\minian\n"
     ]
    }
   ],
   "source": [
    "cd \"C:/Users/Manip2/SCRIPTS/Code python audrey/code python aurelie/interfaceJupyter/minian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantities as pq\n",
    "import numpy as np\n",
    "import math \n",
    "import neo\n",
    "import json\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, Cursor\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy.signal import find_peaks\n",
    "import pickle\n",
    "import os\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.signal import find_peaks\n",
    "import logging\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "from itertools import groupby\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer\n",
    "from IPython.display import display\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "\n",
    "from minian.utilities import (\n",
    "    TaskAnnotation,\n",
    "    get_optimal_chk,\n",
    "    load_videos,\n",
    "    open_minian,\n",
    "    save_minian,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load sleep score and Ca2+ time series numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891d3fbefd3e44838587efe6edfb896c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='\\\\10.69.168.1\\crnldata\\waking\\audrey_hay\\L1imaging\\AnalysedMarch2023\\Gaelle\\Baseline_recordiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'dpath' (str)\n",
      "Stored 'dpath' (str)\n"
     ]
    }
   ],
   "source": [
    "dpath = \"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording\"\n",
    "try:\n",
    "    %store -r dpath\n",
    "except:\n",
    "    print(\"data not in strore\")\n",
    "    #dpath = \"/Users/mb/Documents/Syntuitio/AudreyHay/PlanB/ExampleRedLines/2022_08_06/13_30_01/My_V4_Miniscope/\"\n",
    "    dpath =\"//10.69.168.1/crnldata/waking/audrey_hay/L1imaging/AnalysedMarch2023/Gaelle/Baseline_recording\"\n",
    "\n",
    "# Set up Initial Basic Parameters#\n",
    "minian_path = \".\"\n",
    "\n",
    "fc1 = FileChooser(dpath,select_default=True, show_only_dirs = True, title = \"<b>Folder with videos</b>\")\n",
    "display(fc1)\n",
    "\n",
    "# Sample callback function\n",
    "def update_my_folder(chooser):\n",
    "    global dpath\n",
    "    dpath = chooser.selected\n",
    "    %store dpath\n",
    "    return \n",
    "\n",
    "# Register callback function\n",
    "fc1.register_callback(update_my_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mappingsAB.pkl opened\n",
      "session1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manip2\\SCRIPTS\\Code python audrey\\code python aurelie\\interfaceJupyter\\minian\\minian\\utilities.py:342: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "C:\\Users\\Manip2\\SCRIPTS\\Code python audrey\\code python aurelie\\interfaceJupyter\\minian\\minian\\utilities.py:342: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "session2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manip2\\SCRIPTS\\Code python audrey\\code python aurelie\\interfaceJupyter\\minian\\minian\\utilities.py:342: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "C:\\Users\\Manip2\\SCRIPTS\\Code python audrey\\code python aurelie\\interfaceJupyter\\minian\\minian\\utilities.py:342: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "session3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manip2\\SCRIPTS\\Code python audrey\\code python aurelie\\interfaceJupyter\\minian\\minian\\utilities.py:342: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "C:\\Users\\Manip2\\SCRIPTS\\Code python audrey\\code python aurelie\\interfaceJupyter\\minian\\minian\\utilities.py:342: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "session4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manip2\\SCRIPTS\\Code python audrey\\code python aurelie\\interfaceJupyter\\minian\\minian\\utilities.py:342: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n",
      "C:\\Users\\Manip2\\SCRIPTS\\Code python audrey\\code python aurelie\\interfaceJupyter\\minian\\minian\\utilities.py:342: RuntimeWarning: Failed to open Zarr store with consolidated metadata, but successfully read with non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  arr = list(xr.open_zarr(arr_path).values())[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "folder_base = Path(dpath)\n",
    "\n",
    "nb_sessions = sum(1 for p in folder_base.iterdir() if p.is_dir() and p.name.startswith(\"session\"))\n",
    "\n",
    "try:\n",
    "    mfile = open(folder_base / f'mappingsAB.pkl', 'rb')\n",
    "    mapping = pickle.load(mfile)\n",
    "    print('mappingsAB.pkl opened')\n",
    "except:\n",
    "    mfile = open(folder_base / f'mappings.pkl', 'rb')\n",
    "    mapping = pickle.load(mfile)\n",
    "    print('mappings.pkl opened')\n",
    "\n",
    "sessions = []\n",
    "subsessions = []\n",
    "nb_minian_total=0\n",
    "dict_Calcium = {}\n",
    "dict_Spike = {}\n",
    "dict_SWRprop = {}\n",
    "dict_Spindleprop_PFC = {}\n",
    "dict_Spindleprop_S1 = {}\n",
    "dict_Stamps = {}\n",
    "dict_StampsMiniscope = {}\n",
    "dict_TodropFile = {}\n",
    "\n",
    "for y in range(1, nb_sessions+1):\n",
    "    session= 'session' + str(y)\n",
    "    print(session)\n",
    "    sessions.append(session)\n",
    "    folder_mini = folder_base / f'session{y}/V4_Miniscope'\n",
    "    nb_subsessions = sum(1 for p in folder_mini.iterdir() if p.is_dir() and p.name.startswith(\"session\"))\n",
    "    SWRproperties = folder_base / f'session{y}/OpenEphys/SWRproperties_AB.csv'\n",
    "    Spindleproperties_PFC = folder_base / f'session{y}/OpenEphys/Spindlesproperties_PFC_AB.csv'\n",
    "    Spindleproperties_S1 = folder_base / f'session{y}/OpenEphys/Spindlesproperties_S1_AB.csv'\n",
    "    StampsFile = folder_base / f'session{y}/SynchroFile.xlsx'\n",
    "    StampsMiniscopeFile = folder_mini / f'timeStamps.csv'\n",
    "    if nb_subsessions!=0:\n",
    "        for x in range(1, nb_subsessions+1):            \n",
    "            subsession= \"session\"  + str(y) + str(x)\n",
    "            subsessions.append(subsession)    \n",
    "            minian_ds = open_minian(folder_mini / subsession / f'minian')      # OR minianAB\n",
    "            dict_Calcium[subsession] = minian_ds['C'] # calcium traces \n",
    "            dict_Spike[subsession] = minian_ds['S'] # estimated spikes\n",
    "            dict_SWRprop[subsession]  = pd.read_csv(SWRproperties)\n",
    "            dict_Spindleprop_PFC[subsession]  = pd.read_csv(Spindleproperties_PFC)\n",
    "            dict_Spindleprop_S1[subsession]  = pd.read_csv(Spindleproperties_S1)\n",
    "            dict_Stamps[subsession]  = pd.read_excel(StampsFile)\n",
    "            dict_StampsMiniscope[subsession]  = pd.read_csv(StampsMiniscopeFile)\n",
    "            try:\n",
    "                TodropFile = folder_mini / subsession / f'minian/TodropFileAB.json'\n",
    "                with open(TodropFile, 'r') as f:\n",
    "                    unit_to_drop = json.load(f)\n",
    "                    dict_TodropFile[subsession]  = unit_to_drop\n",
    "            except:\n",
    "                TodropFile = folder_mini / subsession / f'minian/TodropFile.json'\n",
    "                with open(TodropFile, 'r') as f:\n",
    "                    unit_to_drop = json.load(f)\n",
    "                    dict_TodropFile[subsession]  = unit_to_drop\n",
    "            nb_minian_total+=1\n",
    "            print(nb_minian_total)\n",
    "    else:\n",
    "        minian_ds = open_minian(folder_mini / f'minian')            # OR minianAB\n",
    "        dict_Calcium[session] = minian_ds['C'] # calcium traces \n",
    "        dict_Spike[session] = minian_ds['S'] # estimated spikes\n",
    "        dict_SWRprop[session]  = pd.read_csv(SWRproperties)\n",
    "        dict_Spindleprop_PFC[session]  = pd.read_csv(Spindleproperties_PFC)\n",
    "        dict_Spindleprop_S1[session]  = pd.read_csv(Spindleproperties_S1)\n",
    "        dict_Stamps[session]  = pd.read_excel(StampsFile)\n",
    "        dict_StampsMiniscope[session]  = pd.read_csv(StampsMiniscopeFile)\n",
    "        try:\n",
    "            TodropFile = folder_mini / f'minian/TodropFileAB.json'\n",
    "            with open(TodropFile, 'r') as f:\n",
    "                unit_to_drop = json.load(f)\n",
    "                dict_TodropFile[session]  = unit_to_drop\n",
    "        except:\n",
    "            TodropFile = folder_mini / f'minian/TodropFile.json'\n",
    "            with open(TodropFile, 'r') as f:\n",
    "                unit_to_drop = json.load(f)\n",
    "                dict_TodropFile[session]  = unit_to_drop\n",
    "        nb_minian_total+=1  \n",
    "        print(nb_minian_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross registration results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unit nÂ° 0\n",
      "= unit 12 in session1\n",
      "= unit 62 in session2\n",
      "= unit 17 in session3\n",
      "= unit 24 in session4\n",
      "unit nÂ° 1\n",
      "= unit 10 in session1\n",
      "= unit 43 in session2\n",
      "= unit 12 in session3\n",
      "unit nÂ° 2\n",
      "= unit 16 in session1\n",
      "= unit 86 in session2\n",
      "unit nÂ° 3\n",
      "= unit 3 in session1\n",
      "= unit 19 in session2\n",
      "= unit 1 in session3\n",
      "= unit 11 in session4\n",
      "unit nÂ° 4\n",
      "= unit 14 in session1\n",
      "= unit 64 in session2\n",
      "= unit 20 in session3\n",
      "= unit 25 in session4\n",
      "unit nÂ° 5\n",
      "= unit 9 in session1\n",
      "= unit 37 in session2\n",
      "= unit 9 in session3\n",
      "= unit 18 in session4\n",
      "unit nÂ° 6\n",
      "= unit 91 in session2\n",
      "= unit 24 in session3\n",
      "unit nÂ° 7\n",
      "= unit 35 in session2\n",
      "= unit 7 in session3\n",
      "unit nÂ° 8\n",
      "= unit 59 in session2\n",
      "= unit 15 in session3\n",
      "unit nÂ° 9\n",
      "= unit 20 in session2\n",
      "= unit 3 in session3\n",
      "unit nÂ° 10\n",
      "= unit 88 in session2\n",
      "= unit 23 in session3\n",
      "unit nÂ° 11\n",
      "= unit 38 in session2\n",
      "= unit 10 in session3\n",
      "unit nÂ° 12\n",
      "= unit 100 in session2\n",
      "= unit 26 in session3\n",
      "unit nÂ° 13\n",
      "= unit 0 in session1\n",
      "unit nÂ° 14\n",
      "= unit 103 in session2\n",
      "unit nÂ° 15\n",
      "= unit 40 in session2\n",
      "unit nÂ° 16\n",
      "= unit 71 in session2\n",
      "unit nÂ° 17\n",
      "= unit 79 in session2\n",
      "unit nÂ° 18\n",
      "= unit 122 in session2\n",
      "unit nÂ° 19\n",
      "= unit 5 in session3\n",
      "unit nÂ° 20\n",
      "= unit 6 in session3\n",
      "unit nÂ° 21\n",
      "= unit 11 in session3\n",
      "unit nÂ° 22\n",
      "= unit 13 in session3\n",
      "unit nÂ° 23\n",
      "= unit 18 in session3\n",
      "unit nÂ° 24\n",
      "= unit 19 in session3\n",
      "unit nÂ° 25\n",
      "= unit 27 in session3\n"
     ]
    }
   ],
   "source": [
    "B = mapping['session']\n",
    "if os.path.basename(folder_base) == 'Purple':\n",
    "    index = B.columns\n",
    "    B.columns = index.str.replace('part', 'session2')\n",
    "        \n",
    "for c in range(len(B)):\n",
    "    print('unit nÂ°', c)\n",
    "    for sess in list(dict_Stamps.keys()):\n",
    "        print('= unit', int(B[sess][c]), 'in', sess) if math.isnan (float(B[sess][c])) == False else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def take_closest(myList, myNumber):\n",
    "    \"\"\"\n",
    "    Assumes myList is sorted. Returns closest value to myNumber.\n",
    "    If two numbers are equally close, return the smallest number.\n",
    "    \"\"\"\n",
    "    pos = bisect_left(myList, myNumber)\n",
    "    if pos == 0:\n",
    "        return 0\n",
    "    if pos == len(myList):\n",
    "        return len(myList)\n",
    "    before = myList[pos - 1]\n",
    "    after = myList[pos]\n",
    "    if after - myNumber < myNumber - before:\n",
    "        return after\n",
    "    else:\n",
    "        return before\n",
    "\n",
    "def take_closest2(myList, myNumber):\n",
    "    value2 = 10000000\n",
    "    for ind in range(len(myList)):\n",
    "        value = abs(myList[ind]-myNumber)\n",
    "        if value < value2:\n",
    "            value2 = value\n",
    "            index = myList[ind]\n",
    "    return index\n",
    "\n",
    "\n",
    "def take_closest3(myList, myNumber):\n",
    "    pos = bisect_left(myList, myNumber)\n",
    "    if pos == 0:\n",
    "        return myList[0]\n",
    "    if pos == len(myList):\n",
    "        return myList[-1]\n",
    "    before = myList[pos - 1]\n",
    "    after = myList[pos]\n",
    "    if after - myNumber < myNumber - before:\n",
    "        dummy = myList.index(after)\n",
    "        return dummy\n",
    "    else:\n",
    "        dummy = myList.index(before)\n",
    "        return dummy\n",
    "    \n",
    "\n",
    "def is_between(myList, starttime, endtime):\n",
    "    IsTrue='False'\n",
    "    for ind in range(len(myList)):\n",
    "        if starttime <= myList[ind] <= endtime:\n",
    "            IsTrue='True'\n",
    "    return IsTrue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribute Ca2+ intensity & spikes to vigilance state for each sessions/subsessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session1 : starts at 3.8 s & ends at 895.5 s ( 891.7 s duration,  0 dropped frames, minian frequency = 20 )...\n",
      "... kept values = ['[3]', '[5]', '[1]', '[0]', '[4]', '[2]']\n",
      "... in PFC: 7 spindles (1 Pre, 0 Post & 6 Uncoupled Spdl) and 119 SWR detected (1 Pre, 0 Post & 118 Uncoupled SWR)\n",
      "session2 : starts at 3.5 s & ends at 939.7 s ( 936.1 s duration,  0 dropped frames, minian frequency = 20 )...\n",
      "... kept values = ['[3]', '[9]', '[7]', '[5]', '[11]', '[15]', '[1]', '[8]', '[0]', '[4]', '[16]', '[17]', '[2]', '[10]', '[6]', '[12]', '[14]', '[18]']\n",
      "... in PFC: 7 spindles (1 Pre, 2 Post & 4 Uncoupled Spdl) and 107 SWR detected (1 Pre, 3 Post & 103 Uncoupled SWR)\n",
      "session3 : starts at 3.5 s & ends at 896.5 s ( 893.0 s duration,  0 dropped frames, minian frequency = 20 )...\n",
      "... kept values = ['[3]', '[9]', '[19]', '[7]', '[5]', '[11]', '[21]', '[1]', '[8]', '[0]', '[23]', '[4]', '[10]', '[6]', '[12]']\n",
      "... in PFC: 13 spindles (2 Pre, 0 Post & 11 Uncoupled Spdl) and 98 SWR detected (3 Pre, 0 Post & 95 Uncoupled SWR)\n",
      "session4 : starts at 3.5 s & ends at 1785.9 s ( 1782.5 s duration,  1 dropped frames, minian frequency = 20 )...\n",
      "... kept values = ['[3]', '[5]', '[0]', '[4]']\n",
      "... in PFC: 14 spindles (1 Pre, 2 Post & 11 Uncoupled Spdl) and 157 SWR detected (1 Pre, 2 Post & 154 Uncoupled SWR)\n",
      "Nb of unique units for BlackLinesOK = 21\n",
      "session1 : starts at 3.8 s & ends at 895.5 s ( 891.7 s duration,  0 dropped frames, minian frequency = 20 )...\n",
      "... kept values = ['[3]', '[5]', '[1]', '[0]', '[4]', '[2]']\n",
      "... in S1: 17 spindles (0 Pre, 1 Post & 16 Uncoupled Spdl) and 119 SWR detected (0 Pre, 1 Post & 118 Uncoupled SWR)\n",
      "session2 : starts at 3.5 s & ends at 939.7 s ( 936.1 s duration,  0 dropped frames, minian frequency = 20 )...\n",
      "... kept values = ['[3]', '[9]', '[7]', '[5]', '[11]', '[15]', '[1]', '[8]', '[0]', '[4]', '[16]', '[17]', '[2]', '[10]', '[6]', '[12]', '[14]', '[18]']\n",
      "... in S1: 21 spindles (1 Pre, 1 Post & 19 Uncoupled Spdl) and 107 SWR detected (1 Pre, 1 Post & 105 Uncoupled SWR)\n",
      "session3 : starts at 3.5 s & ends at 896.5 s ( 893.0 s duration,  0 dropped frames, minian frequency = 20 )...\n",
      "... kept values = ['[3]', '[9]', '[19]', '[7]', '[5]', '[11]', '[21]', '[1]', '[8]', '[0]', '[23]', '[4]', '[10]', '[6]', '[12]']\n",
      "... in S1: 20 spindles (0 Pre, 1 Post & 19 Uncoupled Spdl) and 98 SWR detected (0 Pre, 1 Post & 97 Uncoupled SWR)\n",
      "session4 : starts at 3.5 s & ends at 1785.9 s ( 1782.5 s duration,  1 dropped frames, minian frequency = 20 )...\n",
      "... kept values = ['[3]', '[5]', '[0]', '[4]']\n",
      "... in S1: 29 spindles (1 Pre, 3 Post & 25 Uncoupled Spdl) and 157 SWR detected (1 Pre, 3 Post & 153 Uncoupled SWR)\n",
      "Nb of unique units for BlackLinesOK = 21\n"
     ]
    }
   ],
   "source": [
    "CortexList= ['PFC', 'S1']\n",
    "plt.close()\n",
    "for Cortex in CortexList:\n",
    "\n",
    "    data = {}\n",
    "    \n",
    "    before = 1000 # Max distance in ms between a SWR and a spindle to be considered as Precoupled\n",
    "    after = 1000 # Max distance in ms between a spindle and a SWR to be considered as Postcoupled\n",
    "    durationSpdl = 2 # number of sec before and after the Spdl onset taken into acount\n",
    "    durationSWR = 0.5 # number of sec before and after the Spdl onset taken into acount\n",
    "    counter=0\n",
    "    counter2=0\n",
    "\n",
    "    norm_freq=10 # final miniscope frequency used for all recordings\n",
    "\n",
    "    Spindles_GlobalResults= pd.DataFrame(data, columns=['Mice', 'Session','Session_Time','Unique_Unit','UnitNumber','UnitValue','SpdlStatut','SpdlNumber','SpdlDuration (ms)','SWR inside Spdl','CalciumActivityPreference', 'CalciumActivityBefore','CalciumActivityAfter','AUC_calciumBefore','AUC_calciumAfter','SpikeActivityPreference','SpikeActivityBefore','SpikeActivityAfter','AUC_spikeBefore', 'AUC_spikeAfter'])\n",
    "    SWR_GlobalResults= pd.DataFrame(data, columns=['Mice', 'Session','Session_Time','Unique_Unit','UnitNumber','UnitValue','SWRStatut','SWRNumber','SWRDuration (ms)','SWR inside Spdl','CalciumActivityPreference', 'CalciumActivityBefore','CalciumActivityAfter','AUC_calciumBefore','AUC_calciumAfter','SpikeActivityPreference','SpikeActivityBefore','SpikeActivityAfter','AUC_spikeBefore', 'AUC_spikeAfter'])\n",
    "\n",
    "    dict_All_ActivityCa_spin={}\n",
    "    dict_All_ActivityCa_spin_Precoupled={}\n",
    "    dict_All_ActivityCa_spin_Postcoupled={}\n",
    "    dict_All_ActivityCa_spin_Uncoupled={}\n",
    "\n",
    "    dict_All_ActivityCa_swr={}\n",
    "    dict_All_ActivityCa_swr_Precoupled={}\n",
    "    dict_All_ActivityCa_swr_Postcoupled={}\n",
    "    dict_All_ActivityCa_swr_Uncoupled={}\n",
    "\n",
    "    dict_All_ActivitySp_spin={}\n",
    "    dict_All_ActivitySp_spin_Precoupled={}\n",
    "    dict_All_ActivitySp_spin_Postcoupled={}\n",
    "    dict_All_ActivitySp_spin_Uncoupled={}\n",
    "\n",
    "    dict_All_ActivitySp_swr={}\n",
    "    dict_All_ActivitySp_swr_Precoupled={}\n",
    "    dict_All_ActivitySp_swr_Postcoupled={}\n",
    "    dict_All_ActivitySp_swr_Uncoupled={}\n",
    "\n",
    "    previousEndTime=0\n",
    "    InitialStartTime=0\n",
    "\n",
    "    for i in list(dict_Stamps.keys()):    \n",
    "        cPreCoupled=0\n",
    "        cPostCoupled=0\n",
    "        cUnCoupled=0\n",
    "\n",
    "        cPreCoupledSWR=0\n",
    "        cPostCoupledSWR=0\n",
    "        cUnCoupledSWR=0\n",
    "        \n",
    "        # Start time & freq miniscope\n",
    "        StartTime = list(dict_Stamps[i][0])[0] # in seconds\n",
    "        minian_freq=list(dict_Stamps[i][0])[2] # in Hz\n",
    "\n",
    "        # start time session 2\n",
    "        def Convert(string):\n",
    "            li = list(string.split(\", \"))\n",
    "            li2 = len(li)\n",
    "            return li2\n",
    "        stri = dict_Stamps[i][0][3]\n",
    "        numbdropfr = Convert(stri)\n",
    "\n",
    "        from ast import literal_eval\n",
    "        list_droppedframes = literal_eval(dict_Stamps[i][0][3])\n",
    "\n",
    "        First_frame = 0 #StartTime*minian_freq \n",
    "        C=dict_Calcium[i]\n",
    "        Cupd = C.loc[:, :] #C.loc[:, First_frame:]\n",
    "        rec_dur = Cupd.shape[1]\n",
    "        S=dict_Spike[i] \n",
    "        Supd = S.loc[:, :] #S.loc[:, :]\n",
    "\n",
    "        if InitialStartTime==0:\n",
    "            InitialStartTime=StartTime    \n",
    "        else:\n",
    "            if StartTime == InitialStartTime:\n",
    "                StartTime = previousEndTime + 1/minian_freq #  +1 frame in seconds \n",
    "            else:  \n",
    "                InitialStartTime=StartTime   \n",
    "\n",
    "        if len(list_droppedframes) > 0:\n",
    "            numbdropfr = sum(1 for item in list_droppedframes if item < (int(StartTime*minian_freq) + rec_dur) and item > int(StartTime*minian_freq))\n",
    "        else:\n",
    "            numbdropfr = 0   \n",
    "\n",
    "        EndTime = StartTime + ((rec_dur + numbdropfr)/minian_freq) # in seconds\n",
    "        previousEndTime=EndTime     \n",
    "\n",
    "        print(i, ': starts at', round(StartTime,1), 's & ends at', round(EndTime,1), 's (', round((rec_dur + numbdropfr)/minian_freq,1), 's duration, ', numbdropfr, 'dropped frames, minian frequency =', minian_freq, ')...') \n",
    "        \n",
    "        AA = C['unit_id']\n",
    "        copyAA = list(AA.copy())\n",
    "        unit_to_drop=dict_TodropFile[i]    \n",
    "        for u in unit_to_drop:\n",
    "            copyAA.remove(u)\n",
    "        unit_to_keep = copyAA\n",
    "        Cupd = Cupd.loc[unit_to_keep,:]\n",
    "        Supd = Supd.loc[unit_to_keep,:]\n",
    "        nb_unit = Cupd.shape[0]\n",
    "        units = range(nb_unit)\n",
    "        \n",
    "        Cseries = Cupd.to_series()\n",
    "        C_upd_unit_id = Cupd['unit_id'].values\n",
    "        Sseries = Supd.to_series()\n",
    "        #sentence1= f\"... kept values = {C_upd_unit_id}\"\n",
    "\n",
    "        kept_uniq_unit_List=[]\n",
    "        for unit in units:\n",
    "            indexMapp = np.where(B[i] == C_upd_unit_id[unit])[0]\n",
    "            kept_uniq_unit_List.append(str(indexMapp))\n",
    "\n",
    "        sentence1= f\"... kept values = {kept_uniq_unit_List}\"\n",
    "        print(sentence1) \n",
    "        \n",
    "        dictnameSpdl=f'dict_Spindleprop_{Cortex}' #change dict according to the cortex \n",
    "        dictSpdl = globals()[dictnameSpdl]\n",
    "\n",
    "        SpipropO=dictSpdl[i]\n",
    "        SpipropM=SpipropO.copy()\n",
    "        SWRpropO=dict_SWRprop[i]\n",
    "        SWRpropM=SWRpropO.copy()\n",
    "        SpipropM[[\"peak time\", \"start time\", \"end time\"]] = SpipropM[[\"peak time\", \"start time\", \"end time\"]]-(StartTime*1000)\n",
    "        SWRpropM[[\"peak time\", \"start time\", \"end time\"]] = SWRpropM[[\"peak time\", \"start time\", \"end time\"]]-(StartTime*1000)        \n",
    "\n",
    "        timeSpdl = range(int(durationSpdl*2*minian_freq))\n",
    "        HalfSpdl = int(durationSpdl*minian_freq)\n",
    "        \n",
    "        timeSWR = range(int(durationSWR*2*minian_freq))\n",
    "        HalfSWR = int(durationSWR*minian_freq)\n",
    "\n",
    "        TimeStamps_miniscope=list(dict_StampsMiniscope[i][\"Time Stamp (ms)\"]) # + (StartTime*1000))\n",
    "\n",
    "        SpipropTrunc = SpipropM[SpipropM[\"start time\"]>0]\n",
    "        SpipropTrunc = SpipropTrunc[SpipropTrunc[\"start time\"]< (EndTime-StartTime)*1000]\n",
    "        SWRpropTrunc = SWRpropM[SWRpropM[\"start time\"]>0]\n",
    "        SWRpropTrunc = SWRpropTrunc[SWRpropTrunc[\"start time\"] < (EndTime-StartTime)*1000]\n",
    "    \n",
    "        nb_spindle = SpipropTrunc.shape[0]\n",
    "        nb_swr = SWRpropTrunc.shape[0]\n",
    "\n",
    "        for ii, unit in enumerate(units): # for each kept units (cause Cseries/Sseries only have kept units)\n",
    "\n",
    "            lCseries = np.array(Cseries)[(unit)*(rec_dur + numbdropfr):(unit+1)*(rec_dur + numbdropfr)]\n",
    "            lSseries = np.array(Sseries)[(unit)*(rec_dur + numbdropfr):(unit+1)*(rec_dur + numbdropfr)]\n",
    "            ActivityCa_Spin = [] #For each unit  \n",
    "            ActivityCa_Spin_Precoupled= [] #For each unit \n",
    "            ActivityCa_Spin_Postcoupled= [] #For each unit \n",
    "            ActivityCa_Spin_Uncoupled= [] #For each unit \n",
    "            ActivitySp_Spin = [] #For each unit  \n",
    "            ActivitySp_Spin_Precoupled= [] #For each unit \n",
    "            ActivitySp_Spin_Postcoupled= [] #For each unit \n",
    "            ActivitySp_Spin_Uncoupled= [] #For each unit \n",
    "            startSpiList = list(pd.Series(SpipropTrunc[\"start time\"]))\n",
    "            endSpiList = list(pd.Series(SpipropTrunc[\"end time\"]))\n",
    "\n",
    "            for Pspin in range(nb_spindle): \n",
    "                \n",
    "                # Get the calcium and spike trace associated with the spdl\n",
    "                startSpi=startSpiList[Pspin]\n",
    "                endSpi=endSpiList[Pspin]\n",
    "                Frame_Spindle_start =int(startSpi/1000*minian_freq)\n",
    "                CaTrace = list(lCseries[Frame_Spindle_start-HalfSpdl:Frame_Spindle_start+HalfSpdl])\n",
    "                SpTraceO = list(lSseries[Frame_Spindle_start-HalfSpdl:Frame_Spindle_start+HalfSpdl]) \n",
    "                peaks, _ = find_peaks(SpTraceO, height=np.std(SpTraceO))\n",
    "                SpTrace=np.zeros(len(SpTraceO))\n",
    "                SpTrace[peaks]=1\n",
    "\n",
    "                if len(CaTrace)<len(timeSpdl): \n",
    "                    print(\" /!\\ Spindle too close to the begining/end of the recording,\", i, \", Spdl nÂ°\", Pspin, \", Start Spdl =\", int(startSpi), \"ms, Start Rec =\", int(Frame_Spindle_start), 'ms') if ii==0 else None            \n",
    "                else:\n",
    "                    ActivityCa_Spin.append(CaTrace)\n",
    "                    ActivitySp_Spin.append(SpTraceO)\n",
    "\n",
    "                    # Define if that spindle is coupled with a SWR or not\n",
    "                    Spdl_statut=[]\n",
    "                    startSWRList = list(pd.Series(SWRpropTrunc[\"start time\"]))\n",
    "                    if len(startSWRList)>0:\n",
    "                        startClosest_SWR = take_closest2(startSWRList, startSpi)\n",
    "                        distance = startClosest_SWR - startSpi\n",
    "                        if (distance > (- before)) and (distance <  0):\n",
    "                            Spdl_statut = ['PreCoupled']\n",
    "                            cPreCoupled+=1 if ii==1 else 0\n",
    "                            ActivityCa_Spin_Precoupled.append(CaTrace)\n",
    "                            ActivitySp_Spin_Precoupled.append(SpTraceO)\n",
    "                        elif (distance > (0)) and (distance <  after):\n",
    "                            Spdl_statut = ['PostCoupled']\n",
    "                            cPostCoupled+=1 if ii==1 else 0\n",
    "                            ActivityCa_Spin_Postcoupled.append(CaTrace)\n",
    "                            ActivitySp_Spin_Postcoupled.append(SpTraceO)\n",
    "                        else:\n",
    "                            Spdl_statut= ['UnCoupled']\n",
    "                            cUnCoupled+=1 if ii==1 else 0\n",
    "                            ActivityCa_Spin_Uncoupled.append(CaTrace)\n",
    "                            ActivitySp_Spin_Uncoupled.append(SpTraceO)\n",
    "                    else:\n",
    "                        Spdl_statut= ['UnCoupled']\n",
    "                        cUnCoupled+=1 if ii==1 else 0\n",
    "                        ActivityCa_Spin_Uncoupled.append(CaTrace)\n",
    "                        ActivitySp_Spin_Uncoupled.append(SpTraceO)\n",
    "\n",
    "                    Spindles_GlobalResults.loc[counter, 'Mice'] = os.path.basename(folder_base)\n",
    "                    Spindles_GlobalResults.loc[counter, 'Session'] = i \n",
    "                    Spindles_GlobalResults.loc[counter, 'Session_Time'] = None \n",
    "                    mapping['session'].columns.tolist()\n",
    "\n",
    "                    indexMapp = np.where(B[i] == C_upd_unit_id[unit])[0]\n",
    "                    Spindles_GlobalResults.loc[counter, 'Unique_Unit'] = indexMapp \n",
    "                    Spindles_GlobalResults.loc[counter, 'UnitNumber'] = unit \n",
    "                    Spindles_GlobalResults.loc[counter, 'UnitValue'] = C_upd_unit_id[unit] \n",
    "                    Spindles_GlobalResults.loc[counter, 'SpdlStatut'] = Spdl_statut\n",
    "                    Spindles_GlobalResults.loc[counter, 'SpdlNumber'] = Pspin\n",
    "                    Spindles_GlobalResults.loc[counter, 'SpdlDuration (ms)'] = endSpi- startSpi\n",
    "                    IsTrue=is_between(startSWRList,startSpi, endSpi)\n",
    "                    Spindles_GlobalResults.loc[counter, 'SWR inside Spdl'] = IsTrue\n",
    "                    \n",
    "                    if np.mean(CaTrace[:HalfSpdl],0) > np.mean(CaTrace[HalfSpdl:],0):\n",
    "                        pref='Before'\n",
    "                    elif np.mean(CaTrace[:HalfSpdl],0) < np.mean(CaTrace[HalfSpdl:],0):\n",
    "                        pref='After' \n",
    "                    else:\n",
    "                        pref='None'\n",
    "                    Spindles_GlobalResults.loc[counter, 'CalciumActivityPreference'] = pref\n",
    "                    Spindles_GlobalResults.loc[counter, 'CalciumActivityBefore'] = np.mean(CaTrace[:HalfSpdl],0)\n",
    "                    Spindles_GlobalResults.loc[counter, 'CalciumActivityAfter'] = np.mean(CaTrace[HalfSpdl:],0)\n",
    "                    Spindles_GlobalResults.loc[counter, 'AUC_calciumBefore'] = np.trapz(CaTrace[:HalfSpdl],np.arange(0,len(CaTrace[:HalfSpdl]),1))\n",
    "                    Spindles_GlobalResults.loc[counter, 'AUC_calciumAfter'] = np.trapz(CaTrace[HalfSpdl:],np.arange(0,len(CaTrace[HalfSpdl:]),1))          \n",
    "                    \n",
    "                    if np.sum(SpTrace[:HalfSpdl],0) > np.sum(SpTrace[HalfSpdl:],0):\n",
    "                        pref='Before'\n",
    "                    elif np.sum(SpTrace[:HalfSpdl],0) < np.sum(SpTrace[HalfSpdl:],0):\n",
    "                        pref='After' \n",
    "                    else:\n",
    "                        pref='None'\n",
    "                    Spindles_GlobalResults.loc[counter, 'SpikeActivityPreference'] = pref\n",
    "                    Spindles_GlobalResults.loc[counter, 'SpikeActivityBefore'] = np.sum(SpTrace[:HalfSpdl],0)\n",
    "                    Spindles_GlobalResults.loc[counter, 'SpikeActivityAfter'] = np.sum(SpTrace[HalfSpdl:],0)\n",
    "                    counter+=1  \n",
    "\n",
    "            # All Ca traces for each spindles per Unique unit (according to cross-registration)\n",
    "\n",
    "            list_ActivityCa= ['ActivityCa_Spin', 'ActivityCa_Spin_Precoupled', 'ActivityCa_Spin_Postcoupled', 'ActivityCa_Spin_Uncoupled']\n",
    "            list_dict_All_ActivityCa= ['dict_All_ActivityCa_spin', 'dict_All_ActivityCa_spin_Precoupled', 'dict_All_ActivityCa_spin_Postcoupled', 'dict_All_ActivityCa_spin_Uncoupled']\n",
    "            for it, ActivityCaNames in enumerate(list_ActivityCa): # for each Spdl types\n",
    "                if len(indexMapp) > 0: #not empty --> cause some units are not in the cross registration..! Need to know why \n",
    "\n",
    "                    ActivityCa = locals()[ActivityCaNames]\n",
    "                    dict_All_ActivityCa = locals()[list_dict_All_ActivityCa[it]]       \n",
    "                    if len(ActivityCa)>0 :    \n",
    "                        if np.shape(np.array(ActivityCa))[1] == int(norm_freq*durationSpdl*2):  #normalize traces to the same frequency rate         \n",
    "                            ActivityCa= np.reshape(np.array(ActivityCa), (-1, len(np.array(ActivityCa)))) if np.ndim(ActivityCa) == 1 else np.array(ActivityCa)    \n",
    "                            dict_All_ActivityCa[str(indexMapp)] = np.append(dict_All_ActivityCa[str(indexMapp)], np.array(ActivityCa), axis=0) if str(indexMapp) in dict_All_ActivityCa else np.array(ActivityCa)\n",
    "                        else:\n",
    "                            dataO = np.array(ActivityCa)\n",
    "                            data= np.repeat(dataO, 2, axis=0) if dataO.shape[0] == 1 else dataO\n",
    "                            x_mesh, y_mesh = np.meshgrid(np.arange(data.shape[1]), np.arange(data.shape[0]))\n",
    "                            x_new_mesh, y_new_mesh = np.meshgrid(np.linspace(0, data.shape[1] - 1, int(norm_freq*durationSpdl*2)), np.linspace(0, data.shape[0] - 1, np.shape(data)[0]))\n",
    "                            resampled_dataO = griddata((x_mesh.flatten(), y_mesh.flatten()), data.flatten(), (x_new_mesh, y_new_mesh), method='linear')\n",
    "                            resampled_data= resampled_dataO[0,:] if dataO.shape[0] == 1 else resampled_dataO\n",
    "                            resampled_data= np.reshape(resampled_data, (-1, len(resampled_data))) if np.ndim(resampled_data) == 1 else resampled_data\n",
    "                            dict_All_ActivityCa[str(indexMapp)] = np.append(dict_All_ActivityCa[str(indexMapp)], np.array(resampled_data), axis=0) if str(indexMapp) in dict_All_ActivityCa else np.array(resampled_data)\n",
    "                    sentence1bis=\"\"\n",
    "                else: \n",
    "                    sentence1bis=f\"/!\\ Cell idx {unit} not in the cross registration\" if it==1 else \"\"\n",
    "                    print(sentence1bis) if it==1 else None\n",
    "\n",
    "            # All Sp traces for each spindles per Unique unit (according to cross-registration)\n",
    "\n",
    "            list_ActivitySp= ['ActivitySp_Spin', 'ActivitySp_Spin_Precoupled', 'ActivitySp_Spin_Postcoupled', 'ActivitySp_Spin_Uncoupled']\n",
    "            list_dict_All_ActivitySp= ['dict_All_ActivitySp_spin', 'dict_All_ActivitySp_spin_Precoupled', 'dict_All_ActivitySp_spin_Postcoupled', 'dict_All_ActivitySp_spin_Uncoupled']\n",
    "            for it, ActivitySpNames in enumerate(list_ActivitySp): # for each Spdl types\n",
    "                if len(indexMapp) > 0: #not empty --> cause some units are not in the cross registration..! Need to know why \n",
    "\n",
    "                    ActivitySp = locals()[ActivitySpNames]\n",
    "                    dict_All_ActivitySp = locals()[list_dict_All_ActivitySp[it]]       \n",
    "                    if len(ActivitySp)>0 :    \n",
    "                        if np.shape(np.array(ActivitySp))[1] == int(norm_freq*durationSpdl*2):  #normalize traces to the same frequency rate         \n",
    "                            ActivitySp= np.reshape(np.array(ActivitySp), (-1, len(np.array(ActivitySp)))) if np.ndim(ActivitySp) == 1 else np.array(ActivitySp)    \n",
    "                            for cl in range(len(ActivitySp)):\n",
    "                                resampled_data_col=ActivitySp[cl]\n",
    "                                peaks, _ = find_peaks(resampled_data_col, height=np.std(resampled_data_col))\n",
    "                                SpTrace=np.zeros(len(resampled_data_col))\n",
    "                                SpTrace[peaks]=1\n",
    "                                ActivitySp[cl]=SpTrace                                \n",
    "                            dict_All_ActivitySp[str(indexMapp)] = np.append(dict_All_ActivitySp[str(indexMapp)], np.array(ActivitySp), axis=0) if str(indexMapp) in dict_All_ActivitySp else np.array(ActivitySp)\n",
    "                        else:\n",
    "                            dataO = np.array(ActivitySp)\n",
    "                            data= np.repeat(dataO, 2, axis=0) if dataO.shape[0] == 1 else dataO\n",
    "                            x_mesh, y_mesh = np.meshgrid(np.arange(data.shape[1]), np.arange(data.shape[0]))\n",
    "                            x_new_mesh, y_new_mesh = np.meshgrid(np.linspace(0, data.shape[1] - 1, int(norm_freq*durationSpdl*2)), np.linspace(0, data.shape[0] - 1, np.shape(data)[0]))\n",
    "                            resampled_dataO = griddata((x_mesh.flatten(), y_mesh.flatten()), data.flatten(), (x_new_mesh, y_new_mesh), method='linear')\n",
    "                            resampled_data= resampled_dataO[0,:] if dataO.shape[0] == 1 else resampled_dataO\n",
    "                            resampled_data= np.reshape(resampled_data, (-1, len(resampled_data))) if np.ndim(resampled_data) == 1 else resampled_data\n",
    "                            for cl in range(len(resampled_data)):\n",
    "                                resampled_data_col=resampled_data[cl]\n",
    "                                peaks, _ = find_peaks(resampled_data_col, height=np.std(resampled_data_col))\n",
    "                                SpTrace=np.zeros(len(resampled_data_col))\n",
    "                                SpTrace[peaks]=1\n",
    "                                resampled_data[cl]=SpTrace    \n",
    "                            dict_All_ActivitySp[str(indexMapp)] = np.append(dict_All_ActivitySp[str(indexMapp)], np.array(resampled_data), axis=0) if str(indexMapp) in dict_All_ActivitySp else np.array(resampled_data)\n",
    "                            \n",
    "            ActivityCa_swr = [] #For each unit  \n",
    "            ActivityCa_swr_Precoupled= [] #For each unit \n",
    "            ActivityCa_swr_Postcoupled= [] #For each unit \n",
    "            ActivityCa_swr_Uncoupled= [] #For each unit \n",
    "\n",
    "            ActivitySp_swr = [] #For each unit  \n",
    "            ActivitySp_swr_Precoupled= [] #For each unit \n",
    "            ActivitySp_swr_Postcoupled= [] #For each unit \n",
    "            ActivitySp_swr_Uncoupled= [] #For each unit \n",
    "\n",
    "            startSwrList = list(pd.Series(SWRpropTrunc[\"start time\"]))\n",
    "            endSwrList = list(pd.Series(SWRpropTrunc[\"end time\"]))\n",
    "            for Pswr in range(nb_swr): \n",
    "\n",
    "                # Get the calcium and spike trace associated with the swr\n",
    "\n",
    "                startSwr=startSwrList[Pswr]\n",
    "                endSwr=endSwrList[Pswr]\n",
    "                Frame_SWR_start=int(startSwr/1000*minian_freq)\n",
    "                CaTrace = list(lCseries[Frame_SWR_start-HalfSWR:Frame_SWR_start+HalfSWR])\n",
    "                SpTraceO = list(lSseries[Frame_SWR_start-HalfSWR:Frame_SWR_start+HalfSWR]) \n",
    "                peaks, _ = find_peaks(SpTraceO, height=np.std(SpTraceO))\n",
    "                SpTrace=np.zeros(len(SpTraceO))\n",
    "                SpTrace[peaks]=1\n",
    "\n",
    "                if len(CaTrace)<len(timeSWR): \n",
    "                    print(\"/!\\ SWR too close to the begining/end of the recording,\", i, \", SWR nÂ°\", Pswr, \", Start SWR =\",  int(startSwr), \"ms, Start Rec =\", int(Frame_SWR_start), 'ms') if ii==0 else None \n",
    "                else:\n",
    "                    ActivityCa_swr.append(CaTrace) \n",
    "                    ActivitySp_swr.append(SpTraceO) \n",
    "\n",
    "                    # Define if that SWR is coupled with a spdl or not\n",
    "\n",
    "                    SWR_statut=[]\n",
    "                    startSpiList = list(pd.Series(SpipropTrunc[\"start time\"]))\n",
    "                    endSpiList = list(pd.Series(SpipropTrunc[\"end time\"]))\n",
    "                    if len(startSpiList)>0:\n",
    "                        startClosest_Spi = take_closest2(startSpiList, startSwr)# + StartTimeIndexSpi])\n",
    "                        indexSpi = startSpiList.index(startClosest_Spi)\n",
    "                        endClosest_Spi=endSpiList[indexSpi]\n",
    "                        distance = startClosest_Spi - startSwr #  + StartTimeIndexSpi]  \n",
    "                        IsTrue = 'False'             \n",
    "                        if (distance > (- before)) and (distance <  0):\n",
    "                            SWR_statut = ['Postcoupled']\n",
    "                            cPostCoupledSWR+=1 if ii==1 else 0\n",
    "                            ActivityCa_swr_Postcoupled.append(CaTrace)\n",
    "                            ActivitySp_swr_Postcoupled.append(SpTraceO)\n",
    "                            if startSwr<endClosest_Spi:\n",
    "                                IsTrue = 'True' #SWR inside the Spindle\n",
    "                        elif (distance > (0)) and (distance <  after):\n",
    "                            SWR_statut = ['Precoupled']\n",
    "                            cPreCoupledSWR+=1 if ii==1 else 0\n",
    "                            ActivityCa_swr_Precoupled.append(CaTrace)\n",
    "                            ActivitySp_swr_Precoupled.append(SpTraceO)\n",
    "                        else:\n",
    "                            SWR_statut= ['UnCoupled']\n",
    "                            cUnCoupledSWR+=1 if ii==1 else 0\n",
    "                            ActivityCa_swr_Uncoupled.append(CaTrace)\n",
    "                            ActivitySp_swr_Uncoupled.append(SpTraceO)\n",
    "                    else: \n",
    "                        SWR_statut= ['UnCoupled']\n",
    "                        cUnCoupledSWR+=1 if ii==1 else 0\n",
    "                        ActivityCa_swr_Uncoupled.append(CaTrace)\n",
    "                        ActivitySp_swr_Uncoupled.append(SpTraceO)\n",
    "\n",
    "                    SWR_GlobalResults.loc[counter2, 'Mice'] = os.path.basename(folder_base)\n",
    "                    SWR_GlobalResults.loc[counter2, 'Session'] = i \n",
    "                    SWR_GlobalResults.loc[counter2, 'Session_Time'] = None \n",
    "                    indexMapp = np.where(B[i] == C_upd_unit_id[unit])[0]\n",
    "                    SWR_GlobalResults.loc[counter2, 'Unique_Unit'] = indexMapp \n",
    "                    SWR_GlobalResults.loc[counter2, 'UnitNumber'] = unit \n",
    "                    SWR_GlobalResults.loc[counter2, 'UnitValue'] = C_upd_unit_id[unit] \n",
    "                    SWR_GlobalResults.loc[counter2, 'SWRStatut'] = SWR_statut\n",
    "                    SWR_GlobalResults.loc[counter2, 'SWRNumber'] = Pswr\n",
    "                    SWR_GlobalResults.loc[counter2, 'SWRDuration (ms)'] = endSwr- startSwr\n",
    "                    SWR_GlobalResults.loc[counter2, 'SWR inside Spdl'] = IsTrue\n",
    "                    \n",
    "                    if np.mean(CaTrace[:HalfSWR],0) > np.mean(CaTrace[HalfSWR:],0):\n",
    "                        pref='Before'\n",
    "                    elif np.mean(CaTrace[:HalfSWR],0) < np.mean(CaTrace[HalfSWR:],0):\n",
    "                        pref='After' \n",
    "                    else:\n",
    "                        pref='None'\n",
    "                    SWR_GlobalResults.loc[counter2, 'CalciumActivityPreference'] = pref\n",
    "                    SWR_GlobalResults.loc[counter2, 'CalciumActivityBefore'] = np.mean(CaTrace[:HalfSWR],0)\n",
    "                    SWR_GlobalResults.loc[counter2, 'CalciumActivityAfter'] = np.mean(CaTrace[HalfSWR:],0)\n",
    "                    SWR_GlobalResults.loc[counter2, 'AUC_calciumBefore'] = np.trapz(CaTrace[:HalfSWR],np.arange(0,len(CaTrace[:HalfSWR]),1))\n",
    "                    SWR_GlobalResults.loc[counter2, 'AUC_calciumAfter'] = np.trapz(CaTrace[HalfSWR:],np.arange(0,len(CaTrace[HalfSWR:]),1))          \n",
    "\n",
    "                    if np.sum(SpTrace[:HalfSWR],0) > np.sum(SpTrace[HalfSWR:],0):\n",
    "                        pref='Before'\n",
    "                    elif np.sum(SpTrace[:HalfSWR],0) < np.sum(SpTrace[HalfSWR:],0):\n",
    "                        pref='After' \n",
    "                    else:\n",
    "                        pref='None'\n",
    "                    SWR_GlobalResults.loc[counter2, 'SpikeActivityPreference'] = pref\n",
    "                    SWR_GlobalResults.loc[counter2, 'SpikeActivityBefore'] = np.sum(SpTrace[:HalfSWR],0)\n",
    "                    SWR_GlobalResults.loc[counter2, 'SpikeActivityAfter'] = np.sum(SpTrace[HalfSWR:],0)\n",
    "                    counter2+=1  \n",
    "\n",
    "            # All Ca traces for each spindles per Unique unit (according to cross-registration)\n",
    "\n",
    "            list_ActivityCa= ['ActivityCa_swr', 'ActivityCa_swr_Precoupled', 'ActivityCa_swr_Postcoupled', 'ActivityCa_swr_Uncoupled']\n",
    "            list_dict_All_ActivityCa= ['dict_All_ActivityCa_swr', 'dict_All_ActivityCa_swr_Precoupled', 'dict_All_ActivityCa_swr_Postcoupled', 'dict_All_ActivityCa_swr_Uncoupled']\n",
    "            for it, ActivityCaNames in enumerate(list_ActivityCa): \n",
    "                if len(indexMapp) > 0: #not empty --> cause some units are not in the cross registration..! Need to know why \n",
    "\n",
    "                    ActivityCa = locals()[ActivityCaNames]\n",
    "                    dict_All_ActivityCa = locals()[list_dict_All_ActivityCa[it]]                \n",
    "                    if len(ActivityCa)>0 :  \n",
    "                        if np.shape(np.array(ActivityCa))[1] == int(norm_freq*durationSWR*2):   #normalize traces to the same frequency rate    \n",
    "                            ActivityCa= np.reshape(np.array(ActivityCa), (-1, len(np.array(ActivityCa)))) if np.ndim(ActivityCa) == 1 else np.array(ActivityCa)    \n",
    "                            dict_All_ActivityCa[str(indexMapp)] = np.append(dict_All_ActivityCa[str(indexMapp)], np.array(ActivityCa), axis=0) if str(indexMapp) in dict_All_ActivityCa else np.array(ActivityCa)\n",
    "                        else:\n",
    "                            dataO = np.array(ActivityCa)\n",
    "                            data= np.repeat(dataO, 2, axis=0) if dataO.shape[0] == 1 else dataO\n",
    "                            x_mesh, y_mesh = np.meshgrid(np.arange(data.shape[1]), np.arange(data.shape[0]))\n",
    "                            x_new_mesh, y_new_mesh = np.meshgrid(np.linspace(0, data.shape[1] - 1, int(norm_freq*durationSWR*2)), np.linspace(0, data.shape[0] - 1, np.shape(data)[0]))\n",
    "                            resampled_dataO = griddata((x_mesh.flatten(), y_mesh.flatten()), data.flatten(), (x_new_mesh, y_new_mesh), method='linear')\n",
    "                            resampled_data= resampled_dataO[0,:] if dataO.shape[0] == 1 else resampled_dataO\n",
    "                            resampled_data= np.reshape(resampled_data, (-1, len(resampled_data))) if np.ndim(resampled_data) == 1 else resampled_data\n",
    "                            dict_All_ActivityCa[str(indexMapp)] = np.append(dict_All_ActivityCa[str(indexMapp)], np.array(resampled_data), axis=0) if str(indexMapp) in dict_All_ActivityCa else np.array(resampled_data)\n",
    "            \n",
    "            # All Sp traces for each spindles per Unique unit (according to cross-registration)\n",
    "\n",
    "            list_ActivitySp= ['ActivitySp_swr', 'ActivitySp_swr_Precoupled', 'ActivitySp_swr_Postcoupled', 'ActivitySp_swr_Uncoupled']\n",
    "            list_dict_All_ActivitySp= ['dict_All_ActivitySp_swr', 'dict_All_ActivitySp_swr_Precoupled', 'dict_All_ActivitySp_swr_Postcoupled', 'dict_All_ActivitySp_swr_Uncoupled']\n",
    "            for it, ActivitySpNames in enumerate(list_ActivitySp): \n",
    "                if len(indexMapp) > 0: #not empty --> cause some units are not in the cross registration..! Need to know why \n",
    "\n",
    "                    ActivitySp = locals()[ActivitySpNames]\n",
    "                    dict_All_ActivitySp = locals()[list_dict_All_ActivitySp[it]]                \n",
    "                    if len(ActivitySp)>0 :  \n",
    "                        if np.shape(np.array(ActivitySp))[1] == int(norm_freq*durationSWR*2):   \n",
    "                            ActivitySp= np.reshape(np.array(ActivitySp), (-1, len(np.array(ActivitySp)))) if np.ndim(ActivitySp) == 1 else np.array(ActivitySp)    \n",
    "                            for cl in range(len(ActivitySp)):\n",
    "                                resampled_data_col=ActivitySp[cl]\n",
    "                                peaks, _ = find_peaks(resampled_data_col, height=np.std(resampled_data_col))\n",
    "                                SpTrace=np.zeros(len(resampled_data_col))\n",
    "                                SpTrace[peaks]=1\n",
    "                                ActivitySp[cl]=SpTrace\n",
    "                            dict_All_ActivitySp[str(indexMapp)] = np.append(dict_All_ActivitySp[str(indexMapp)], np.array(ActivitySp), axis=0) if str(indexMapp) in dict_All_ActivitySp else np.array(ActivitySp)\n",
    "                        else: #normalize traces to the same frequency rate    \n",
    "                            dataO = np.array(ActivitySp)\n",
    "                            data= np.repeat(dataO, 2, axis=0) if dataO.shape[0] == 1 else dataO\n",
    "                            x_mesh, y_mesh = np.meshgrid(np.arange(data.shape[1]), np.arange(data.shape[0]))\n",
    "                            x_new_mesh, y_new_mesh = np.meshgrid(np.linspace(0, data.shape[1] - 1, int(norm_freq*durationSWR*2)), np.linspace(0, data.shape[0] - 1, np.shape(data)[0]))\n",
    "                            resampled_dataO = griddata((x_mesh.flatten(), y_mesh.flatten()), data.flatten(), (x_new_mesh, y_new_mesh), method='linear')\n",
    "                            resampled_data= resampled_dataO[0,:] if dataO.shape[0] == 1 else resampled_dataO\n",
    "                            resampled_data= np.reshape(resampled_data, (-1, len(resampled_data))) if np.ndim(resampled_data) == 1 else resampled_data\n",
    "                            for cl in range(len(resampled_data)):\n",
    "                                resampled_data_col=resampled_data[cl]\n",
    "                                peaks, _ = find_peaks(resampled_data_col, height=np.std(resampled_data_col))\n",
    "                                SpTrace=np.zeros(len(resampled_data_col))\n",
    "                                SpTrace[peaks]=1\n",
    "                                resampled_data[cl]=SpTrace\n",
    "                            dict_All_ActivitySp[str(indexMapp)] = np.append(dict_All_ActivitySp[str(indexMapp)], np.array(resampled_data), axis=0) if str(indexMapp) in dict_All_ActivitySp else np.array(resampled_data)\n",
    "        sentence2=f\"... in {Cortex}: {nb_spindle} spindles ({cPreCoupled} Pre, {cPostCoupled} Post & {cUnCoupled} Uncoupled Spdl) and {nb_swr} SWR detected ({cPreCoupledSWR} Pre, {cPostCoupledSWR} Post & {cUnCoupledSWR} Uncoupled SWR)\"\n",
    "        print(sentence2)\n",
    "    sentence3=f\"Nb of unique units for {os.path.basename(folder_base)} = {len(dict_All_ActivityCa_spin)}\"\n",
    "    print(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HalfSWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mice</th>\n",
       "      <th>Session</th>\n",
       "      <th>Session_Time</th>\n",
       "      <th>Unique_Unit</th>\n",
       "      <th>UnitNumber</th>\n",
       "      <th>UnitValue</th>\n",
       "      <th>SpdlStatut</th>\n",
       "      <th>SpdlNumber</th>\n",
       "      <th>SpdlDuration (ms)</th>\n",
       "      <th>SWR inside Spdl</th>\n",
       "      <th>CalciumActivityPreference</th>\n",
       "      <th>CalciumActivityBefore</th>\n",
       "      <th>CalciumActivityAfter</th>\n",
       "      <th>AUC_calciumBefore</th>\n",
       "      <th>AUC_calciumAfter</th>\n",
       "      <th>SpikeActivityPreference</th>\n",
       "      <th>SpikeActivityBefore</th>\n",
       "      <th>SpikeActivityAfter</th>\n",
       "      <th>AUC_spikeBefore</th>\n",
       "      <th>AUC_spikeAfter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>1</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>2</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>3</td>\n",
       "      <td>524.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>4</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>24</td>\n",
       "      <td>608.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>25</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>26</td>\n",
       "      <td>540.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>27</td>\n",
       "      <td>1339.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>28</td>\n",
       "      <td>1269.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Mice   Session Session_Time Unique_Unit UnitNumber UnitValue  \\\n",
       "0    BlackLinesOK  session1         None           3          0         3   \n",
       "1    BlackLinesOK  session1         None           3          0         3   \n",
       "2    BlackLinesOK  session1         None           3          0         3   \n",
       "3    BlackLinesOK  session1         None           3          0         3   \n",
       "4    BlackLinesOK  session1         None           3          0         3   \n",
       "..            ...       ...          ...         ...        ...       ...   \n",
       "891  BlackLinesOK  session4         None           4          3        25   \n",
       "892  BlackLinesOK  session4         None           4          3        25   \n",
       "893  BlackLinesOK  session4         None           4          3        25   \n",
       "894  BlackLinesOK  session4         None           4          3        25   \n",
       "895  BlackLinesOK  session4         None           4          3        25   \n",
       "\n",
       "      SpdlStatut SpdlNumber SpdlDuration (ms) SWR inside Spdl  \\\n",
       "0    [UnCoupled]          0             629.0           False   \n",
       "1    [UnCoupled]          1            1030.0           False   \n",
       "2    [UnCoupled]          2            1049.0           False   \n",
       "3    [UnCoupled]          3             524.0           False   \n",
       "4    [UnCoupled]          4            1340.0           False   \n",
       "..           ...        ...               ...             ...   \n",
       "891  [UnCoupled]         24             608.0           False   \n",
       "892  [UnCoupled]         25            1439.0           False   \n",
       "893  [UnCoupled]         26             540.0           False   \n",
       "894  [UnCoupled]         27            1339.0           False   \n",
       "895  [UnCoupled]         28            1269.0           False   \n",
       "\n",
       "    CalciumActivityPreference CalciumActivityBefore CalciumActivityAfter  \\\n",
       "0                        None                   0.0                  0.0   \n",
       "1                        None                   0.0                  0.0   \n",
       "2                        None                   0.0                  0.0   \n",
       "3                        None                   0.0                  0.0   \n",
       "4                        None                   0.0                  0.0   \n",
       "..                        ...                   ...                  ...   \n",
       "891                      None                   0.0                  0.0   \n",
       "892                      None                   0.0                  0.0   \n",
       "893                      None                   0.0                  0.0   \n",
       "894                      None                   0.0                  0.0   \n",
       "895                      None                   0.0                  0.0   \n",
       "\n",
       "    AUC_calciumBefore AUC_calciumAfter SpikeActivityPreference  \\\n",
       "0                 0.0              0.0                    None   \n",
       "1                 0.0              0.0                    None   \n",
       "2                 0.0              0.0                    None   \n",
       "3                 0.0              0.0                    None   \n",
       "4                 0.0              0.0                    None   \n",
       "..                ...              ...                     ...   \n",
       "891               0.0              0.0                    None   \n",
       "892               0.0              0.0                    None   \n",
       "893               0.0              0.0                    None   \n",
       "894               0.0              0.0                    None   \n",
       "895               0.0              0.0                    None   \n",
       "\n",
       "    SpikeActivityBefore SpikeActivityAfter AUC_spikeBefore AUC_spikeAfter  \n",
       "0                   0.0                0.0             NaN            NaN  \n",
       "1                   0.0                0.0             NaN            NaN  \n",
       "2                   0.0                0.0             NaN            NaN  \n",
       "3                   0.0                0.0             NaN            NaN  \n",
       "4                   0.0                0.0             NaN            NaN  \n",
       "..                  ...                ...             ...            ...  \n",
       "891                 0.0                0.0             NaN            NaN  \n",
       "892                 0.0                0.0             NaN            NaN  \n",
       "893                 0.0                0.0             NaN            NaN  \n",
       "894                 0.0                0.0             NaN            NaN  \n",
       "895                 0.0                0.0             NaN            NaN  \n",
       "\n",
       "[896 rows x 20 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spindles_GlobalResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Spindles_GlobalResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice=os.path.basename(folder_base) \n",
    "filenameOut = folder_base / f'Spindles_{Cortex}_ABdetection_GlobalResultsAB_{mice}.xlsx'\n",
    "writer = pd.ExcelWriter(filenameOut)\n",
    "Spindles_GlobalResults.to_excel(writer)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do average results for Spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_dict_All_ActivityCa_spin = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivityCa_spin.items()}\n",
    "Array=list(AVG_dict_All_ActivityCa_spin.values())\n",
    "\n",
    "AVG_dict_All_ActivityCa_spin_Uncoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivityCa_spin_Uncoupled.items()}\n",
    "ArrayUn=list(AVG_dict_All_ActivityCa_spin_Uncoupled.values())\n",
    "\n",
    "AVG_dict_All_ActivityCa_spin_Precoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivityCa_spin_Precoupled.items()}\n",
    "ArrayPre=list(AVG_dict_All_ActivityCa_spin_Precoupled.values())\n",
    "\n",
    "AVG_dict_All_ActivityCa_spin_Postcoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivityCa_spin_Postcoupled.items()}\n",
    "ArrayPost=list(AVG_dict_All_ActivityCa_spin_Postcoupled.values())\n",
    "\n",
    "filenameOut = folder_base / f'Spindles_{Cortex}_ABdetection_CalciumAvgResultsAB_{mice}.xlsx'\n",
    "excel_writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "Array=pd.DataFrame(Array)\n",
    "ArrayUn=pd.DataFrame(ArrayUn)\n",
    "ArrayPre=pd.DataFrame(ArrayPre)\n",
    "ArrayPost=pd.DataFrame(ArrayPost)\n",
    "\n",
    "Array.to_excel(excel_writer, sheet_name='All_Spindles', index=True, header=False)\n",
    "ArrayUn.to_excel(excel_writer, sheet_name='Uncoupled_Spindles', index=True, header=False)\n",
    "ArrayPre.to_excel(excel_writer, sheet_name='Precoupled_Spindles', index=True, header=False)\n",
    "ArrayPost.to_excel(excel_writer, sheet_name='Postcoupled_Spindles', index=True, header=False)\n",
    "\n",
    "excel_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_dict_All_ActivitySp_spin = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivitySp_spin.items()}\n",
    "Array=list(AVG_dict_All_ActivitySp_spin.values())\n",
    "\n",
    "AVG_dict_All_ActivitySp_spin_Uncoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivitySp_spin_Uncoupled.items()}\n",
    "ArrayUn=list(AVG_dict_All_ActivityCa_spin_Uncoupled.values())\n",
    "\n",
    "AVG_dict_All_ActivitySp_spin_Precoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivitySp_spin_Precoupled.items()}\n",
    "ArrayPre=list(AVG_dict_All_ActivitySp_spin_Precoupled.values())\n",
    "\n",
    "AVG_dict_All_ActivitySp_spin_Postcoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivitySp_spin_Postcoupled.items()}\n",
    "ArrayPost=list(AVG_dict_All_ActivitySp_spin_Postcoupled.values())\n",
    "\n",
    "filenameOut = folder_base / f'Spindles_{Cortex}_ABdetection_SpikeAvgResultsAB_{mice}.xlsx'\n",
    "excel_writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "Array=pd.DataFrame(Array)\n",
    "ArrayUn=pd.DataFrame(ArrayUn)\n",
    "ArrayPre=pd.DataFrame(ArrayPre)\n",
    "ArrayPost=pd.DataFrame(ArrayPost)\n",
    "\n",
    "Array.to_excel(excel_writer, sheet_name='All_Spindles', index=True, header=False)\n",
    "ArrayUn.to_excel(excel_writer, sheet_name='Uncoupled_Spindles', index=True, header=False)\n",
    "ArrayPre.to_excel(excel_writer, sheet_name='Precoupled_Spindles', index=True, header=False)\n",
    "ArrayPost.to_excel(excel_writer, sheet_name='Postcoupled_Spindles', index=True, header=False)\n",
    "\n",
    "excel_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mice</th>\n",
       "      <th>Session</th>\n",
       "      <th>Session_Time</th>\n",
       "      <th>Unique_Unit</th>\n",
       "      <th>UnitNumber</th>\n",
       "      <th>UnitValue</th>\n",
       "      <th>SWRStatut</th>\n",
       "      <th>SWRNumber</th>\n",
       "      <th>SWRDuration (ms)</th>\n",
       "      <th>SWR inside Spdl</th>\n",
       "      <th>CalciumActivityPreference</th>\n",
       "      <th>CalciumActivityBefore</th>\n",
       "      <th>CalciumActivityAfter</th>\n",
       "      <th>AUC_calciumBefore</th>\n",
       "      <th>AUC_calciumAfter</th>\n",
       "      <th>SpikeActivityPreference</th>\n",
       "      <th>SpikeActivityBefore</th>\n",
       "      <th>SpikeActivityAfter</th>\n",
       "      <th>AUC_spikeBefore</th>\n",
       "      <th>AUC_spikeAfter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>152</td>\n",
       "      <td>61.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>153</td>\n",
       "      <td>71.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>154</td>\n",
       "      <td>58.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>155</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>BlackLinesOK</td>\n",
       "      <td>session4</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>[UnCoupled]</td>\n",
       "      <td>156</td>\n",
       "      <td>53.0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4738 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mice   Session Session_Time Unique_Unit UnitNumber UnitValue  \\\n",
       "0     BlackLinesOK  session1         None           3          0         3   \n",
       "1     BlackLinesOK  session1         None           3          0         3   \n",
       "2     BlackLinesOK  session1         None           3          0         3   \n",
       "3     BlackLinesOK  session1         None           3          0         3   \n",
       "4     BlackLinesOK  session1         None           3          0         3   \n",
       "...            ...       ...          ...         ...        ...       ...   \n",
       "4733  BlackLinesOK  session4         None           4          3        25   \n",
       "4734  BlackLinesOK  session4         None           4          3        25   \n",
       "4735  BlackLinesOK  session4         None           4          3        25   \n",
       "4736  BlackLinesOK  session4         None           4          3        25   \n",
       "4737  BlackLinesOK  session4         None           4          3        25   \n",
       "\n",
       "        SWRStatut SWRNumber SWRDuration (ms) SWR inside Spdl  \\\n",
       "0     [UnCoupled]         0             59.0           False   \n",
       "1     [UnCoupled]         1             60.0           False   \n",
       "2     [UnCoupled]         2             55.0           False   \n",
       "3     [UnCoupled]         3             61.0           False   \n",
       "4     [UnCoupled]         4             45.0           False   \n",
       "...           ...       ...              ...             ...   \n",
       "4733  [UnCoupled]       152             61.0           False   \n",
       "4734  [UnCoupled]       153             71.0           False   \n",
       "4735  [UnCoupled]       154             58.0           False   \n",
       "4736  [UnCoupled]       155            150.0           False   \n",
       "4737  [UnCoupled]       156             53.0           False   \n",
       "\n",
       "     CalciumActivityPreference CalciumActivityBefore CalciumActivityAfter  \\\n",
       "0                         None                   0.0                  0.0   \n",
       "1                         None                   0.0                  0.0   \n",
       "2                         None                   0.0                  0.0   \n",
       "3                         None                   0.0                  0.0   \n",
       "4                         None                   0.0                  0.0   \n",
       "...                        ...                   ...                  ...   \n",
       "4733                      None                   0.0                  0.0   \n",
       "4734                      None                   0.0                  0.0   \n",
       "4735                      None                   0.0                  0.0   \n",
       "4736                      None                   0.0                  0.0   \n",
       "4737                      None                   0.0                  0.0   \n",
       "\n",
       "     AUC_calciumBefore AUC_calciumAfter SpikeActivityPreference  \\\n",
       "0                  0.0              0.0                    None   \n",
       "1                  0.0              0.0                    None   \n",
       "2                  0.0              0.0                    None   \n",
       "3                  0.0              0.0                    None   \n",
       "4                  0.0              0.0                    None   \n",
       "...                ...              ...                     ...   \n",
       "4733               0.0              0.0                    None   \n",
       "4734               0.0              0.0                    None   \n",
       "4735               0.0              0.0                    None   \n",
       "4736               0.0              0.0                    None   \n",
       "4737               0.0              0.0                    None   \n",
       "\n",
       "     SpikeActivityBefore SpikeActivityAfter AUC_spikeBefore AUC_spikeAfter  \n",
       "0                    0.0                0.0             NaN            NaN  \n",
       "1                    0.0                0.0             NaN            NaN  \n",
       "2                    0.0                0.0             NaN            NaN  \n",
       "3                    0.0                0.0             NaN            NaN  \n",
       "4                    0.0                0.0             NaN            NaN  \n",
       "...                  ...                ...             ...            ...  \n",
       "4733                 0.0                0.0             NaN            NaN  \n",
       "4734                 0.0                0.0             NaN            NaN  \n",
       "4735                 0.0                0.0             NaN            NaN  \n",
       "4736                 0.0                0.0             NaN            NaN  \n",
       "4737                 0.0                0.0             NaN            NaN  \n",
       "\n",
       "[4738 rows x 20 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SWR_GlobalResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save SWR_GlobalResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "mice=os.path.basename(folder_base) \n",
    "filenameOut = folder_base / f'SWR_{Cortex}_ABdetection_GlobalResultsAB_{mice}.xlsx'\n",
    "writer = pd.ExcelWriter(filenameOut)\n",
    "SWR_GlobalResults.to_excel(writer)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do average results for SWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_dict_All_ActivityCa_swr = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivityCa_swr.items()}\n",
    "Array=list(AVG_dict_All_ActivityCa_swr.values())\n",
    "\n",
    "AVG_dict_All_ActivityCa_swr_Uncoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivityCa_swr_Uncoupled.items()}\n",
    "ArrayUn=list(AVG_dict_All_ActivityCa_swr_Uncoupled.values())\n",
    "\n",
    "AVG_dict_All_ActivityCa_swr_Precoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivityCa_swr_Precoupled.items()}\n",
    "ArrayPre=list(AVG_dict_All_ActivityCa_swr_Precoupled.values())\n",
    "\n",
    "AVG_dict_All_ActivityCa_swr_Postcoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivityCa_swr_Postcoupled.items()}\n",
    "ArrayPost=list(AVG_dict_All_ActivityCa_swr_Postcoupled.values())\n",
    "\n",
    "filenameOut = folder_base / f'SWR_{Cortex}_ABdetection_CalciumAvgResultsAB_{mice}.xlsx'\n",
    "excel_writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "Array=pd.DataFrame(Array)\n",
    "ArrayUn=pd.DataFrame(ArrayUn)\n",
    "ArrayPre=pd.DataFrame(ArrayPre)\n",
    "ArrayPost=pd.DataFrame(ArrayPost)\n",
    "\n",
    "Array.to_excel(excel_writer, sheet_name='All_SWR', index=True, header=False)\n",
    "ArrayUn.to_excel(excel_writer, sheet_name='Uncoupled_SWR', index=True, header=False)\n",
    "ArrayPre.to_excel(excel_writer, sheet_name='Precoupled_SWR', index=True, header=False)\n",
    "ArrayPost.to_excel(excel_writer, sheet_name='Postcoupled_SWR', index=True, header=False)\n",
    "\n",
    "excel_writer.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_dict_All_ActivitySp_swr = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivitySp_swr.items()}\n",
    "Array=list(AVG_dict_All_ActivitySp_swr.values())\n",
    "\n",
    "AVG_dict_All_ActivitySp_swr_Uncoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivitySp_swr_Uncoupled.items()}\n",
    "ArrayUn=list(AVG_dict_All_ActivitySp_swr_Uncoupled.values())\n",
    "\n",
    "AVG_dict_All_ActivitySp_swr_Precoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivitySp_swr_Precoupled.items()}\n",
    "ArrayPre=list(AVG_dict_All_ActivitySp_swr_Precoupled.values())\n",
    "\n",
    "AVG_dict_All_ActivitySp_swr_Postcoupled = {key: np.mean(matrix,0) for key, matrix in dict_All_ActivitySp_swr_Postcoupled.items()}\n",
    "ArrayPost=list(AVG_dict_All_ActivitySp_swr_Postcoupled.values())\n",
    "\n",
    "filenameOut = folder_base / f'SWR_{Cortex}_ABdetection_SpikeAvgResultsAB_{mice}.xlsx'\n",
    "excel_writer = pd.ExcelWriter(filenameOut)\n",
    "\n",
    "Array=pd.DataFrame(Array)\n",
    "ArrayUn=pd.DataFrame(ArrayUn)\n",
    "ArrayPre=pd.DataFrame(ArrayPre)\n",
    "ArrayPost=pd.DataFrame(ArrayPost)\n",
    "\n",
    "Array.to_excel(excel_writer, sheet_name='All_SWR', index=True, header=False)\n",
    "ArrayUn.to_excel(excel_writer, sheet_name='Uncoupled_SWR', index=True, header=False)\n",
    "ArrayPre.to_excel(excel_writer, sheet_name='Precoupled_SWR', index=True, header=False)\n",
    "ArrayPost.to_excel(excel_writer, sheet_name='Postcoupled_SWR', index=True, header=False)\n",
    "\n",
    "excel_writer.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('minian')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d28f0aa69d972f186b6eef62f149b885b857325c1e4e259a67006c9c0c737cc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
